{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "njobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv',sep='|')\n",
    "test=pd.read_csv('test.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     104\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.055349\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.fraud.value_counts())\n",
    "print(train.fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training set\n",
    "\n",
    "train['scannedLineItems'] = train['scannedLineItemsPerSecond'] * train['totalScanTimeInSeconds']\n",
    "train['pricePerScannedLineItem'] = train['grandTotal'] / train['scannedLineItems']\n",
    "train['scansWithoutRegistrationPerScannedLineItem'] = train['scansWithoutRegistration'] / train['scannedLineItems']\n",
    "train['quantityModificationsPerScannedLineItem'] = train['quantityModifications'] / train['scannedLineItems']\n",
    "train['lineItemVoidsPerSecond'] = train['lineItemVoids'] / train['totalScanTimeInSeconds']\n",
    "train['scansWithoutRegistrationPerSecond'] = train['scansWithoutRegistration'] / train['totalScanTimeInSeconds']\n",
    "train['quantityModificationsPerSecond'] = train['quantityModifications'] / train['totalScanTimeInSeconds']\n",
    "train['secondsPerEuro'] = train['totalScanTimeInSeconds'] / train['grandTotal']\n",
    "train['lineItemVoidsPerEuro'] = train['lineItemVoids'] / train['grandTotal']\n",
    "train['scansWithoutRegistrationPerEuro'] = train['scansWithoutRegistration'] / train['grandTotal']\n",
    "train['quantityModificationsPerEuro'] = train['quantityModifications'] / train['grandTotal']\n",
    "\n",
    "\n",
    "# for test set\n",
    "test['scannedLineItems'] = test['scannedLineItemsPerSecond'] * test['totalScanTimeInSeconds']\n",
    "test['pricePerScannedLineItem'] = test['grandTotal'] / test['scannedLineItems']\n",
    "test['scansWithoutRegistrationPerScannedLineItem'] = test['scansWithoutRegistration'] / test['scannedLineItems']\n",
    "test['quantityModificationsPerScannedLineItem'] = test['quantityModifications'] / test['scannedLineItems']\n",
    "test['lineItemVoidsPerSecond'] = test['lineItemVoids'] / test['totalScanTimeInSeconds']\n",
    "test['scansWithoutRegistrationPerSecond'] = test['scansWithoutRegistration'] / test['totalScanTimeInSeconds']\n",
    "test['quantityModificationsPerSecond'] = test['quantityModifications'] / test['totalScanTimeInSeconds']\n",
    "test['secondsPerEuro'] = test['totalScanTimeInSeconds'] / test['grandTotal']\n",
    "test['lineItemVoidsPerEuro'] = test['lineItemVoids'] / test['grandTotal']\n",
    "test['scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / test['grandTotal']\n",
    "test['quantityModificationsPerEuro'] = test['quantityModifications'] / test['grandTotal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation for perEuro attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40562            inf\n",
       "492399           inf\n",
       "86833            inf\n",
       "363211           inf\n",
       "456994           inf\n",
       "155622           inf\n",
       "438266           inf\n",
       "69401            inf\n",
       "489766           inf\n",
       "147774           inf\n",
       "52962            inf\n",
       "34895            inf\n",
       "143886           inf\n",
       "129034           inf\n",
       "87373            inf\n",
       "199015           inf\n",
       "117536           inf\n",
       "462632           inf\n",
       "436235           inf\n",
       "328053           inf\n",
       "112020           inf\n",
       "29990            inf\n",
       "120191           inf\n",
       "214052           inf\n",
       "208504           inf\n",
       "30187            inf\n",
       "454691           inf\n",
       "19792            inf\n",
       "46561            inf\n",
       "270427           inf\n",
       "30423            inf\n",
       "158772           inf\n",
       "496219           inf\n",
       "146252           inf\n",
       "455867           inf\n",
       "337680           inf\n",
       "161945           inf\n",
       "64223            inf\n",
       "201272           inf\n",
       "461791           inf\n",
       "13695            inf\n",
       "211326           inf\n",
       "118032           inf\n",
       "91248            inf\n",
       "179013           inf\n",
       "455538           inf\n",
       "441018           inf\n",
       "330870           inf\n",
       "106855           inf\n",
       "389520           inf\n",
       "43649            inf\n",
       "287909           inf\n",
       "35561            inf\n",
       "418922           inf\n",
       "190225           inf\n",
       "299044           inf\n",
       "87759            inf\n",
       "53667     500.000000\n",
       "133426    500.000000\n",
       "497223    500.000000\n",
       "31676     500.000000\n",
       "102618    400.000000\n",
       "371320    400.000000\n",
       "283861    400.000000\n",
       "3282      400.000000\n",
       "176008    400.000000\n",
       "16726     300.000000\n",
       "448922    300.000000\n",
       "156517    300.000000\n",
       "236301    300.000000\n",
       "158961    300.000000\n",
       "428300    300.000000\n",
       "129930    300.000000\n",
       "256995    300.000000\n",
       "58189     300.000000\n",
       "104670    300.000000\n",
       "306285    250.000000\n",
       "449290    250.000000\n",
       "166233    250.000000\n",
       "175423    250.000000\n",
       "65523     250.000000\n",
       "57386     250.000000\n",
       "356924    250.000000\n",
       "416085    250.000000\n",
       "234038    200.000000\n",
       "149198    200.000000\n",
       "124665    200.000000\n",
       "16134     200.000000\n",
       "227115    200.000000\n",
       "306866    200.000000\n",
       "487253    200.000000\n",
       "431434    200.000000\n",
       "24165     200.000000\n",
       "250987    200.000000\n",
       "16998     200.000000\n",
       "178268    200.000000\n",
       "232443    200.000000\n",
       "267039    200.000000\n",
       "39654     200.000000\n",
       "207351    200.000000\n",
       "481847    200.000000\n",
       "157456    200.000000\n",
       "25121     200.000000\n",
       "304527    200.000000\n",
       "7624      200.000000\n",
       "429833    200.000000\n",
       "309508    200.000000\n",
       "374213    200.000000\n",
       "373593    200.000000\n",
       "23336     200.000000\n",
       "154649    166.666667\n",
       "447408    166.666667\n",
       "302576    166.666667\n",
       "101060    166.666667\n",
       "150499    166.666667\n",
       "223221    166.666667\n",
       "128211    166.666667\n",
       "286758    166.666667\n",
       "103050    150.000000\n",
       "469526    150.000000\n",
       "134886    150.000000\n",
       "68346     150.000000\n",
       "22192     150.000000\n",
       "50403     150.000000\n",
       "14751     150.000000\n",
       "251164    150.000000\n",
       "9273      150.000000\n",
       "195198    150.000000\n",
       "228560    133.333333\n",
       "315680    133.333333\n",
       "186307    133.333333\n",
       "354611    133.333333\n",
       "380463    133.333333\n",
       "252849    133.333333\n",
       "486833    133.333333\n",
       "35380     133.333333\n",
       "486320    133.333333\n",
       "211776    133.333333\n",
       "184479    133.333333\n",
       "82156     133.333333\n",
       "136661    133.333333\n",
       "3653      133.333333\n",
       "456458    125.000000\n",
       "258338    125.000000\n",
       "48123     125.000000\n",
       "81978     125.000000\n",
       "280337    125.000000\n",
       "215024    125.000000\n",
       "288380    125.000000\n",
       "400587    125.000000\n",
       "195437    125.000000\n",
       "216483    125.000000\n",
       "484382    125.000000\n",
       "215335    100.000000\n",
       "187633    100.000000\n",
       "103595    100.000000\n",
       "138846    100.000000\n",
       "269421    100.000000\n",
       "71060     100.000000\n",
       "470823    100.000000\n",
       "310894    100.000000\n",
       "353291    100.000000\n",
       "35932     100.000000\n",
       "160837    100.000000\n",
       "242300    100.000000\n",
       "347490    100.000000\n",
       "389981    100.000000\n",
       "458442    100.000000\n",
       "285196    100.000000\n",
       "396734    100.000000\n",
       "261011    100.000000\n",
       "347724    100.000000\n",
       "286247    100.000000\n",
       "70209     100.000000\n",
       "454704    100.000000\n",
       "398228    100.000000\n",
       "257586    100.000000\n",
       "422628    100.000000\n",
       "256054    100.000000\n",
       "126292    100.000000\n",
       "294177    100.000000\n",
       "278522    100.000000\n",
       "7605      100.000000\n",
       "405388    100.000000\n",
       "457265    100.000000\n",
       "427150    100.000000\n",
       "372795    100.000000\n",
       "13725     100.000000\n",
       "372754    100.000000\n",
       "332910    100.000000\n",
       "391369    100.000000\n",
       "206802     83.333333\n",
       "445151     83.333333\n",
       "306261     83.333333\n",
       "451236     83.333333\n",
       "446393     83.333333\n",
       "349243     83.333333\n",
       "219308     83.333333\n",
       "116391     83.333333\n",
       "434975     83.333333\n",
       "485587     83.333333\n",
       "228967     80.000000\n",
       "351935     80.000000\n",
       "97101      80.000000\n",
       "233295     80.000000\n",
       "314855     75.000000\n",
       "455728     75.000000\n",
       "33592      75.000000\n",
       "241432     75.000000\n",
       "116881     75.000000\n",
       "467226     75.000000\n",
       "292051     75.000000\n",
       "201233     75.000000\n",
       "416801     75.000000\n",
       "444529     71.428571\n",
       "379820     71.428571\n",
       "186711     71.428571\n",
       "34321      71.428571\n",
       "378908     71.428571\n",
       "214139     71.428571\n",
       "452081     71.428571\n",
       "42831      71.428571\n",
       "150453     71.428571\n",
       "345096     71.428571\n",
       "432282     66.666667\n",
       "269630     66.666667\n",
       "166380     66.666667\n",
       "294199     66.666667\n",
       "205210     66.666667\n",
       "85390      66.666667\n",
       "428532     66.666667\n",
       "247837     66.666667\n",
       "382411     66.666667\n",
       "60423      66.666667\n",
       "466514     66.666667\n",
       "71334      66.666667\n",
       "151093     66.666667\n",
       "50267      66.666667\n",
       "61186      66.666667\n",
       "25381      66.666667\n",
       "481154     66.666667\n",
       "112396     66.666667\n",
       "105383     66.666667\n",
       "275316     66.666667\n",
       "12561      66.666667\n",
       "184687     66.666667\n",
       "480748     66.666667\n",
       "120256     62.500000\n",
       "320373     62.500000\n",
       "335024     62.500000\n",
       "             ...    \n",
       "116522      0.000000\n",
       "116530      0.000000\n",
       "116532      0.000000\n",
       "116534      0.000000\n",
       "397156      0.000000\n",
       "116542      0.000000\n",
       "116543      0.000000\n",
       "116545      0.000000\n",
       "116555      0.000000\n",
       "240179      0.000000\n",
       "396802      0.000000\n",
       "116957      0.000000\n",
       "396800      0.000000\n",
       "240081      0.000000\n",
       "117355      0.000000\n",
       "117357      0.000000\n",
       "396447      0.000000\n",
       "396446      0.000000\n",
       "117359      0.000000\n",
       "239976      0.000000\n",
       "396441      0.000000\n",
       "396440      0.000000\n",
       "396437      0.000000\n",
       "117370      0.000000\n",
       "117376      0.000000\n",
       "117382      0.000000\n",
       "117383      0.000000\n",
       "117385      0.000000\n",
       "117386      0.000000\n",
       "396417      0.000000\n",
       "239972      0.000000\n",
       "239966      0.000000\n",
       "239959      0.000000\n",
       "117408      0.000000\n",
       "289468      0.000000\n",
       "117421      0.000000\n",
       "396394      0.000000\n",
       "396387      0.000000\n",
       "396385      0.000000\n",
       "289452      0.000000\n",
       "396453      0.000000\n",
       "117339      0.000000\n",
       "117288      0.000000\n",
       "396525      0.000000\n",
       "117257      0.000000\n",
       "396523      0.000000\n",
       "396521      0.000000\n",
       "117266      0.000000\n",
       "117269      0.000000\n",
       "117273      0.000000\n",
       "117284      0.000000\n",
       "396509      0.000000\n",
       "117285      0.000000\n",
       "117286      0.000000\n",
       "117298      0.000000\n",
       "117337      0.000000\n",
       "396496      0.000000\n",
       "117310      0.000000\n",
       "239988      0.000000\n",
       "117318      0.000000\n",
       "117323      0.000000\n",
       "396478      0.000000\n",
       "396477      0.000000\n",
       "396472      0.000000\n",
       "117330      0.000000\n",
       "396464      0.000000\n",
       "396461      0.000000\n",
       "396384      0.000000\n",
       "396382      0.000000\n",
       "117438      0.000000\n",
       "396285      0.000000\n",
       "117531      0.000000\n",
       "117532      0.000000\n",
       "117537      0.000000\n",
       "396300      0.000000\n",
       "396299      0.000000\n",
       "117547      0.000000\n",
       "117549      0.000000\n",
       "396295      0.000000\n",
       "239936      0.000000\n",
       "396292      0.000000\n",
       "117552      0.000000\n",
       "396282      0.000000\n",
       "117528      0.000000\n",
       "396279      0.000000\n",
       "289496      0.000000\n",
       "117576      0.000000\n",
       "396273      0.000000\n",
       "117579      0.000000\n",
       "289499      0.000000\n",
       "239927      0.000000\n",
       "396252      0.000000\n",
       "396251      0.000000\n",
       "117599      0.000000\n",
       "117600      0.000000\n",
       "239939      0.000000\n",
       "289486      0.000000\n",
       "117439      0.000000\n",
       "117491      0.000000\n",
       "239957      0.000000\n",
       "396372      0.000000\n",
       "117455      0.000000\n",
       "396368      0.000000\n",
       "117459      0.000000\n",
       "117462      0.000000\n",
       "117467      0.000000\n",
       "239949      0.000000\n",
       "396357      0.000000\n",
       "117476      0.000000\n",
       "117488      0.000000\n",
       "289479      0.000000\n",
       "396322      0.000000\n",
       "117493      0.000000\n",
       "396341      0.000000\n",
       "117499      0.000000\n",
       "396339      0.000000\n",
       "117502      0.000000\n",
       "239948      0.000000\n",
       "396335      0.000000\n",
       "117506      0.000000\n",
       "117509      0.000000\n",
       "117511      0.000000\n",
       "117519      0.000000\n",
       "396526      0.000000\n",
       "396528      0.000000\n",
       "117255      0.000000\n",
       "117074      0.000000\n",
       "117039      0.000000\n",
       "117041      0.000000\n",
       "117042      0.000000\n",
       "240059      0.000000\n",
       "289385      0.000000\n",
       "396716      0.000000\n",
       "117057      0.000000\n",
       "117064      0.000000\n",
       "117068      0.000000\n",
       "240052      0.000000\n",
       "396702      0.000000\n",
       "396699      0.000000\n",
       "240067      0.000000\n",
       "117081      0.000000\n",
       "117082      0.000000\n",
       "117088      0.000000\n",
       "396685      0.000000\n",
       "396682      0.000000\n",
       "117099      0.000000\n",
       "117104      0.000000\n",
       "117107      0.000000\n",
       "117108      0.000000\n",
       "289397      0.000000\n",
       "396672      0.000000\n",
       "240066      0.000000\n",
       "396736      0.000000\n",
       "117121      0.000000\n",
       "116996      0.000000\n",
       "396794      0.000000\n",
       "116966      0.000000\n",
       "396791      0.000000\n",
       "116968      0.000000\n",
       "116973      0.000000\n",
       "396776      0.000000\n",
       "396775      0.000000\n",
       "396774      0.000000\n",
       "396773      0.000000\n",
       "116986      0.000000\n",
       "240079      0.000000\n",
       "240077      0.000000\n",
       "396737      0.000000\n",
       "117004      0.000000\n",
       "396757      0.000000\n",
       "289370      0.000000\n",
       "289371      0.000000\n",
       "117013      0.000000\n",
       "396751      0.000000\n",
       "289373      0.000000\n",
       "396749      0.000000\n",
       "117016      0.000000\n",
       "396741      0.000000\n",
       "117027      0.000000\n",
       "117111      0.000000\n",
       "117126      0.000000\n",
       "117246      0.000000\n",
       "240017      0.000000\n",
       "396589      0.000000\n",
       "396585      0.000000\n",
       "117194      0.000000\n",
       "117195      0.000000\n",
       "396581      0.000000\n",
       "117208      0.000000\n",
       "240026      0.000000\n",
       "240022      0.000000\n",
       "396574      0.000000\n",
       "117212      0.000000\n",
       "396572      0.000000\n",
       "396568      0.000000\n",
       "396596      0.000000\n",
       "289424      0.000000\n",
       "396564      0.000000\n",
       "396562      0.000000\n",
       "117220      0.000000\n",
       "396555      0.000000\n",
       "396553      0.000000\n",
       "289427      0.000000\n",
       "240015      0.000000\n",
       "240014      0.000000\n",
       "396544      0.000000\n",
       "240009      0.000000\n",
       "117192      0.000000\n",
       "289418      0.000000\n",
       "396657      0.000000\n",
       "117142      0.000000\n",
       "396656      0.000000\n",
       "396655      0.000000\n",
       "396653      0.000000\n",
       "289401      0.000000\n",
       "117132      0.000000\n",
       "396646      0.000000\n",
       "117133      0.000000\n",
       "289402      0.000000\n",
       "396643      0.000000\n",
       "117134      0.000000\n",
       "396640      0.000000\n",
       "240041      0.000000\n",
       "396601      0.000000\n",
       "289404      0.000000\n",
       "396631      0.000000\n",
       "396630      0.000000\n",
       "396629      0.000000\n",
       "396621      0.000000\n",
       "117162      0.000000\n",
       "289411      0.000000\n",
       "117172      0.000000\n",
       "396608      0.000000\n",
       "396607      0.000000\n",
       "240034      0.000000\n",
       "382421      0.000000\n",
       "54617            NaN\n",
       "98526            NaN\n",
       "184209           NaN\n",
       "184591           NaN\n",
       "213466           NaN\n",
       "231516           NaN\n",
       "267463           NaN\n",
       "304808           NaN\n",
       "351847           NaN\n",
       "356724           NaN\n",
       "427756           NaN\n",
       "433822           NaN\n",
       "469663           NaN\n",
       "494789           NaN\n",
       "Name: quantityModificationsPerEuro, Length: 498121, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values(by = \"quantityModificationsPerEuro\", ascending = False)['quantityModificationsPerEuro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 20)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.loc[test['grandTotal'] == 0.00, 'secondsPerEuro'] = test['totalScanTimeInSeconds'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'lineItemVoidsPerEuro'] = test['lineItemVoids'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'quantityModificationsPerEuro'] = test['quantityModifications'] / 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31676     500.000000\n",
       "112020    500.000000\n",
       "287909    500.000000\n",
       "214052    500.000000\n",
       "455538    500.000000\n",
       "46561     500.000000\n",
       "53667     500.000000\n",
       "208504    500.000000\n",
       "52962     500.000000\n",
       "330870    500.000000\n",
       "270427    500.000000\n",
       "133426    500.000000\n",
       "497223    500.000000\n",
       "461791    500.000000\n",
       "143886    500.000000\n",
       "389520    400.000000\n",
       "328053    400.000000\n",
       "147774    400.000000\n",
       "3282      400.000000\n",
       "161945    400.000000\n",
       "91248     400.000000\n",
       "371320    400.000000\n",
       "118032    400.000000\n",
       "176008    400.000000\n",
       "283861    400.000000\n",
       "34895     400.000000\n",
       "43649     400.000000\n",
       "337680    400.000000\n",
       "19792     400.000000\n",
       "299044    400.000000\n",
       "13695     400.000000\n",
       "102618    400.000000\n",
       "236301    300.000000\n",
       "156517    300.000000\n",
       "462632    300.000000\n",
       "211326    300.000000\n",
       "129930    300.000000\n",
       "436235    300.000000\n",
       "428300    300.000000\n",
       "256995    300.000000\n",
       "129034    300.000000\n",
       "496219    300.000000\n",
       "58189     300.000000\n",
       "104670    300.000000\n",
       "492399    300.000000\n",
       "199015    300.000000\n",
       "16726     300.000000\n",
       "117536    300.000000\n",
       "86833     300.000000\n",
       "448922    300.000000\n",
       "441018    300.000000\n",
       "158961    300.000000\n",
       "65523     250.000000\n",
       "306285    250.000000\n",
       "449290    250.000000\n",
       "416085    250.000000\n",
       "356924    250.000000\n",
       "175423    250.000000\n",
       "57386     250.000000\n",
       "166233    250.000000\n",
       "124665    200.000000\n",
       "16998     200.000000\n",
       "64223     200.000000\n",
       "179013    200.000000\n",
       "489766    200.000000\n",
       "25121     200.000000\n",
       "16134     200.000000\n",
       "267039    200.000000\n",
       "23336     200.000000\n",
       "431434    200.000000\n",
       "35561     200.000000\n",
       "487253    200.000000\n",
       "481847    200.000000\n",
       "146252    200.000000\n",
       "149198    200.000000\n",
       "304527    200.000000\n",
       "232443    200.000000\n",
       "87759     200.000000\n",
       "373593    200.000000\n",
       "190225    200.000000\n",
       "120191    200.000000\n",
       "429833    200.000000\n",
       "306866    200.000000\n",
       "157456    200.000000\n",
       "207351    200.000000\n",
       "24165     200.000000\n",
       "374213    200.000000\n",
       "234038    200.000000\n",
       "39654     200.000000\n",
       "201272    200.000000\n",
       "456994    200.000000\n",
       "178268    200.000000\n",
       "227115    200.000000\n",
       "250987    200.000000\n",
       "7624      200.000000\n",
       "438266    200.000000\n",
       "309508    200.000000\n",
       "154649    166.666667\n",
       "286758    166.666667\n",
       "223221    166.666667\n",
       "150499    166.666667\n",
       "302576    166.666667\n",
       "101060    166.666667\n",
       "447408    166.666667\n",
       "128211    166.666667\n",
       "9273      150.000000\n",
       "469526    150.000000\n",
       "251164    150.000000\n",
       "195198    150.000000\n",
       "134886    150.000000\n",
       "22192     150.000000\n",
       "14751     150.000000\n",
       "68346     150.000000\n",
       "50403     150.000000\n",
       "103050    150.000000\n",
       "486320    133.333333\n",
       "252849    133.333333\n",
       "186307    133.333333\n",
       "315680    133.333333\n",
       "3653      133.333333\n",
       "380463    133.333333\n",
       "354611    133.333333\n",
       "82156     133.333333\n",
       "184479    133.333333\n",
       "211776    133.333333\n",
       "35380     133.333333\n",
       "136661    133.333333\n",
       "486833    133.333333\n",
       "228560    133.333333\n",
       "456458    125.000000\n",
       "288380    125.000000\n",
       "258338    125.000000\n",
       "400587    125.000000\n",
       "215024    125.000000\n",
       "81978     125.000000\n",
       "48123     125.000000\n",
       "216483    125.000000\n",
       "484382    125.000000\n",
       "195437    125.000000\n",
       "280337    125.000000\n",
       "389981    100.000000\n",
       "13725     100.000000\n",
       "455867    100.000000\n",
       "332910    100.000000\n",
       "71060     100.000000\n",
       "35932     100.000000\n",
       "418922    100.000000\n",
       "398228    100.000000\n",
       "257586    100.000000\n",
       "458442    100.000000\n",
       "106855    100.000000\n",
       "347724    100.000000\n",
       "470823    100.000000\n",
       "353291    100.000000\n",
       "158772    100.000000\n",
       "103595    100.000000\n",
       "457265    100.000000\n",
       "29990     100.000000\n",
       "454704    100.000000\n",
       "256054    100.000000\n",
       "286247    100.000000\n",
       "454691    100.000000\n",
       "372754    100.000000\n",
       "422628    100.000000\n",
       "372795    100.000000\n",
       "87373     100.000000\n",
       "30187     100.000000\n",
       "427150    100.000000\n",
       "160837    100.000000\n",
       "138846    100.000000\n",
       "242300    100.000000\n",
       "310894    100.000000\n",
       "285196    100.000000\n",
       "187633    100.000000\n",
       "405388    100.000000\n",
       "126292    100.000000\n",
       "70209     100.000000\n",
       "363211    100.000000\n",
       "215335    100.000000\n",
       "69401     100.000000\n",
       "294177    100.000000\n",
       "261011    100.000000\n",
       "278522    100.000000\n",
       "396734    100.000000\n",
       "155622    100.000000\n",
       "269421    100.000000\n",
       "40562     100.000000\n",
       "347490    100.000000\n",
       "7605      100.000000\n",
       "391369    100.000000\n",
       "30423     100.000000\n",
       "451236     83.333333\n",
       "219308     83.333333\n",
       "446393     83.333333\n",
       "485587     83.333333\n",
       "434975     83.333333\n",
       "206802     83.333333\n",
       "116391     83.333333\n",
       "306261     83.333333\n",
       "349243     83.333333\n",
       "445151     83.333333\n",
       "351935     80.000000\n",
       "233295     80.000000\n",
       "228967     80.000000\n",
       "97101      80.000000\n",
       "116881     75.000000\n",
       "467226     75.000000\n",
       "455728     75.000000\n",
       "416801     75.000000\n",
       "292051     75.000000\n",
       "314855     75.000000\n",
       "33592      75.000000\n",
       "241432     75.000000\n",
       "201233     75.000000\n",
       "378908     71.428571\n",
       "186711     71.428571\n",
       "34321      71.428571\n",
       "444529     71.428571\n",
       "379820     71.428571\n",
       "214139     71.428571\n",
       "345096     71.428571\n",
       "42831      71.428571\n",
       "150453     71.428571\n",
       "452081     71.428571\n",
       "112396     66.666667\n",
       "12561      66.666667\n",
       "428532     66.666667\n",
       "166380     66.666667\n",
       "466514     66.666667\n",
       "480748     66.666667\n",
       "60423      66.666667\n",
       "61186      66.666667\n",
       "432282     66.666667\n",
       "184687     66.666667\n",
       "205210     66.666667\n",
       "151093     66.666667\n",
       "247837     66.666667\n",
       "105383     66.666667\n",
       "50267      66.666667\n",
       "25381      66.666667\n",
       "382411     66.666667\n",
       "294199     66.666667\n",
       "85390      66.666667\n",
       "481154     66.666667\n",
       "275316     66.666667\n",
       "71334      66.666667\n",
       "269630     66.666667\n",
       "301891     62.500000\n",
       "71207      62.500000\n",
       "120256     62.500000\n",
       "             ...    \n",
       "380552      0.000000\n",
       "380547      0.000000\n",
       "380544      0.000000\n",
       "380539      0.000000\n",
       "135626      0.000000\n",
       "380533      0.000000\n",
       "380532      0.000000\n",
       "135629      0.000000\n",
       "380528      0.000000\n",
       "135643      0.000000\n",
       "136171      0.000000\n",
       "380058      0.000000\n",
       "136891      0.000000\n",
       "136697      0.000000\n",
       "379644      0.000000\n",
       "136666      0.000000\n",
       "379641      0.000000\n",
       "136669      0.000000\n",
       "136670      0.000000\n",
       "136674      0.000000\n",
       "379636      0.000000\n",
       "379632      0.000000\n",
       "379630      0.000000\n",
       "136681      0.000000\n",
       "379621      0.000000\n",
       "136696      0.000000\n",
       "379612      0.000000\n",
       "136665      0.000000\n",
       "136701      0.000000\n",
       "379610      0.000000\n",
       "136702      0.000000\n",
       "136703      0.000000\n",
       "136704      0.000000\n",
       "379606      0.000000\n",
       "136709      0.000000\n",
       "379602      0.000000\n",
       "379600      0.000000\n",
       "379590      0.000000\n",
       "136722      0.000000\n",
       "136724      0.000000\n",
       "379645      0.000000\n",
       "136664      0.000000\n",
       "379582      0.000000\n",
       "379694      0.000000\n",
       "136580      0.000000\n",
       "379722      0.000000\n",
       "136589      0.000000\n",
       "136597      0.000000\n",
       "136599      0.000000\n",
       "379710      0.000000\n",
       "136601      0.000000\n",
       "379706      0.000000\n",
       "379705      0.000000\n",
       "379703      0.000000\n",
       "136608      0.000000\n",
       "379695      0.000000\n",
       "136609      0.000000\n",
       "136663      0.000000\n",
       "379684      0.000000\n",
       "136614      0.000000\n",
       "136619      0.000000\n",
       "136620      0.000000\n",
       "379680      0.000000\n",
       "136625      0.000000\n",
       "136627      0.000000\n",
       "379669      0.000000\n",
       "379668      0.000000\n",
       "136650      0.000000\n",
       "379655      0.000000\n",
       "379653      0.000000\n",
       "379583      0.000000\n",
       "136728      0.000000\n",
       "380057      0.000000\n",
       "136854      0.000000\n",
       "379487      0.000000\n",
       "379485      0.000000\n",
       "136829      0.000000\n",
       "379482      0.000000\n",
       "379480      0.000000\n",
       "379475      0.000000\n",
       "136840      0.000000\n",
       "379469      0.000000\n",
       "379468      0.000000\n",
       "136851      0.000000\n",
       "136852      0.000000\n",
       "379462      0.000000\n",
       "136855      0.000000\n",
       "136826      0.000000\n",
       "379456      0.000000\n",
       "136857      0.000000\n",
       "136858      0.000000\n",
       "379451      0.000000\n",
       "136861      0.000000\n",
       "136864      0.000000\n",
       "136867      0.000000\n",
       "379444      0.000000\n",
       "136874      0.000000\n",
       "379439      0.000000\n",
       "136878      0.000000\n",
       "136879      0.000000\n",
       "136828      0.000000\n",
       "379498      0.000000\n",
       "379579      0.000000\n",
       "136768      0.000000\n",
       "136729      0.000000\n",
       "136737      0.000000\n",
       "379573      0.000000\n",
       "136745      0.000000\n",
       "136750      0.000000\n",
       "136752      0.000000\n",
       "136761      0.000000\n",
       "136763      0.000000\n",
       "379557      0.000000\n",
       "379554      0.000000\n",
       "379553      0.000000\n",
       "379551      0.000000\n",
       "136773      0.000000\n",
       "136814      0.000000\n",
       "136776      0.000000\n",
       "379540      0.000000\n",
       "379532      0.000000\n",
       "379527      0.000000\n",
       "136784      0.000000\n",
       "379519      0.000000\n",
       "136788      0.000000\n",
       "136789      0.000000\n",
       "379514      0.000000\n",
       "136790      0.000000\n",
       "379505      0.000000\n",
       "136809      0.000000\n",
       "379730      0.000000\n",
       "379732      0.000000\n",
       "379734      0.000000\n",
       "136350      0.000000\n",
       "136324      0.000000\n",
       "136326      0.000000\n",
       "136335      0.000000\n",
       "136337      0.000000\n",
       "379948      0.000000\n",
       "136338      0.000000\n",
       "379946      0.000000\n",
       "136345      0.000000\n",
       "379936      0.000000\n",
       "379932      0.000000\n",
       "379931      0.000000\n",
       "136348      0.000000\n",
       "379926      0.000000\n",
       "379957      0.000000\n",
       "136353      0.000000\n",
       "136354      0.000000\n",
       "136356      0.000000\n",
       "379917      0.000000\n",
       "136362      0.000000\n",
       "379914      0.000000\n",
       "136367      0.000000\n",
       "136369      0.000000\n",
       "379908      0.000000\n",
       "136370      0.000000\n",
       "379906      0.000000\n",
       "379897      0.000000\n",
       "379956      0.000000\n",
       "136316      0.000000\n",
       "136575      0.000000\n",
       "136239      0.000000\n",
       "136180      0.000000\n",
       "380053      0.000000\n",
       "380048      0.000000\n",
       "380041      0.000000\n",
       "136197      0.000000\n",
       "136216      0.000000\n",
       "380031      0.000000\n",
       "380028      0.000000\n",
       "136227      0.000000\n",
       "136232      0.000000\n",
       "136236      0.000000\n",
       "380017      0.000000\n",
       "136240      0.000000\n",
       "379974      0.000000\n",
       "136260      0.000000\n",
       "380003      0.000000\n",
       "136267      0.000000\n",
       "379997      0.000000\n",
       "136279      0.000000\n",
       "379993      0.000000\n",
       "136280      0.000000\n",
       "136281      0.000000\n",
       "136282      0.000000\n",
       "136286      0.000000\n",
       "379977      0.000000\n",
       "379976      0.000000\n",
       "379896      0.000000\n",
       "379895      0.000000\n",
       "136391      0.000000\n",
       "379782      0.000000\n",
       "136482      0.000000\n",
       "379812      0.000000\n",
       "379809      0.000000\n",
       "379808      0.000000\n",
       "136491      0.000000\n",
       "379804      0.000000\n",
       "136501      0.000000\n",
       "136507      0.000000\n",
       "379799      0.000000\n",
       "136511      0.000000\n",
       "136514      0.000000\n",
       "379785      0.000000\n",
       "379779      0.000000\n",
       "136400      0.000000\n",
       "136522      0.000000\n",
       "379777      0.000000\n",
       "379774      0.000000\n",
       "136524      0.000000\n",
       "379772      0.000000\n",
       "136525      0.000000\n",
       "136527      0.000000\n",
       "379758      0.000000\n",
       "136547      0.000000\n",
       "136551      0.000000\n",
       "379749      0.000000\n",
       "136570      0.000000\n",
       "136476      0.000000\n",
       "379821      0.000000\n",
       "379825      0.000000\n",
       "379826      0.000000\n",
       "136403      0.000000\n",
       "379874      0.000000\n",
       "136408      0.000000\n",
       "136417      0.000000\n",
       "136422      0.000000\n",
       "379865      0.000000\n",
       "136425      0.000000\n",
       "136429      0.000000\n",
       "136430      0.000000\n",
       "136434      0.000000\n",
       "136443      0.000000\n",
       "379857      0.000000\n",
       "379853      0.000000\n",
       "136450      0.000000\n",
       "379847      0.000000\n",
       "379844      0.000000\n",
       "379840      0.000000\n",
       "136464      0.000000\n",
       "379837      0.000000\n",
       "136466      0.000000\n",
       "136468      0.000000\n",
       "379834      0.000000\n",
       "379831      0.000000\n",
       "379828      0.000000\n",
       "379827      0.000000\n",
       "133509      0.000000\n",
       "Name: quantityModificationsPerEuro, Length: 498121, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values(by = \"quantityModificationsPerEuro\", ascending = False)['quantityModificationsPerEuro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 20)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger training set -> Pseudo Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easiest Way -> Apply rules found from Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "additional_no_frauds = test[test[\"trustLevel\"] > 2.5]\n",
    "additional_no_frauds = additional_no_frauds.assign(fraud = 0)\n",
    "\n",
    "additional_frauds = test[(test[\"trustLevel\"] < 1.5) &  (test[\"scannedLineItems\"] > 20.5) & (test[\"valuePerSecond\"] <= 0.118) & (test[\"scansWithoutRegistrationPerScannedLineItem\"] > 0.168)]\n",
    "additional_frauds = additional_frauds.assign(fraud = 1)\n",
    "\n",
    "\n",
    "train = pd.concat([train, additional_no_frauds], ignore_index=True)\n",
    "train = pd.concat([train, additional_frauds], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic Pseudo-Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class PseudoLabeler(BaseEstimator):\n",
    "    '''\n",
    "    Sci-kit learn wrapper for creating pseudo-lebeled estimators.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model, unlabled_data, features, target, sample_rate=0.2, seed=42):\n",
    "        '''\n",
    "        @sample_rate - percent of samples used as pseudo-labelled data\n",
    "                       from the unlabled dataset\n",
    "        '''\n",
    "        assert sample_rate <= 1.0, 'Sample_rate should be between 0.0 and 1.0.'\n",
    "        self.sample_rate = sample_rate\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.model.seed = seed\n",
    "        self.unlabled_data = unlabled_data\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def create_augmented_train(self, X, y):\n",
    "        '''\n",
    "        Create and return the augmented_train set that consists\n",
    "        of pseudo-labeled and labeled data.\n",
    "        '''        \n",
    "        num_of_samples = int(len(self.unlabled_data) * self.sample_rate)\n",
    "        \n",
    "        # Train the model and creat the pseudo-labels\n",
    "        self.model.fit(X, y)\n",
    "        pseudo_labels = self.model.predict(self.unlabled_data[self.features])\n",
    "        \n",
    "        # Add the pseudo-labels to the test set\n",
    "        pseudo_data = self.unlabled_data.copy(deep=True)\n",
    "        pseudo_data[self.target] = pseudo_labels\n",
    "        \n",
    "        # Take a subset of the test set with pseudo-labels and append in onto\n",
    "        # the training set\n",
    "        sampled_pseudo_data = pseudo_data.sample(n=num_of_samples)\n",
    "        temp_train = pd.concat([X, y], axis=1)\n",
    "        augemented_train = pd.concat([sampled_pseudo_data, temp_train])\n",
    "\n",
    "        return augemented_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop('fraud',axis=1).columns\n",
    "target = 'fraud'\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "PseudoLabelingModel = PseudoLabeler(\n",
    "    model = DecisionTreeClassifier(),\n",
    "    unlabled_data = test,\n",
    "    features = features,\n",
    "    target = target,\n",
    "    sample_rate = 0.001\n",
    ")\n",
    "\n",
    "train = PseudoLabelingModel.create_augmented_train(train.drop('fraud',axis=1),train['fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resulting fraud distribution of the new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3199\n",
      "1     174\n",
      "Name: fraud, dtype: int64\n",
      "0    0.948414\n",
      "1    0.051586\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.fraud.value_counts())\n",
    "print(train.fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    score = ((-25)*fp + (-5)*fn + 5*tp) / len(y_true)\n",
    "    return (score)\n",
    "\n",
    "my_custom_score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm.classes import OneClassSVM\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.linear_model.ridge import RidgeClassifierCV\n",
    "from sklearn.linear_model.ridge import RidgeClassifier\n",
    "from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier\n",
    "from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
    "from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.mixture import DPGMM\n",
    "#from sklearn.mixture import GMM\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "#from sklearn.mixture import VBGMM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "model_tuning_factory = [\n",
    "    GridSearchCV(LogisticRegression(max_iter = 10000), \n",
    "                 dict(# penalty = ['l1','l2'],  # automatic regularization  -> option 'l1' doesnt work with all solvers and leads to errors\n",
    "                     solver = ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "                     fit_intercept = [True, False]),\n",
    "                    #  solver = ['lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(KNeighborsClassifier(), \n",
    "                 dict(n_neighbors = range(1,4),\n",
    "                      weights = ['uniform', 'distance']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(NearestCentroid(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(DecisionTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(ExtraTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(ExtraTreesClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                      # n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    GridSearchCV(RandomForestClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    GridSearchCV(BernoulliNB(),\n",
    "                 dict(binarize  = np.arange(0.0, 2.0, 0.1)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(GaussianNB(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(AdaBoostClassifier(),\n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(GradientBoostingClassifier(),\n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 #     learning_rate = np.arange(0.01, 1.0, 0.01)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),                     \n",
    "    GridSearchCV(BaggingClassifier(), \n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(Perceptron(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(LinearDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(QuadraticDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(SVC(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score)\n",
    "]           \n",
    "                 \n",
    "                 \n",
    "iterations = 10                 \n",
    "               \n",
    "model_tuning_factory_randomized = [\n",
    "    RandomizedSearchCV(LogisticRegression(max_iter = 10000), \n",
    "                 dict(# penalty = ['l1','l2'],  # automatic regularization  -> option 'l1' doesnt work with all solvers and leads to errors\n",
    "                       solver = ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                       fit_intercept = [True, False]),\n",
    "                    #  solver = ['lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(KNeighborsClassifier(), \n",
    "                 dict(n_neighbors = range(1,4),\n",
    "                      weights = ['uniform', 'distance']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(NearestCentroid(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    RandomizedSearchCV(DecisionTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(ExtraTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(ExtraTreesClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini'],\n",
    "                      n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    RandomizedSearchCV(RandomForestClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini'],\n",
    "                      n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),    \n",
    "    RandomizedSearchCV(BernoulliNB(),\n",
    "                 dict(binarize  = np.arange(0.0, 1.0, 0.1)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations), \n",
    "    RandomizedSearchCV(GaussianNB(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    RandomizedSearchCV(AdaBoostClassifier(),\n",
    "                 dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                 dict(n_estimators = range(1,150),\n",
    "                      learning_rate = np.arange(0.01, 1.0, 0.01)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),                    \n",
    "    RandomizedSearchCV(BaggingClassifier(), \n",
    "                 dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(Perceptron(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(LinearDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(QuadraticDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(SVC(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['fraud']\n",
    "X = train.drop('fraud',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a smaller sample for quicker training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     104\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.055349\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.fraud.value_counts())\n",
    "print(train.fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "result_table = pd.DataFrame(columns=[\"Model\", \"Data Preparation\", \"Feature Count\", \"Features\", \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \"Monetary Value Per Instance - Standard Deviation\", \"Time needed\", \"Raw Model\"])\n",
    "\n",
    "\n",
    "# three types of data preparation: No preparation, MaxMinScaler, StandardScaler\n",
    "for data_preparation_step in range(1,4):\n",
    "    if (data_preparation_step == 1):  \n",
    "        X_scaled = X\n",
    "        data_preparation = \"No Scaling\"\n",
    "    elif (data_preparation_step == 2):\n",
    "        feature_scaler = MinMaxScaler()  \n",
    "        feature_scaler.fit_transform(X.values) \n",
    "        X_scaled = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index) \n",
    "        data_preparation = \"MinMaxScaler\"\n",
    "    elif (data_preparation_step == 3):\n",
    "        feature_scaler = StandardScaler()  \n",
    "        feature_scaler.fit_transform(X.values) \n",
    "        X_scaled = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index)\n",
    "        data_preparation = \"StandardScaler\"\n",
    "\n",
    "    for feature_count in range(1,len(list(X))+1):\n",
    "\n",
    "        for model in model_tuning_factory:   # replace with model_tuning_factory_randomized for faster results\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            best_features = SelectKBest(f_classif, k=feature_count).fit(X_scaled,Y)\n",
    "            best_feature_list = X.columns[best_features.get_support()]\n",
    "            X_selected_features = X[best_feature_list]\n",
    "            \n",
    "            model.seed = 42\n",
    "            model.fit(X_selected_features,Y)  \n",
    "            model_name = model.best_estimator_.__class__.__name__\n",
    "            score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "            score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(\"Finished \" + model.best_estimator_.__class__.__name__ + \" with \" + data_preparation + \" and \" + str(feature_count) + \" features after \" + str(end_time - start_time) + \" seconds\")\n",
    "\n",
    "            result_table = result_table.append({\n",
    "             \"Model\": model_name,\n",
    "             \"Data Preparation\": data_preparation,\n",
    "             \"Feature Count\": feature_count,\n",
    "             \"Features\": best_feature_list.values,\n",
    "             \"Optimal Parameters\": model.best_params_,\n",
    "             \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "             \"Monetary Value Per Instance - Standard Deviation\": score_std,\n",
    "             \"Time needed\": end_time - start_time,    \n",
    "             \"Raw Model\": model.best_estimator_\n",
    "              }, ignore_index=True)\n",
    "    \n",
    "result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the saved result table to avoid recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_table.to_pickle(\"result_table_extendec_training_set.pkl\")\n",
    "result_table = pd.read_pickle(\"result_table_extended_training_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)\n",
    "\n",
    "result_table.to_excel(\"Result-Train Set.xlsx\")\n",
    "\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table_aggregated = pd.DataFrame(columns=[\"Model\", \"Data Preparation\", \"Feature Count\", \"Features\", \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \"Monetary Value Per Instance - Standard Deviation\", \"Time needed\", \"Raw Model\"])\n",
    "\n",
    "\n",
    "for model in list(set(result_table[\"Model\"].values)):\n",
    "    sub_table = result_table[result_table[\"Model\"] == model]\n",
    "    result_table_aggregated = result_table_aggregated.append({\n",
    "        \"Model\": model,\n",
    "        \"Data Preparation\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Data Preparation\"],\n",
    "        \"Feature Count\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Feature Count\"],\n",
    "        \"Features\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Features\"],\n",
    "        \"Optimal Parameters\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Optimal Parameters\"],\n",
    "        \"Monetary Value Per Instance - Mean\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Monetary Value Per Instance - Mean\"],\n",
    "        \"Monetary Value Per Instance - Standard Deviation\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Monetary Value Per Instance - Standard Deviation\"],\n",
    "        \"Time needed\":  sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Time needed\"],\n",
    "        \"Raw Model\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Raw Model\"]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "result_table_aggregated.to_excel(\"Result-Train Set-Aggregated.xlsx\")\n",
    "\n",
    "result_table_aggregated.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = result_table_aggregated.loc[result_table_aggregated[\"Monetary Value Per Instance - Mean\"].argmax()][\"Raw Model\"]\n",
    "best_model_features = result_table_aggregated.loc[result_table_aggregated[\"Monetary Value Per Instance - Mean\"].argmax()][\"Features\"]\n",
    "\n",
    "print(best_model)\n",
    "print(best_model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_monetary_value(cm, y_holdout):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(\"True negative: \", tn)\n",
    "        print(\"False positive: \", fp)\n",
    "        print(\"False negative: \", fn)\n",
    "        print(\"True positive: \", tp)\n",
    "        score = (-25)*fp + (-5)*fn + 5*tp\n",
    "        print(score, 'for ', len(y_holdout), ' instances in the test set')\n",
    "        print(score/len(y_holdout), ' per instance in the test set')\n",
    "        return score\n",
    "    \n",
    "cm = confusion_matrix(Y , best_model.predict(X[best_model_features]))\n",
    "\n",
    "monetary_value = get_monetary_value(cm, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
