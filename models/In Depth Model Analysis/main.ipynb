{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:royalblue; font-size:3em\"> This serves as a baseline notebook to be imported by other notebooks </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../../data/train.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     104\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.055349\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.fraud.value_counts())\n",
    "print(train.fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['scannedLineItems'] = train['scannedLineItemsPerSecond'] * train['totalScanTimeInSeconds']\n",
    "train['pricePerScannedLineItem'] = train['grandTotal'] / train['scannedLineItems']\n",
    "train['scansWithoutRegistrationPerScannedLineItem'] = train['scansWithoutRegistration'] / train['scannedLineItems']\n",
    "train['quantityModificationsPerScannedLineItem'] = train['quantityModifications'] / train['scannedLineItems']\n",
    "train['lineItemVoidsPerSecond'] = train['lineItemVoids'] / train['totalScanTimeInSeconds']\n",
    "train['scansWithoutRegistrationPerSecond'] = train['scansWithoutRegistration'] / train['totalScanTimeInSeconds']\n",
    "train['quantityModificationsPerSecond'] = train['quantityModifications'] / train['totalScanTimeInSeconds']\n",
    "train['secondsPerEuro'] = train['totalScanTimeInSeconds'] / train['grandTotal']\n",
    "train['lineItemVoidsPerEuro'] = train['lineItemVoids'] / train['grandTotal']\n",
    "train['scansWithoutRegistrationPerEuro'] = train['scansWithoutRegistration'] / train['grandTotal']\n",
    "train['quantityModificationsPerEuro'] = train['quantityModifications'] / train['grandTotal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Cross validation\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Split *train* dataset to feature and target sets \n",
    "X = train.drop('fraud',axis=1)\n",
    "Y = train['fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    score = ((-25)*fp + (-5)*fn + 5*tp) / len(y_true)\n",
    "    return (score)\n",
    "\n",
    "my_custom_score = make_scorer(my_custom_loss_func, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to run loops for training and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "result_table = pd.DataFrame(columns=[\"Model\", \"Data Preparation\", \"Feature Count\", \"Features\", \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \"Monetary Value Per Instance - Standard Deviation\", \"Raw Model\"])\n",
    "model_name = ''\n",
    "\n",
    "def run():\n",
    "    global result_table, model_name\n",
    "    for data_preparation_strategy in range(1,5):\n",
    "        if (data_preparation_strategy == 1):  \n",
    "            X_scaled = X\n",
    "            data_preparation = \"No Scaling\"\n",
    "        elif (data_preparation_strategy == 2):\n",
    "            feature_scaler = MinMaxScaler()  \n",
    "            X_scaled = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index) \n",
    "            data_preparation = \"MinMaxScaler\"\n",
    "        elif (data_preparation_strategy == 3):\n",
    "            feature_scaler = StandardScaler()  \n",
    "            X_scaled = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index)\n",
    "            data_preparation = \"StandardScaler\"\n",
    "        elif (data_preparation_strategy == 4):\n",
    "            transformer = FunctionTransformer(np.log1p, validate=True)  \n",
    "            X_scaled = pd.DataFrame(transformer.transform(X), columns=X.columns, index=X.index)\n",
    "            data_preparation = \"LogScaler\"    \n",
    "        \n",
    "        for model in model_tuning_factory:   # replace with model_tuning_factory_randomized for faster results\n",
    "            model_name = model.estimator.__class__.__name__\n",
    "            \n",
    "            for feature_count in range(1,len(list(X))+1):\n",
    "\n",
    "                model.seed = 42\n",
    "                start_time = time.time()              \n",
    "\n",
    "\n",
    "                # Solution with SelectKBest\n",
    "                best_features = SelectKBest(f_classif, k=feature_count).fit(X_scaled,Y)\n",
    "                best_feature_list = X.columns[best_features.get_support()]\n",
    "                X_selected_features = X[best_feature_list]\n",
    "\n",
    "                model.fit(X_selected_features,Y)  \n",
    "                model_name = model.best_estimator_.__class__.__name__\n",
    "                score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "                score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "                result_table = result_table.append({\n",
    "                 \"Model\": model_name, \n",
    "                 \"Data Preparation\": data_preparation,   \n",
    "                 \"Feature Count\": feature_count,\n",
    "                 \"Feature Selection Technique\": \"SelectKBest\",   \n",
    "                 \"Features\": best_feature_list.values, \n",
    "                 \"Optimal Parameters\": model.best_params_,\n",
    "                 \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "                 \"Monetary Value Per Instance - Standard Deviation\": score_std,   \n",
    "                 \"Raw Model\": model.best_estimator_\n",
    "                  }, ignore_index=True)\n",
    "\n",
    "\n",
    "                # Solution with Recursive Feature Elimination -> only works for some models\n",
    "\n",
    "                if (model.estimator.__class__.__name__ == 'LogisticRegression'\n",
    "                 or model.estimator.__class__.__name__ == 'DecisionTreeClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'ExtraTreeClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'ExtraTreesClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'RandomForestClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'BernoulliNB'\n",
    "                 or model.estimator.__class__.__name__ == 'AdaBoostClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'GradientBoostingClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'Perceptron'\n",
    "                 or model.estimator.__class__.__name__ == 'LinearDiscriminantAnalysis'):\n",
    "\n",
    "                   # Traditional RFE\n",
    "                    rfe = RFE(model.estimator, n_features_to_select = feature_count)\n",
    "                    rfe = rfe.fit(X,Y)\n",
    "                    best_feature_list = np.array(list(X))[np.array(rfe.support_)]\n",
    "                    X_selected_features = X[best_feature_list]\n",
    "\n",
    "                    model.fit(X_selected_features,Y)  \n",
    "                    model_name = model.best_estimator_.__class__.__name__\n",
    "                    score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "                    score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "\n",
    "                    result_table = result_table.append({\n",
    "                     \"Model\": model_name, \n",
    "                     \"Data Preparation\": data_preparation,\n",
    "                     \"Feature Count\": feature_count,\n",
    "                     \"Feature Selection Technique\": \"RFE\",\n",
    "                     \"Features\": best_feature_list,\n",
    "                     \"Optimal Parameters\": model.best_params_,\n",
    "                     \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "                     \"Monetary Value Per Instance - Standard Deviation\": score_std,  \n",
    "                     \"Raw Model\": model.best_estimator_\n",
    "                      }, ignore_index=True)\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                print(\"Finished \" + model.best_estimator_.__class__.__name__ + \" with \" + data_preparation + \" and \" + str(feature_count) + \" features after \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "\n",
    "\n",
    "\n",
    "            if (model.estimator.__class__.__name__ == 'LogisticRegression'\n",
    "             or model.estimator.__class__.__name__ == 'DecisionTreeClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'ExtraTreeClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'ExtraTreesClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'RandomForestClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'BernoulliNB'\n",
    "             or model.estimator.__class__.__name__ == 'AdaBoostClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'GradientBoostingClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'Perceptron'\n",
    "             or model.estimator.__class__.__name__ == 'LinearDiscriminantAnalysis'):\n",
    "\n",
    "                # RFE with Cross Validation -> determines the optimum feature count automatically\n",
    "                rfecv = RFECV(model.estimator, cv = skf, scoring = my_custom_score)\n",
    "                rfecv = rfe.fit(X,Y)\n",
    "                best_feature_list = np.array(list(X))[np.array(rfecv.support_)]\n",
    "                X_selected_features = X[best_feature_list]\n",
    "\n",
    "                model.fit(X_selected_features,Y)  \n",
    "                model_name = model.best_estimator_.__class__.__name__\n",
    "                score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "                score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "\n",
    "                result_table = result_table.append({\n",
    "                 \"Model\": model_name,  \n",
    "                 \"Data Preparation\": data_preparation,\n",
    "                 \"Feature Count\": len(best_feature_list),\n",
    "                 \"Feature Selection Technique\": \"RFECV\",\n",
    "                 \"Features\": best_feature_list,\n",
    "                 \"Optimal Parameters\": model.best_params_,\n",
    "                 \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "                 \"Monetary Value Per Instance - Standard Deviation\": score_std,    \n",
    "                 \"Raw Model\": model.best_estimator_\n",
    "                  }, ignore_index=True)\n",
    "    \n",
    "    result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_it():\n",
    "    result_table.to_pickle(\"result_table_\" + str(model_name) + \".pkl\")\n",
    "    #result_table = pd.read_pickle(\"result_table_Random_Forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot number of features against monetary value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_number_features():\n",
    "    plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "    plt.scatter(result_table[\"Feature Count\"], result_table[\"Monetary Value Per Instance - Mean\"])\n",
    "    plt.xlabel('Number of features', fontsize=16)\n",
    "    plt.ylabel('Monetary Value Per Instance - Mean', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to store the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModel:\n",
    "    best_model = None\n",
    "    best_model_features = None\n",
    "    rank = 0\n",
    "    \n",
    "    def __init__(self, rank):\n",
    "        self.rank = rank\n",
    "    \n",
    "    def set(self):\n",
    "        global result_table\n",
    "        self.best_model = result_table.loc[self.rank,][\"Raw Model\"]\n",
    "        self.best_model_features = result_table.loc[self.rank,][\"Features\"]\n",
    "    \n",
    "    def predict(self):\n",
    "        self.set()\n",
    "        return self.best_model.predict(X[self.best_model_features])\n",
    "    \n",
    "    def print_best_model(self):\n",
    "        print(self.best_model)\n",
    "        print(self.best_model_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate performance of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monetary_value(best_model):\n",
    "        cm = confusion_matrix(Y , best_model.predict())\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        size = tn + fp + fn + tp\n",
    "        print(\"True negative: \", tn)\n",
    "        print(\"False positive: \", fp)\n",
    "        print(\"False negative: \", fn)\n",
    "        print(\"True positive: \", tp)\n",
    "        score = (-25)*fp + (-5)*fn + 5*tp\n",
    "        print(score, 'for ', size, ' instances in the test set')\n",
    "        print(score/size, ' per instance in the test set')\n",
    "        return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
