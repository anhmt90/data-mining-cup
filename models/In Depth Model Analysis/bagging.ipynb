{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     104\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.055349\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%run main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table for training results\n",
    "result_table = pd.DataFrame(columns=[\"Model\", \"Data Preparation\", \"Feature Count\", \"Features\", \n",
    "                                     \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \n",
    "                                     \"Monetary Value Per Instance - Standard Deviation\", \n",
    "                                     \"Time needed\", \"Raw Model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model factory -> only KNeighborsClassifier for in-depth analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-97a4042b6947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m model_tuning_factory = [\n\u001b[1;32m     50\u001b[0m     GridSearchCV(BaggingClassifier(DecisionTreeClassifier()), \n\u001b[0;32m---> 51\u001b[0;31m                  \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_bagging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                  ),\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, param_grid, scoring, fit_params, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[1;32m   1075\u001b[0m             return_train_score=return_train_score)\n\u001b[1;32m   1076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0m_check_param_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_param_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# model = {'model': BaggingClassifier,\n",
    "#          'kwargs': \n",
    "#              {'base_estimator': DecisionTreeClassifier(),\n",
    "              \n",
    "              \n",
    "#              },\n",
    "#          'parameters': {\n",
    "#              'name__base_estimator__max_leaf_nodes': [5,10,20,30]\n",
    "#          }}\n",
    "# pipeline = Pipeline([('name', model['model'](**model['kwargs']))])\n",
    "# cv_model = GridSearchCV(pipeline, param_grid=model['parameters'], cv=cv, scoring=scorer)\n",
    "\n",
    "\n",
    "param_bagging = {\n",
    "    #     'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False],    \n",
    "    'n_estimators': [5, 10, 25, 50, 100],\n",
    "    'max_samples': [0.2, 0.5, 0.8, 1.0],\n",
    "#     'warm_start': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "    'n_jobs' : 2,\n",
    "    'scoring' : 'my_custom_score',\n",
    "    'cv' : 'skf'\n",
    "}\n",
    "\n",
    "param_dt = {\n",
    "    'base_estimator__max_leaf_nodes': [5,10,20,30]\n",
    "}\n",
    "\n",
    "param_knn = {\n",
    "    'base_estimator__n_neighbors' : [1, 3, 5, 10, 15],\n",
    "    'base_estimator__weights' : ['uniform', 'distance'],\n",
    "    'base_estimator__p' : [1, 2, 3]\n",
    "}\n",
    "\n",
    "param_logistics = {\n",
    "    'base_estimator__solver' : ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "    'base_estimator__fit_intercept' : [True, False],\n",
    "    'base_estimator__C' : np.arange(0.1, 2.0, 0.1)\n",
    "}\n",
    "\n",
    "\n",
    "model_tuning_factory = [\n",
    "    GridSearchCV(BaggingClassifier(DecisionTreeClassifier()), \n",
    "                 param_grid = param_bagging.update(param_dt),\n",
    "                 ),\n",
    "    \n",
    "     GridSearchCV(BaggingClassifier(KNeighborsClassifier()), \n",
    "                 param_grid = param_bagging.update(param_knn),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score\n",
    "                 ),\n",
    "    \n",
    "    GridSearchCV(BaggingClassifier(LogisticRegression(max_iter = 100000)), \n",
    "                 param_grid = param_bagging.update(param_logistics),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score\n",
    "                 )\n",
    "]           \n",
    "                 \n",
    "                 \n",
    "# iterations = 10                 \n",
    "               \n",
    "# model_tuning_factory_randomized = [\n",
    "#     RandomizedSearchCV(BaggingClassifier(), \n",
    "#                  dict(n_estimators = range(1,150)),\n",
    "#                  cv = skf,\n",
    "#                  scoring = my_custom_score,\n",
    "#                  n_iter = iterations)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_table = result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)\n",
    "result_table.index = range(0,result_table.shape[0])\n",
    "result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print performance of best 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(0,11):\n",
    "    best = BestModel(rank)\n",
    "    monetary_value = get_monetary_value(best)\n",
    "    print()\n",
    "    best.print_best_model()\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
