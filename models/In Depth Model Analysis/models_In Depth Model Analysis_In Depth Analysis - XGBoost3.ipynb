{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "njobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv',sep='|')\n",
    "test=pd.read_csv('test.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     104\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.055349\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.fraud.value_counts())\n",
    "print(train.fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training set\n",
    "\n",
    "train['scannedLineItems'] = train['scannedLineItemsPerSecond'] * train['totalScanTimeInSeconds']\n",
    "train['pricePerScannedLineItem'] = train['grandTotal'] / train['scannedLineItems']\n",
    "train['scansWithoutRegistrationPerScannedLineItem'] = train['scansWithoutRegistration'] / train['scannedLineItems']\n",
    "train['quantityModificationsPerScannedLineItem'] = train['quantityModifications'] / train['scannedLineItems']\n",
    "train['lineItemVoidsPerSecond'] = train['lineItemVoids'] / train['totalScanTimeInSeconds']\n",
    "train['scansWithoutRegistrationPerSecond'] = train['scansWithoutRegistration'] / train['totalScanTimeInSeconds']\n",
    "train['quantityModificationsPerSecond'] = train['quantityModifications'] / train['totalScanTimeInSeconds']\n",
    "train['secondsPerEuro'] = train['totalScanTimeInSeconds'] / train['grandTotal']\n",
    "train['lineItemVoidsPerEuro'] = train['lineItemVoids'] / train['grandTotal']\n",
    "train['scansWithoutRegistrationPerEuro'] = train['scansWithoutRegistration'] / train['grandTotal']\n",
    "train['quantityModificationsPerEuro'] = train['quantityModifications'] / train['grandTotal']\n",
    "\n",
    "test['scannedLineItems'] = test['scannedLineItemsPerSecond'] * test['totalScanTimeInSeconds']\n",
    "test['pricePerScannedLineItem'] = test['grandTotal'] / test['scannedLineItems']\n",
    "test['scansWithoutRegistrationPerScannedLineItem'] = test['scansWithoutRegistration'] / test['scannedLineItems']\n",
    "test['quantityModificationsPerScannedLineItem'] = test['quantityModifications'] / test['scannedLineItems']\n",
    "test['lineItemVoidsPerSecond'] = test['lineItemVoids'] / test['totalScanTimeInSeconds']\n",
    "test['scansWithoutRegistrationPerSecond'] = test['scansWithoutRegistration'] / test['totalScanTimeInSeconds']\n",
    "test['quantityModificationsPerSecond'] = test['quantityModifications'] / test['totalScanTimeInSeconds']\n",
    "test['secondsPerEuro'] = test['totalScanTimeInSeconds'] / test['grandTotal']\n",
    "test['lineItemVoidsPerEuro'] = test['lineItemVoids'] / test['grandTotal']\n",
    "test['scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / test['grandTotal']\n",
    "test['quantityModificationsPerEuro'] = test['quantityModifications'] / test['grandTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['grandTotal'] == 0.00, 'secondsPerEuro'] = test['totalScanTimeInSeconds'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'lineItemVoidsPerEuro'] = test['lineItemVoids'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'quantityModificationsPerEuro'] = test['quantityModifications'] / 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add tSNE/PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_combined = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 20) (500000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_test_combined = train_test_combined.drop('fraud',axis=1)\n",
    "Y_train_test_combined = train_test_combined['fraud']\n",
    "print(X_train_test_combined.shape, Y_train_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer \n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "X_train_test_combined = pd.DataFrame(feature_scaler.fit_transform(X_train_test_combined.values), columns=X_train_test_combined.columns, index=X_train_test_combined.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.16124041 0.1559011  0.14737624 0.13509126 0.13197732 0.11312753\n",
      " 0.11161208]\n",
      "Cumulative explained variation for 7 principal components: 0.9563259397521083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train_test_combined_PCA = X_train_test_combined.copy()\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca_result = pca.fit_transform(X_train_test_combined_PCA)\n",
    "\n",
    "X_train_test_combined_PCA['pca-one'] = pca_result[:,0]\n",
    "X_train_test_combined_PCA['pca-two'] = pca_result[:,1] \n",
    "X_train_test_combined_PCA['pca-three'] = pca_result[:,2]\n",
    "\n",
    "X_train_test_combined_PCA['pca-one'] = pca_result[:,0]\n",
    "X_train_test_combined_PCA['pca-two'] = pca_result[:,1] \n",
    "X_train_test_combined_PCA['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Cumulative explained variation for 7 principal components: {}'.format(np.sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pca_axis_1'] = X_train_test_combined_PCA['pca-one'].head(len(train))\n",
    "train['pca_axis_2'] = X_train_test_combined_PCA['pca-two'].head(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test_combined_tSNE = X_train_test_combined.copy()\n",
    "tsne_results = pd.read_pickle(\"tsneResult.pkl\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test_combined_tSNE['tsne-one'] = tsne_results[:,0]\n",
    "X_train_test_combined_tSNE['tsne-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>lineItemVoidsPerEuro</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>lineItemVoidsPerSecond</th>\n",
       "      <th>pricePerScannedLineItem</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>quantityModificationsPerEuro</th>\n",
       "      <th>quantityModificationsPerScannedLineItem</th>\n",
       "      <th>quantityModificationsPerSecond</th>\n",
       "      <th>scannedLineItems</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>scansWithoutRegistrationPerEuro</th>\n",
       "      <th>scansWithoutRegistrationPerScannedLineItem</th>\n",
       "      <th>scansWithoutRegistrationPerSecond</th>\n",
       "      <th>secondsPerEuro</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>tsne-one</th>\n",
       "      <th>tsne-two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547055</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.575410</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.371124</td>\n",
       "      <td>2.065992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.273627</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.019545</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.413292</td>\n",
       "      <td>-0.542113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.621662</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.047820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>2.043197</td>\n",
       "      <td>-0.529174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923192</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.025078</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.031834</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.027586</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>1.375445</td>\n",
       "      <td>2.444786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.815382</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.234426</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>-0.579406</td>\n",
       "      <td>1.961413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grandTotal  lineItemVoids  lineItemVoidsPerEuro  lineItemVoidsPerPosition  lineItemVoidsPerSecond  pricePerScannedLineItem  quantityModifications  quantityModificationsPerEuro  quantityModificationsPerScannedLineItem  quantityModificationsPerSecond  scannedLineItems  scannedLineItemsPerSecond  scansWithoutRegistration  scansWithoutRegistrationPerEuro  scansWithoutRegistrationPerScannedLineItem  scansWithoutRegistrationPerSecond  secondsPerEuro  totalScanTimeInSeconds  trustLevel  valuePerSecond  tsne-one  tsne-two\n",
       "0    0.547055       0.636364              0.000116                  0.021944                0.000604                 0.018864                    0.6                      0.000110                                 0.020690                        0.000569          0.965517                   0.000899                       0.0                         0.000000                                    0.000000                           0.000000        0.000105                0.575410         0.8        0.000520  0.371124  2.065992\n",
       "1    0.273627       0.454545              0.000166                  0.032468                0.004209                 0.019545                    0.8                      0.000292                                 0.057143                        0.007407          0.448276                   0.004303                       0.2                         0.000073                                    0.014286                           0.001852        0.000022                0.058470         0.4        0.002541  1.413292 -0.542113\n",
       "2    0.621662       0.272727              0.000044                  0.020979                0.000180                 0.047820                    1.0                      0.000161                                 0.076923                        0.000660          0.413793                   0.000268                       1.0                         0.000161                                    0.076923                           0.000660        0.000133                0.827869         0.4        0.000411  2.043197 -0.529174\n",
       "3    0.923192       0.727273              0.000079                  0.025078                0.000406                 0.031834                    0.8                      0.000087                                 0.027586                        0.000447          0.965517                   0.000522                       0.4                         0.000043                                    0.013793                           0.000223        0.000106                0.978142         1.0        0.000517  1.375445  2.444786\n",
       "4    0.815382       0.272727              0.000033                  0.010101                0.000634                 0.030199                    0.4                      0.000049                                 0.014815                        0.000930          0.896552                   0.002075                       0.7                         0.000086                                    0.025926                           0.001628        0.000029                0.234426         0.8        0.001902 -0.579406  1.961413"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_test_combined_tSNE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tsne_axis_1'] = X_train_test_combined_tSNE['tsne-one'].head(len(train))\n",
    "train['tsne_axis_2'] = X_train_test_combined_tSNE['tsne-two'].head(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "      <th>scannedLineItems</th>\n",
       "      <th>pricePerScannedLineItem</th>\n",
       "      <th>scansWithoutRegistrationPerScannedLineItem</th>\n",
       "      <th>quantityModificationsPerScannedLineItem</th>\n",
       "      <th>lineItemVoidsPerSecond</th>\n",
       "      <th>scansWithoutRegistrationPerSecond</th>\n",
       "      <th>quantityModificationsPerSecond</th>\n",
       "      <th>secondsPerEuro</th>\n",
       "      <th>lineItemVoidsPerEuro</th>\n",
       "      <th>scansWithoutRegistrationPerEuro</th>\n",
       "      <th>quantityModificationsPerEuro</th>\n",
       "      <th>pca_axis_1</th>\n",
       "      <th>pca_axis_2</th>\n",
       "      <th>tsne_axis_1</th>\n",
       "      <th>tsne_axis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.886207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>19.268739</td>\n",
       "      <td>0.127971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>-0.106133</td>\n",
       "      <td>0.278145</td>\n",
       "      <td>0.371124</td>\n",
       "      <td>2.065992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.954286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>0.182749</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.146199</td>\n",
       "      <td>0.243599</td>\n",
       "      <td>-0.108150</td>\n",
       "      <td>1.413292</td>\n",
       "      <td>-0.542113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.781538</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>24.388674</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.160875</td>\n",
       "      <td>0.080438</td>\n",
       "      <td>0.502515</td>\n",
       "      <td>-0.100077</td>\n",
       "      <td>2.043197</td>\n",
       "      <td>-0.529174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.183103</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>19.402015</td>\n",
       "      <td>0.086665</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.122039</td>\n",
       "      <td>0.480733</td>\n",
       "      <td>1.375445</td>\n",
       "      <td>2.444786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.019630</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>5.274132</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.024531</td>\n",
       "      <td>-0.226498</td>\n",
       "      <td>0.289921</td>\n",
       "      <td>-0.579406</td>\n",
       "      <td>1.961413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.426538</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>69.431921</td>\n",
       "      <td>0.991885</td>\n",
       "      <td>0.450857</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>-0.212661</td>\n",
       "      <td>-0.509492</td>\n",
       "      <td>-0.656204</td>\n",
       "      <td>-2.447449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>294</td>\n",
       "      <td>55.63</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037415</td>\n",
       "      <td>0.189218</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.057273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>5.284918</td>\n",
       "      <td>0.035952</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.017976</td>\n",
       "      <td>-0.241190</td>\n",
       "      <td>-0.091522</td>\n",
       "      <td>-1.573847</td>\n",
       "      <td>-0.438576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1545</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>67.763158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.310786</td>\n",
       "      <td>-0.297834</td>\n",
       "      <td>1.287310</td>\n",
       "      <td>-1.474801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>962</td>\n",
       "      <td>65.44</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028067</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.423704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>14.700489</td>\n",
       "      <td>0.106968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>-0.263363</td>\n",
       "      <td>0.482789</td>\n",
       "      <td>-0.620175</td>\n",
       "      <td>2.505669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>725</td>\n",
       "      <td>41.08</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.521481</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>17.648491</td>\n",
       "      <td>0.243427</td>\n",
       "      <td>0.048685</td>\n",
       "      <td>0.097371</td>\n",
       "      <td>0.124496</td>\n",
       "      <td>-0.319390</td>\n",
       "      <td>1.443362</td>\n",
       "      <td>-1.942744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  fraud  scannedLineItems  pricePerScannedLineItem  scansWithoutRegistrationPerScannedLineItem  quantityModificationsPerScannedLineItem  lineItemVoidsPerSecond  scansWithoutRegistrationPerSecond  quantityModificationsPerSecond  secondsPerEuro  lineItemVoidsPerEuro  scansWithoutRegistrationPerEuro  quantityModificationsPerEuro  pca_axis_1  pca_axis_2  tsne_axis_1  tsne_axis_2\n",
       "0           5                    1054       54.70              7                         0                      3                   0.027514        0.051898                  0.241379      0              29.0                 1.886207                                    0.000000                                 0.103448                0.006641                           0.000000                        0.002846       19.268739              0.127971                         0.000000                      0.054845   -0.106133    0.278145     0.371124     2.065992\n",
       "1           3                     108       27.36              5                         2                      4                   0.129630        0.253333                  0.357143      0              14.0                 1.954286                                    0.142857                                 0.285714                0.046296                           0.018519                        0.037037        3.947368              0.182749                         0.073099                      0.146199    0.243599   -0.108150     1.413292    -0.542113\n",
       "2           3                    1516       62.16              3                        10                      5                   0.008575        0.041003                  0.230769      0              13.0                 4.781538                                    0.769231                                 0.384615                0.001979                           0.006596                        0.003298       24.388674              0.048263                         0.160875                      0.080438    0.502515   -0.100077     2.043197    -0.529174\n",
       "3           6                    1791       92.31              8                         4                      4                   0.016192        0.051541                  0.275862      0              29.0                 3.183103                                    0.137931                                 0.137931                0.004467                           0.002233                        0.002233       19.402015              0.086665                         0.043332                      0.043332    0.122039    0.480733     1.375445     2.444786\n",
       "4           5                     430       81.53              3                         7                      2                   0.062791        0.189605                  0.111111      0              27.0                 3.019630                                    0.259259                                 0.074074                0.006977                           0.016279                        0.004651        5.274132              0.036796                         0.085858                      0.024531   -0.226498    0.289921    -0.579406     1.961413\n",
       "5           1                     770       11.09             11                         5                      2                   0.033766        0.014403                  0.423077      1              26.0                 0.426538                                    0.192308                                 0.076923                0.014286                           0.006494                        0.002597       69.431921              0.991885                         0.450857                      0.180343   -0.212661   -0.509492    -0.656204    -2.447449\n",
       "6           3                     294       55.63              2                         7                      1                   0.037415        0.189218                  0.181818      0              11.0                 5.057273                                    0.636364                                 0.090909                0.006803                           0.023810                        0.003401        5.284918              0.035952                         0.125831                      0.017976   -0.241190   -0.091522    -1.573847    -0.438576\n",
       "7           2                    1545       22.80              0                         8                      4                   0.006472        0.014757                  0.000000      0              10.0                 2.280000                                    0.800000                                 0.400000                0.000000                           0.005178                        0.002589       67.763158              0.000000                         0.350877                      0.175439    0.310786   -0.297834     1.287310    -1.474801\n",
       "8           6                     962       65.44              7                         0                      2                   0.028067        0.068025                  0.259259      0              27.0                 2.423704                                    0.000000                                 0.074074                0.007277                           0.000000                        0.002079       14.700489              0.106968                         0.000000                      0.030562   -0.263363    0.482789    -0.620175     2.505669\n",
       "9           2                     725       41.08             10                         2                      4                   0.037241        0.056662                  0.370370      0              27.0                 1.521481                                    0.074074                                 0.148148                0.013793                           0.002759                        0.005517       17.648491              0.243427                         0.048685                      0.097371    0.124496   -0.319390     1.443362    -1.942744"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    score = ((-25)*fp + (-5)*fn + 5*tp) / len(y_true)\n",
    "    return (score)\n",
    "\n",
    "my_custom_score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monetary_value(cm):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(\"True negative: \", tn)\n",
    "        print(\"False positive: \", fp)\n",
    "        print(\"False negative: \", fn)\n",
    "        print(\"True positive: \", tp)\n",
    "        score = (-25)*fp + (-5)*fn + 5*tp\n",
    "        print(str(score) + \" for \" + str(sum(sum(cm))) + \" instances in the test set\")\n",
    "        print(str(score/sum(sum(cm))) + \" per instance in the test set\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic XGBoost Implementation with train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop('fraud', axis=1)\n",
    "y = train.fraud\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative:  440\n",
      "False positive:  2\n",
      "False negative:  8\n",
      "True positive:  20\n",
      "10 for 470 instances in the test set\n",
      "0.02127659574468085 per instance in the test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "predictors = [x for x in X.columns]\n",
    "clf = XGBClassifier(objective=\"binary:logistic\",\n",
    "                    random_state=42,\n",
    "                    max_depth=5,\n",
    "                    min_child_weight= 1,\n",
    "                    gamma = 0,\n",
    "                    subsample = 0.8,\n",
    "                    colsample_bytree = 0.8,\n",
    "                    scale_pos_weight = 1,\n",
    "                    n_jobs = 4\n",
    "                   )\n",
    "\n",
    "#modelfit(clf, train, predictors)\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "get_monetary_value(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 4,\n",
       " 'nthread': None,\n",
       " 'objective': 'binary:logistic',\n",
       " 'random_state': 42,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': None,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "paramset = dict(objective = ['binary:logistic'],\n",
    "                eval_metric = ['error'],\n",
    "                base_score = [0.3, 0.5, 0.7],\n",
    "                learning_rate = [0.01, 0.1, 0.2, 0.3],\n",
    "                max_depth = range(3,7),\n",
    "                min_child_weight = range(1,6),\n",
    "                #gamma = [i/10.0 for i in range(0,4)],\n",
    "                n_estimators = [100, 200, 300, 400, 500],\n",
    "                random_state = [42],\n",
    "                n_jobs = [-1],\n",
    "                max_delta_step = range(0,7) #usually not needed, might help because class is extremely imbalanced)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#less parameters (most important ones) for faster search\n",
    "paramset1 = dict(objective = ['binary:logistic'],\n",
    "                eval_metric = ['error'],\n",
    "                learning_rate = [0.1],\n",
    "                n_estimators = [140],\n",
    "                max_depth = range(3,10,2),\n",
    "                min_child_weight = range(1,6,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_tuning_factory = [\n",
    "    GridSearchCV(estimator = XGBClassifier(),\n",
    "                     param_grid = paramset,\n",
    "                     cv = skf,\n",
    "                     scoring = my_custom_score,\n",
    "                     n_jobs = -1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "iterations = 5                 \n",
    "               \n",
    "model_tuning_factory_randomized = [\n",
    "    RandomizedSearchCV(XGBClassifier(),\n",
    "                 paramset,\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['fraud']\n",
    "X = train.drop('fraud',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished XGBClassifier with No Scaling and 1 features after 33.39 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-e5ee198b7415>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mX_selected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_feature_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_selected_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mscore_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "result_table = pd.DataFrame(columns=[\"Model\", \"Data Preparation\", \"Feature Count\", \"Feature Selection Technique\", \"Features\", \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \"Monetary Value Per Instance - Standard Deviation\", \"Raw Model\"])\n",
    "X_scaled = X   \n",
    "data_preparation = \"No Scaling\"\n",
    "\n",
    "\n",
    "######### TODO: Feature Importance xgboost: get_fscore()\n",
    "for model in model_tuning_factory:   # replace with model_tuning_factory_randomized for faster results\n",
    "\n",
    "\n",
    "    for feature_count in range(1,len(list(X))+1):\n",
    "        \n",
    "        model.seed = 42\n",
    "        start_time = time.time()              \n",
    "\n",
    "\n",
    "        # Solution with SelectKBest\n",
    "        best_features = SelectKBest(f_classif, k=feature_count).fit(X_scaled,Y)\n",
    "        best_feature_list = X.columns[best_features.get_support()]\n",
    "        X_selected_features = X[best_feature_list]\n",
    "\n",
    "        model.fit(X_selected_features,Y)  \n",
    "        model_name = model.best_estimator_.__class__.__name__\n",
    "        score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "        score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "        result_table = result_table.append({\n",
    "         \"Model\": model_name, \n",
    "         \"Data Preparation\": data_preparation,   \n",
    "         \"Feature Count\": feature_count,\n",
    "         \"Feature Selection Technique\": \"SelectKBest\",   \n",
    "         \"Features\": best_feature_list.values, \n",
    "         \"Optimal Parameters\": model.best_params_,\n",
    "         \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "         \"Monetary Value Per Instance - Standard Deviation\": score_std,   \n",
    "         \"Raw Model\": model.best_estimator_\n",
    "          }, ignore_index=True)\n",
    "\n",
    "\n",
    "        # Solution with Recursive Feature Elimination -> only works for some models\n",
    "\n",
    "        if (model.estimator.__class__.__name__ == 'LogisticRegression'\n",
    "         or model.estimator.__class__.__name__ == 'DecisionTreeClassifier'\n",
    "         or model.estimator.__class__.__name__ == 'ExtraTreeClassifier'\n",
    "         or model.estimator.__class__.__name__ == 'ExtraTreesClassifier'\n",
    "         or model.estimator.__class__.__name__ == 'RandomForestClassifier'\n",
    "         or model.estimator.__class__.__name__ == 'BernoulliNB'\n",
    "         or model.estimator.__class__.__name__ == 'AdaBoostClassifier'\n",
    "         or model.estimator.__class__.__name__ == 'GradientBoostingClassifier'\n",
    "         or model.estimator.__class__.__name__ == 'Perceptron'\n",
    "         or model.estimator.__class__.__name__ == 'LinearDiscriminantAnalysis'\n",
    "         or model.estimator.__class__.__name__ == 'XGBClassifier'):\n",
    "\n",
    "           # Traditional RFE\n",
    "            rfe = RFE(model.estimator, n_features_to_select = feature_count)\n",
    "            rfe = rfe.fit(X,Y)\n",
    "            best_feature_list = np.array(list(X))[np.array(rfe.support_)]\n",
    "            X_selected_features = X[best_feature_list]\n",
    "\n",
    "            model.fit(X_selected_features,Y)  \n",
    "            model_name = model.best_estimator_.__class__.__name__\n",
    "            score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "            score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "\n",
    "            result_table = result_table.append({\n",
    "             \"Model\": model_name, \n",
    "             \"Data Preparation\": data_preparation,\n",
    "             \"Feature Count\": feature_count,\n",
    "             \"Feature Selection Technique\": \"RFE\",\n",
    "             \"Features\": best_feature_list,\n",
    "             \"Optimal Parameters\": model.best_params_,\n",
    "             \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "             \"Monetary Value Per Instance - Standard Deviation\": score_std,  \n",
    "             \"Raw Model\": model.best_estimator_\n",
    "              }, ignore_index=True)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(\"Finished \" + model.best_estimator_.__class__.__name__ + \" with \" + data_preparation + \" and \" + str(feature_count) + \" features after \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "\n",
    "\n",
    "\n",
    "    if (model.estimator.__class__.__name__ == 'LogisticRegression'\n",
    "     or model.estimator.__class__.__name__ == 'DecisionTreeClassifier'\n",
    "     or model.estimator.__class__.__name__ == 'ExtraTreeClassifier'\n",
    "     or model.estimator.__class__.__name__ == 'ExtraTreesClassifier'\n",
    "     or model.estimator.__class__.__name__ == 'RandomForestClassifier'\n",
    "     or model.estimator.__class__.__name__ == 'BernoulliNB'\n",
    "     or model.estimator.__class__.__name__ == 'AdaBoostClassifier'\n",
    "     or model.estimator.__class__.__name__ == 'GradientBoostingClassifier'\n",
    "     or model.estimator.__class__.__name__ == 'Perceptron'\n",
    "     or model.estimator.__class__.__name__ == 'LinearDiscriminantAnalysis'\n",
    "     or model.estimator.__class__.__name__ == 'XGBClassifier'):\n",
    "\n",
    "        # RFE with Cross Validation -> determines the optimum feature count automatically\n",
    "        rfecv = RFECV(model.estimator, cv = skf, scoring = my_custom_score)\n",
    "        rfecv = rfe.fit(X,Y)\n",
    "        best_feature_list = np.array(list(X))[np.array(rfecv.support_)]\n",
    "        X_selected_features = X[best_feature_list]\n",
    "\n",
    "        model.fit(X_selected_features,Y)  \n",
    "        model_name = model.best_estimator_.__class__.__name__\n",
    "        score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "        score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "\n",
    "        result_table = result_table.append({\n",
    "         \"Model\": model_name,  \n",
    "         \"Data Preparation\": data_preparation,\n",
    "         \"Feature Count\": len(best_feature_list),\n",
    "         \"Feature Selection Technique\": \"RFECV\",\n",
    "         \"Features\": best_feature_list,\n",
    "         \"Optimal Parameters\": model.best_params_,\n",
    "         \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "         \"Monetary Value Per Instance - Standard Deviation\": score_std,    \n",
    "         \"Raw Model\": model.best_estimator_\n",
    "          }, ignore_index=True)\n",
    "\n",
    "\n",
    "result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data Preparation</th>\n",
       "      <th>Feature Count</th>\n",
       "      <th>Feature Selection Technique</th>\n",
       "      <th>Features</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Monetary Value Per Instance - Mean</th>\n",
       "      <th>Monetary Value Per Instance - Standard Deviation</th>\n",
       "      <th>Raw Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, lineItemVoids, scansW...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.154337</td>\n",
       "      <td>0.096457</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>23</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.112608</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.089899</td>\n",
       "      <td>XGBClassifier(base_score=0.3, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, lineItemVoids, scansW...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.113070</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115559</td>\n",
       "      <td>XGBClassifier(base_score=0.3, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>21</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.141032</td>\n",
       "      <td>0.107112</td>\n",
       "      <td>XGBClassifier(base_score=0.3, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>23</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.135710</td>\n",
       "      <td>0.083595</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.133049</td>\n",
       "      <td>0.102993</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.133049</td>\n",
       "      <td>0.095945</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.133049</td>\n",
       "      <td>0.095837</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.130389</td>\n",
       "      <td>0.119266</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.127728</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>0.103188</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>23</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>0.100524</td>\n",
       "      <td>XGBClassifier(base_score=0.3, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>21</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.117084</td>\n",
       "      <td>0.123061</td>\n",
       "      <td>XGBClassifier(base_score=0.3, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.137834</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.134684</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scansWithoutRegistrat...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>0.037254</td>\n",
       "      <td>0.204257</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, valuePerSecond, scann...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.015966</td>\n",
       "      <td>0.248609</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.050559</td>\n",
       "      <td>0.223998</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.055881</td>\n",
       "      <td>0.200991</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pca_axis_2, tsne_axis_2]</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.180947</td>\n",
       "      <td>0.237439</td>\n",
       "      <td>XGBClassifier(base_score=0.7, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[tsne_axis_2]</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.290048</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>XGBClassifier(base_score=0.3, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[tsne_axis_2]</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.460351</td>\n",
       "      <td>0.249626</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, pca_axis_2, tsne_axis_2]</td>\n",
       "      <td>{'random_state': 42, 'objective': 'binary:logi...</td>\n",
       "      <td>-0.508249</td>\n",
       "      <td>0.186772</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Data Preparation Feature Count Feature Selection Technique                                           Features                                 Optimal Parameters  Monetary Value Per Instance - Mean  Monetary Value Per Instance - Standard Deviation                                          Raw Model\n",
       "9   XGBClassifier       No Scaling             9                         RFE  [totalScanTimeInSeconds, lineItemVoids, scansW...  {'random_state': 42, 'objective': 'binary:logi...                            0.154337                                          0.096457  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "24  XGBClassifier       No Scaling            23                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'random_state': 42, 'objective': 'binary:logi...                            0.151676                                          0.112608  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "15  XGBClassifier       No Scaling            15                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.149015                                          0.089899  XGBClassifier(base_score=0.3, booster='gbtree'...\n",
       "11  XGBClassifier       No Scaling            11                         RFE  [totalScanTimeInSeconds, lineItemVoids, scansW...  {'random_state': 42, 'objective': 'binary:logi...                            0.143693                                          0.113070  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "10  XGBClassifier       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'random_state': 42, 'objective': 'binary:logi...                            0.143693                                          0.115559  XGBClassifier(base_score=0.3, booster='gbtree'...\n",
       "20  XGBClassifier       No Scaling            21                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.141032                                          0.107112  XGBClassifier(base_score=0.3, booster='gbtree'...\n",
       "23  XGBClassifier       No Scaling            23                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'random_state': 42, 'objective': 'binary:logi...                            0.135710                                          0.083595  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "19  XGBClassifier       No Scaling            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'random_state': 42, 'objective': 'binary:logi...                            0.133049                                          0.102993  XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "16  XGBClassifier       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.133049                                          0.095945  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "14  XGBClassifier       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.133049                                          0.095837  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "8   XGBClassifier       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.130389                                          0.119266  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "12  XGBClassifier       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.127728                                          0.107077  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "18  XGBClassifier       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.119745                                          0.103188  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "22  XGBClassifier       No Scaling            23                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'random_state': 42, 'objective': 'binary:logi...                            0.119745                                          0.100524  XGBClassifier(base_score=0.3, booster='gbtree'...\n",
       "21  XGBClassifier       No Scaling            21                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'random_state': 42, 'objective': 'binary:logi...                            0.117084                                          0.123061  XGBClassifier(base_score=0.3, booster='gbtree'...\n",
       "13  XGBClassifier       No Scaling            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.098457                                          0.137834  XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "17  XGBClassifier       No Scaling            17                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'random_state': 42, 'objective': 'binary:logi...                            0.074508                                          0.134684  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "7   XGBClassifier       No Scaling             7                         RFE  [totalScanTimeInSeconds, scansWithoutRegistrat...  {'random_state': 42, 'objective': 'binary:logi...                            0.037254                                          0.204257  XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "5   XGBClassifier       No Scaling             5                         RFE  [totalScanTimeInSeconds, valuePerSecond, scann...  {'random_state': 42, 'objective': 'binary:logi...                           -0.015966                                          0.248609  XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "4   XGBClassifier       No Scaling             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...  {'random_state': 42, 'objective': 'binary:logi...                           -0.050559                                          0.223998  XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "6   XGBClassifier       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...  {'random_state': 42, 'objective': 'binary:logi...                           -0.055881                                          0.200991  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "3   XGBClassifier       No Scaling             3                         RFE        [scannedLineItems, pca_axis_2, tsne_axis_2]  {'random_state': 42, 'objective': 'binary:logi...                           -0.180947                                          0.237439  XGBClassifier(base_score=0.7, booster='gbtree'...\n",
       "1   XGBClassifier       No Scaling             1                         RFE                                      [tsne_axis_2]  {'random_state': 42, 'objective': 'binary:logi...                           -0.290048                                          0.038596  XGBClassifier(base_score=0.3, booster='gbtree'...\n",
       "0   XGBClassifier       No Scaling             1                 SelectKBest                                      [tsne_axis_2]  {'random_state': 42, 'objective': 'binary:logi...                           -0.460351                                          0.249626  XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "2   XGBClassifier       No Scaling             3                 SelectKBest              [trustLevel, pca_axis_2, tsne_axis_2]  {'random_state': 42, 'objective': 'binary:logi...                           -0.508249                                          0.186772  XGBClassifier(base_score=0.5, booster='gbtree'..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.to_pickle(\"result_table_xgb_classifier_indepth3.pkl\")\n",
    "# result_table = pd.read_pickle(\"result_table_Decision_Tree.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Monetary Value Per Instance - Mean')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAJVCAYAAABahxgbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYXFWd//H31xCkcZmwQyIICmZwz0y7oqgjGLefRBzFPTg6yDjuY8Zk3BAXonEdd8QFUdxjzIxoVJBxF4NhDKiRVaA7LCLtMrYQwvf3x72Nnaaq+hZd2+1+v56nnqq653bVt7vo8Olz7jknMhNJkiTVz+36XYAkSZJuG4OcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqqZ36XUAv7LnnnnnggQf2uwxJkqRpnXvuub/NzL2qnDsngtyBBx7Ixo0b+12GJEnStCLiN1XPdWhVkiSppgxykiRJNWWQkyRJqimDnCRJUk0Z5CRJkmrKICdJklRTBjlJkqSaMshJkiTVlEFOkiSppgxykiRJNWWQkyRJqimDnCRJUk0Z5CRJkmrKICdJklRTBjlJkqSaMshJkiTVlEFOkiSppgxykiRJNWWQkyRJqimDnCRJUk0Z5CRJkmrKICdJklRTBjlJkqSaMshJkiTV1E79LkDSYFu3aYQ1G7YwOjbOwgVDrFi6mGVLFvW7LEkSBjlJLazbNMKqtZsZ37YdgJGxcVat3QxgmJOkAWCQk9TUmg1bbglxE8a3bWfNhi0GOUlzyqCOThjkJDU1Ojbe1nFJmo0GeXTCyQ6Smlq4YKit45rb1m0a4bDVZ3HQyq9x2OqzWLdppN8lSR3RanSi3wxykppasXQxQ/Pn7XBsaP48Vixd3KeKNKgmeixGxsZJ/tpjYZjTbDDIoxMGOUlNLVuyiJOOvg+LFgwRwKIFQ5x09H36PpSgwTPIPRbSTA3y6ITXyElqadmSRQY3TWuQeyykmVqxdPEO18jB4IxOGOQkzUqvXbeZz/7kCrZnMi+CZzxof9687D79LmvWWrhgiJEGoW0QeiykmZr4Y9ZZq5LUA69dt5lP//jyW55vz7zluWGuOwa5x0LqhEEdnfAaOUmzzmd/ckVbxzVzXk+pqpzd3Fn2yEmadbZntnVcnTGoPRYaHIO8Hltd2SMnadaZF9HWcUm94ezmzjPISZp1nvGg/ds6Lqk3nN3ceQ6tSpp1JiY0OGtVGix1nt08qHutRs6Ba0aGh4dz48aN/S5DkqQ5beo1clDMbh70iTG9rjsizs3M4Srn2iMnSeqIQe2xmI51984gr8fWSqtr+/pdu0FOkjRjdZ2NaN29V8fZzYN8bZ+THSS15JpPqqKusxGtW1UM8l6rBjlJTU381T8yNk7y17/6DXPdU9fgPMg9Fq1Yt6pYsXQxQ/Pn7XBsUHYuMchJasq/+nurzsF5kHssWrFuVTHIO5cY5CQ15V/9vVXn4DzIPRatWLeqWrZkET9Y+Q9cuvoJ/GDlPwxEiAMnO0hqoc5rPtVRnYNzXWcjWrfqziAnqakVSxc3XDvJv/q7o+7BuY6zEcG6VW8OrUpqapCvC5mNHC6T1C575CS15F/9veNwmdpRxwWB62xQf94GOUkaIAZnVVHnBYHraJB/3g6tSpJUM3We4VzHtRIH+edtj5wkSTVT1xnOg9yz1cog/7ztkZMkqWbquiDwIPdstTLIP2+DnCRJNVPXGc6D3LPVyiD/vB1alSSpZuo6w7muayUO8s87MrPfNXTd8PBwbty4sd9lSJI0p029Rg6Kni3Xp9xRRJybmcNVzrVHTpIk9cQg92zVlUFOkiT1jGsldpaTHSRJkmrKICdJklRTBjlJkqSaMshJkiTV1MAFuYh4bERsiYiLImJlg/bDI+JnEXFTRPxjP2qUJEkaBAMV5CJiHvAB4HHAPYFnRMQ9p5x2OXAscHpvq5MkSRosg7b8yAOBizLzEoCI+BxwFPCLiRMy87Ky7eZ+FChJ3bRu04hrbEmqbNCC3CLgiknPrwQe1KdaJKmnpq56PzI2zqq1mwEMc5IaGqihVSAaHLtNe4hFxHERsTEiNl577bUzLEuSum/Nhi07bF0EML5tO2s2bOlTRZIG3aAFuSuB/Sc9vwswelteKDNPzszhzBzea6+9OlKcJHXTaIPNxFsdl6RBC3I/BQ6JiIMiYmfg6cD6PtckST2xcMFQW8claaCCXGbeBLwY2AD8EvhCZl4QESdGxJMAIuIBEXEl8FTgIxFxQf8qlqTOWbF0MUPz5+1wbGj+PFYsXdyniiQNukGb7EBmngGcMeXY6yc9/inFkKskzSoTExqctSqpqoELcpI0ly1bssjgJqmygRpalSRJUnUGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJpyiy5J0py2btOI+9uqtgxykqQ5a92mEVat3cz4tu0AjIyNs2rtZgDDnGrBoVVJ0py1ZsOWW0LchPFt21mzYUufKpLaY5CTJM1Zo2PjbR2XBo1BTpI0Zy1cMNTWcWnQGOQkSXPWiqWLGZo/b4djQ/PnsWLp4j5VJLXHyQ6SpDlrYkKDs1ZVVwY5SdKctmzJIoObasuhVUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmdup3AdJcsW7TCGs2bGF0bJyFC4ZYsXQxy5Ys6ndZkqQaM8hJPbBu0wir1m5mfNt2AEbGxlm1djOAYU6SdJs5tCr1wJoNW24JcRPGt21nzYYtfapIkjQbGOSkHhgdG2/ruCRJVRjkpB5YuGCoreOSJFVhkJN6YMXSxQzNn7fDsaH581ixdHGfKpIkzQZOdpB6YGJCg7NWJUmdZJCTemTZkkUGN0lSRzm0KkmSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFOVglxEzI+I10TE+RHxh4i4ccrthm4XKkmSpB1V3aLr7cBLgW8CZwAGN0mSpD6rGuSeBpyQmW/qZjGSJEmqruo1cncEftDNQiRJktSeqkHua8DDulmIJEmS2lN1aPVdwKcj4iaKa+R+N/WEzLy8k4VJkiSptapB7pzy/s1As+vk5s28HEmSJFVVNcgdB2Q3C5EkSVJ7KgW5zDyl24VIkiSpPe7sIEmSVFNVh1aJiD2BY4DFwC5TmjMzX9iJgiLiscB7Ka65OyUzV09pvz3wKeDvgeuAYzLzsk68tyRJUp1UCnIRcQ/gRxQBbhfgemABRY/e74E/dqKYiJgHfAA4ErgS+GlErM/MX0w67fnA9Zl5cEQ8HXgbRcCUJEmaU6oOra4BfgbsBQTwGOAOwPEUIe4JHarngcBFmXlJZt4IfA44aso5RwGnlo+/BDw6IqJD7y9JklQbVYPcAyh6yv4y8XWZeUNmngx8EHhPh+pZBFwx6fmV5bGG52TmTRQ9gntMfaGIOC4iNkbExmuvvbZD5UmSJA2OqkHuzsB1mXkz8Adgz0lt5wAP6lA9jXrWpi57UuUcMvPkzBzOzOG99tqrI8VJkiQNkqpB7jJgn/LxFuApk9oeB4x1qJ4rgf0nPb8LMNrsnIjYCfgbGuw0IUmSNNtVDXLfBo4oH78beH5EXBAR/wu8Evhkh+r5KXBIRBwUETsDTwfWTzlnPbC8fPyPwFmZ6WLFkiRpzqm6/MhKYAggMz8XETdQzBTdFfgI8OFOFJOZN0XEi4ENFMuPfDwzL4iIE4GNmbke+BhwWkRcRNET9/ROvLckSVLdxFzozBoeHs6NGzf2uwxJkqRpRcS5mTlc5dzKCwKXL7wbxcSGPYAzMvP6iJifmdtuQ52SJEmagcpbdEXESRQTD86g2FnhoLLpaxHx2i7UJkmSpBYqBbmIeDXwCuAk4DB2XALkv+jcgsCSJEmqqOrQ6nHAmzLzLeU2WpNdCBzc2bKk5tZtGmHNhi2Mjo2zcMEQK5YuZtmSqetGS5I0+1UNcncBftik7Ubgjp0pR2pt3aYRVq3dzPi27QCMjI2zau1mAMOcJGnOqXqN3ChwryZt96FYMFjqujUbttwS4iaMb9vOmg1b+lSRJEn9UzXIfQl4fURM3oorI+LuwKuAz3e8MqmB0bHxto5LkjSbVQ1yJwAXUQyv/rI89jngfOBSikkQUtctXDDU1nFJkmazSkEuM/8POBx4AfAz4Gzg58CLgUdn5g3dKlCabMXSxQzN33G+zdD8eaxYurhPFUmS1D+VFwTOzJuAT5Q3qS8mJjQ4a1WSpDZ3dpAGwbIliwxukiTRIshFxFltvE5m5qM7UI8kSZIqatUj90jgDxTXwkWL8yRJktQHrYLcD4GHAnsDpwGnZeblPalKkiRJ02o6azUzHwbcHfgscCxwSUR8JyKOjQh3cpAkSeqzlsuPZOalmfnGzDyEYqj1QuBdwFUR8emIeGgPapQkSVIDVRcEJjO/n5nHAfsB7wGeTrGrgyRJkvqg8vIjEbEP8CzgOcD9gHOB07tUlyRJkqbRMshFxBDwZIrwdiQwCnwGeGZm/rLV10qSJKm7Wq0j90ng6PLpWmApcFZmZg/qkiRJ0jRa9cg9l2IduQ3AzRTDqs+KaLikXGbm8ztfniRJkpppFeRGgaRYS2469tJJkiT1WNMgl5l36WUhkiRJak/l5UckSZI0WAxykiRJNWWQkyRJqimDnCRJUk0Z5CRJkmqq8hZd0qBYt2mENRu2MDo2zsIFQ6xYuphlSxb1uyxJknqu7R65KJwcEft3oyCplXWbRli1djMjY+MkMDI2zqq1m1m3aaTfpUmS1HO3ZWj1dsDzgb06XIs0rTUbtjC+bfsOx8a3bWfNhi19qkiSpP65rdfINdynS+q20bHxto5LkjSbeY2camXhgiFGGoS2hQuG+lBNe7y2T5LUabelR+5m4DPAdR2uRZrWiqWLGZo/b4djQ/PnsWLp4j5VVI3X9kmSuqHtIJeF52Tmb7pRkNTKsiWLOOno+7BowRABLFowxElH32fge7a8tk+S1A0Orap2li1ZNPDBbSqv7ZMkdYMLAks90Owavjpc2ydJGlwGOakH6nptnyRpsDm0KvXAxFCws1YlSZ1kkJN6pI7X9kmSBltbQ6sR8fiIWB0RH42IA8pjh0XEvt0pT5IkSc1U6pGLiL8BvgY8FPgzMAR8CLgceBHwW+BlXapRkiRJDVTtkVsD3A14BLCAHbfo+hbw6A7XJUmSpGlUDXLLgP/IzO8BOaXtcmD/jlYlSZKkaVUNcncCrmzSdntgXpM2SZIkdUnVIPdr4IgmbYcDmztTjiRJkqqquvzIh4D/jIjrgdPLY3eKiOcALwH+pRvFSZIkqblKQS4zPxwRBwNvAd5aHj6L4nq5d2bmaV2qT5IkSU1UXhA4M18VER8EHgPsDVwHfDMzL+xWcZIkSWqurZ0dMvMS4MNdqkWSJEltqDTZISKeGxGva9L2uvJaOUmSJPVQ1VmrrwR+36TteuAVnSlHkiRJVVUNcgcD5zdpu6BslyRJUg9VDXLbgT2btO3Jjlt2SZIkqQeqBrlzgOOatL0Q+GlnypEkSVJVVWetvhX4VkT8ADgFGAEWAS8AHggs7U55kiRJaqbqgsDfiYhjgHcDH5vUdAXwtMw8qxvFSZIkqbl2FgT+ckSsBe4J7AH8FvhlZma3ipMkSVJz7S4InBSzVCVJktRnlYNcRNwReCxwALDLlObMzJM6WZgkSZJaqxTkIuIhwH8Buzc5JQGDnCRJUg9VXX7kvcCVwEOAOwLzp9x27kp1kiRJaqrq0Oo9gWMy8yfdLEaSJEnVVe2RuwJ73SRJkgZK1SD3JuDfywkPXRERu0fEtyLiwvJ+tybnfSMixiLiv7tViyRJUh1UHVo9EtgPuLTc3eF3U9ozM58/w1pWAmdm5uqIWFk+f3WD89YAu1JsDSZJkjRnVQ1yR5T3fwH+vkF7JxYFPgp4ZPn4VOBsGgS5zDwzIh459bgkSdJcU3WLrv27XQiwT2ZuLd9va0Ts3YP3lCRJqq22dnaYqYj4NrBvg6bXdOG9jgOOAzjggAM6/fKSJEl913aQi4jdufXODmTm6HRfm5lHNGuLiKsjYr+yN24/4Jp2a5vyXicDJwMMDw+7H6wkSZp1Ks1ajYjbRcSJEXENcC3FciRTbzO1HlhePl4OfLUDrylJkjRrVV1+5CXAy4H3AwG8DVgNXA5cDBzfgVpWA0dGxIUUs2RXA0TEcEScMnFSRHwP+CLw6Ii4MiKWduC9JUmSaicypx91jIjNFDNJ3w1sA4Yz82cRsTPwLYplQ07saqUzMDw8nBs3bux3GZIkSdOKiHMzc7jKuVV75A4CfpqZ24HtlNfIZeaNFOFupmvISZIkqU1Vg9wf+OsEh1Fg8aS2APboZFGSJEmaXtVZq+cBfwtsAL4JnBARfwJuoriWbVN3ypMkSVIzVYPce4G7lY9fT7G7w+fL51dSTIaQJElSD1Xd2WHDpMdbI2IYuAfFnqcXZOYNXapPkiRJTVRdR+6Z5ULAAGTmzZn5q8z8GbBrRDyzaxVKkiSpoaqTHU4DDm7SdreyXZIkST1UNchFi7ZdKSY9SJIkqYeaXiMXEfcF7j/p0OMj4m+nnDYEPAO4qAu1SZIkqYVWkx2eDLyhfJwUs1UbGcMFgSVJknquVZD7T+DTFMOqvwaeSrGe3GQ3AKOZeXN3ypMkSVIzTYNcZl4PXA8QEYcAl2fmtl4VJkmSpNbamexw31ueROwSEW+KiK9ExPHdKU2SJEmtVA1yH6CY1DDhzcBKiqVH3hcR/9LpwiRJktRa1SB3P+D7ABERwHJgZWbeD3gr8MLulCdJkqRmqga5BcBvy8dLgN2BL5bPz+Kv+7BKkiSpR6oGuWuAu5ePjwQuyczLy+d3ALZ3ujBJkiS11mr5kcnWA2+NiEMp1oz76KS2ewOXdLowSZIktVY1yK2i6Hk7Cvg68JZJbUcDZ3a4LkmSJE2jUpDLzD8Cz2vS9uCOViRJkqRKql4jJ0mSpAFTdWiViHgWxVpyBwC7TGnOzFzcycIkSZLUWqUgFxGvAd4E/Ao4n2KPVUmSJPVR1R65FwDvz8yXdrMYSZIkVVf1Grm9gHXdLESSJEntqRrkvgvct5uFSJIkqT1Vh1ZfDKyNiGuAMzJzrIs1SZIkqYKqQe6i8v40gIiY2p6ZWXkGrCRJkmauavh6K5DdLESSJEntqbqzw2u7XYgkSZLa484OkiRJNdW0Ry4intvOC2Xmp2ZejiRJkqpqNbT6yTZeJwGDnCRJUg+1CnKH9KwKSZIkta1pkMvMi3tZiCRJktrjZAdJkqSaMshJkiTVlEFOkiSppgxykiRJNVUpyEXEHSJifreLkSRJUnXTBrkywP0eeFz3y5EkSVJV0wa5zNwGXAPc1P1yJEmSVFXVa+ROB57XzUIkSZLUnlY7O0z2a+CYiPgR8FVgK8W2XLdwr1VJkqTeqhrkPlzeLwIe1KDdvVYlSZJ6rGqQc99VSZKkAVMpyLnvqiRJ0uCp2iMHQETcC3g4sAfwscy8KiIOAq7NzD91o0BJkiQ1VinIRcTOwKnA04CguCbu68BVwLuAXwGrulSjJEmSGqi6/MibKRYEfh7FhIeY1PZ1YGmH65IkSdI0qg6tPhN4XWZ+KiLmTWm7FDiwo1VJkiRpWlWD3J7ABS3ad+lALeqxdZtGWLNhC6Nj4yxcMMSKpYtZtmRRv8uSJEkVVR1avYzG68cBPJBiwWDVyLpNI6xau5mRsXESGBkbZ9XazazbNNLv0iRJUkVVg9xpwKqIOAaYXx7LiHg48ErgE90oTt2zZsMWxrdt3+HY+LbtrNmwpU8VSZKkdlUdWl0N3B/4LDBeHvsusCvwJeA/O1+auml0bLyt45IkafBUXRB4O/DUiHgUxQzVvYHrgG9k5pldrE9dsnDBECMNQtvCBUN9qEaSJN0WbS0InJnfAb7TpVrUQyuWLmbV2s07DK8OzZ/HiqWL+1iVJElqR8tr5CLi2RGxMSLGIuKyiHhbRMxv9TWqh2VLFnHS0fdh0YIhAli0YIiTjr6Ps1YlSaqRpj1y5cSGT1GsE3cmcBDwKorFgP+9J9Wpq5YtWWRwkySpxlr1yL0CWA8szsynZObfAW8FXtxgUWBJkiT1WKsgdw/gI5l506Rj76NY/PeArlYlSZKkabUKcgsoZqZONvF8t+6UI0mSpKqmWxA42zwuSZKkHplu+ZEfR0Sj4xunHM/MbGspE0mSJM1Mq/D1lp5VAUTE7sDngQMp9nZ9WmZeP+Wc+wMfAu4MbAfekpmf72WdkiRJg6JpkMvM1/WyEGAlcGZmro6IleXzV08558/AczPzwohYCJwbERsyc6zHtUqSJPXddNfI9dJRwKnl41OBZVNPyMxfZ+aF5eNR4Bpgr55VKEmSNEAGKcjtk5lbAcr7vVudHBEPBHYGLu5BbZIkSQOnpxMUIuLbwL4Nml7T5uvsB5wGLM/Mm5uccxxwHMABB7jsnSRJmn16GuQy84hmbRFxdUTsl5lby6B2TZPz7gx8DXhtZv64xXudDJwMMDw87HIpkiRp1hmkodX1wPLy8XLgq1NPiIidga8An8rML/awNkmSpIEzSEFuNXBkRFwIHFk+JyKGI+KU8pynAYcDx0bEeeXt/v0pV5Ikqb8is9qoYznc+QqKILU78OTMvCAiXgL8JDPP6V6ZMzM8PJwbN27sdxmSJEnTiohzM3O4yrmVeuQi4lBgM/B84HfA3YHbl813B152G+qUJEnSDFQdWn0ncCFwEPAkYPL+XD8EHtzhuiRJkjSNqrNWHw48KzP/EBHzprRdBezX2bIkSZI0nXYmOzRcrw3YAxjvQC2SJElqQ9Ugdw5/XRpkqqdSDK9KkiSph6oOrb4Z+GZEnAGcDiTwqIj4V+AfgUd0qT5JkiQ1UalHLjO/QxHYDgU+RTHZYQ1wBPCUzPxR1yqUJElSQ5W36MrMrwJfjYi/pdjQ/jrgF1l1ITpJkiR1VNt7rWbmr4BfdaEWSZIktaFSkIuIZ053TmaePvNyJEmSVFXVHrlPNzk+eVjVICdJktRDVYPcIQ2O7QE8ETgGeE7HKpIkSVIllYJcZl7c4PDFwDkRkcBLgWd3sjBJkiS11s7ODs18l6JnTpIkST3UiSD3AOD/OvA6kiRJakPVWav/0eDwzsC9gScBH+5kUZIkSZpeO1t0TbUNuAJ4e5N2SZIkdVHVIDd/6oHM3N7hWiRJktSGqrNWDW2SJEkDpmmQi4iF7bxQZo7OvBxJkiRV1apH7kp23LlhOvNmWIskSZLa0CrIHUd7QU6SJEk91DTIZeYpvSxEkiRJ7enEgsCSJEnqg6rLjxARewLHAIuBXaY0Z2a+sJOFSZIkqbWqOzvcA/gRRYDbBbgeWEDRo/d74I/dKlCSJEmNVR1aXQP8DNgLCOAxwB2A4ylC3BO6Up0kSZKaqjq0+gDgRcBfyue3y8wbgJMjYnfgPcCju1CfJEmSmqjaI3dn4LrMvBn4A7DnpLZzgAd1ujBJkiS1VjXIXQbsUz7eAjxlUtvjgLEO1iRJkqQKqg6tfhs4AvgS8G7g9Ih4KHATcG/gpO6UJ0mSpGaqBrmVwBBAZn4uIm6gWIpkV+AjwIe7U54kSZKaqRTkMvMv/HWiA5n5FeAr3SpKkiRJ02t6jVxEXBwRr4+Ig3pZkCRJkqppNdlhFHgDcFFEfDci/iki7tSjuiRJkjSNpkEuMx8O3B04EdgXOAW4KiI+ExGPiYjoUY2SJElqoOXyI5l5WWa+MTPvATwMOA14LPB14MqIeFtE3KsHdUqSJGmKquvIkZk/zMzjgf0oZqxuBF4O/DwiNnapPkmSJDVROchNyMwbM/NLwMv467IjSzpalSRJkqZVdR05ACLizsDTgOcChwEJnAmc2vnSJEmS1Mq0QS4i5lFsw/Uc4P8BuwC/Al4DnJaZI12tUJIkSQ01DXIRMUwR3p4O7Emxn+ongFMz85zelCdJkqRmWvXInUOxl+o3KIZO/yszb+xJVZIkSZpWqyD3SuAzmXltr4qRJElSdU2DXGa+p5eFSJIkqT1tLz8iSZKkwWCQkyRJqimDnCRJUk0Z5CRJkmqqUpCLiH+OiDt0uxhJkiRVV7VH7sPAaER8ICLu282CJEmSVE3VIHd34IPA0cCmiPhRRCyPiF26V5okSZJaqRTkMvOyzFwF7E+xZdefgY9T9NK9OyIO7WKNkiRJaqCtyQ6ZeVNmfjEzHw0sBn4OvBQ4PyL+JyKe0I0iJUmSdGttz1qNiDtFxIuALwOHA5uA11DsErE+Ik7sbImSJElqpHKQi4jhiPgoMAq8AzgPeEhmDmfm6sw8DDgB+NeuVCpJkqQdVF1+5FzgJ8CjgBOBu2Tm8sz8yZRTvwXs1tkSJUmS1MhOFc8bBV4LfCMzs8V5PwMOmnFVkiRJmta0QS4idgYuAn47TYgjM28EftOh2mpj3aYR1mzYwujYOAsXDLFi6WKWLVnU77IkSdIsN+3QahnOjgOGul9O/azbNMKqtZsZGRsngZGxcVat3cy6TSP9Lk2SJM1yVSc7nAfcp5uF1NWaDVsY37Z9h2Pj27azZsOWPlUkSZLmiqpB7t+AV0XEEyMiullQ3YyOjbd1XJIkqVOqTnb4IvA3wFeBmyLiGmDy9XKZmXftdHF1sHDBECMNQtvCBY5ES5Kk7qoa5M5kx+Cm0oqli1m1dvMOw6tD8+exYuniPlYlSZLmgkpBLjOP7XIdtTUxO9VZq5Ikqdeq9sh1XUTsDnweOBC4DHhaZl4/5Zy7AmuBecB84H2Z+eHeVnpry5YsMrhJkqSeayvIRcT9gMXALlPbMvNTM6xlJXBmZq6OiJXl81dPOWcr8NDMvCEi7gicHxHrM3N0hu8tSZJUO5WCXEQsAL4GPHjiUHk/+bq5mQa5o4BHlo9PBc5mSpAr17SbcHva2CtWkiTvDFyTAAAVaElEQVRptqkahN4K7AEcThHingz8A/AZ4BLggR2oZZ/M3ApQ3u/d6KSI2D8ifg5cAbytWW9cRBwXERsjYuO1117bgfIkSZIGS9Ugt5QizP24fH5lZp6dmc8Fvg28rMqLRMS3I+L8BrejqhacmVdk5n2Bg4HlEbFPk/NOzszhzBzea6+9qr68JElSbVS9Rm4/4JLM3B4RfwHuNKltLfC5Ki+SmUc0a4uIqyNiv8zcGhH7AddM81qjEXEB8HDgS1XeX5IkaTap2iN3FbCgfPwb4CGT2g7uUC3rgeXl4+UUiw/vICLuEhFD5ePdgMMA98KSJElzUtUeue9ThLf/Bk4D3hARBwI3UYSu9R2oZTXwhYh4PnA58FSAiBgGjs/MFwCHAu+MiKS4Vu8dmbm5A+8tSZJUO1WD3BuBheXjNRQTH44BdqUIcS+ZaSGZeR3w6AbHNwIvKB9/C7jvTN9LkiRpNqi6s8PFwMXl423Av5U3SZIk9Umla+Qi4uMRcVCTtrtGxMc7W5YkSZKmU3Wyw7FAszU89uSvkxQkSZLUI+3sjJBNju8LjHegFkmSJLWh6TVyEfFkih0cJrwxIn475bQhinXczu1CbZIkSWqh1WSHAyhCGhS9cfcHbphyzg3AD4FVnS9NkiRJrTQNcpn5XuC9ABFxKbAsM/+3V4VJkiSptarLjzScsSpJkqT+qTzZISIWRcS7ImJjRFwaEfcuj788Ih7UvRIlSZLUSNV15O4FbAaeA4xSXD+3c9l8V+BlXalOkiRJTVXtkXsn8EvgIOBoin1OJ/wQeHCH65IkSdI0qu61+jDgGZn5p4iYN6Xtaoq15CRJktRDVXvkbm7RticuCCxJktRzVYPcOcDzmrQ9DfhBZ8qRJElSVVWHVt8EfDsivgmcTrFA8BER8TKK3R8O71J9kiRJaqJSj1xm/g+wjGKyw8cpJjusptj5YVlm/qRrFUqSJKmhqj1yZObXgK9FxMHA3sB1mbmla5VJkiSppcpBbkJmXgRc1IVaJEmS1IbKQS4i7gw8nmIx4F2mNGdmvqmThUmSJKm1SkEuIg4D/gtY0OSUpJgQIUmSpB6puvzIe4DLgAcAu2Tm7abcpi4SLEmSpC6rOrR6KPC0zDy3m8VIkiSpuqo9cpcDt+9mIZIkSWpP1SD3RmBlOeFBkiRJA6Dq0OoTgX2ASyPiR8DvprRnZi7vaGWSJElqqWqQexjFzNQ/APdq0J4dq0iSJEmVVApymXlQtwuRJElSe6peIydJkqQB087ODrsC/wQ8AtgduA44G/hkZv65K9VJkiSpqUo9chGxL/Az4D+BYWBXisWB3w+cGxH7dK1CSZIkNVR1aPXtwG7AwzPzoMx8SHnd3MMotu16W7cKlCRJUmNVg9zjgFWZ+YPJBzPzh8BrgSd0ujBJkiS1VjXI3REYbdJ2ZdkuSZKkHqoa5LYAz2nS9mzgV50pR5IkSVVVnbX6DuBT5aSG04GtwL7A04EjaB7yJEmS1CVVFwT+dLn8yInAKZOargaOz8zTu1GcJEmSmqu8jlxmnhwRpwCLKdaR+x2wJTNv7lZxkiRJaq5ykAMoQ9svu1SLJEmS2tA0yEXEP7TzQpl51szLkSRJUlWteuS+DWT5OJqck2VbAvM6WJckSZKmMd3Q6h+BL5e3/+t+OZIkSaqqVZB7FPBc4CnAU4GvAKc6hCpJkjQYmi4InJn/k5nPp1gv7nhgb2BDRFweESdFxKG9KlKSJEm3Nu3ODpn5l8w8PTMfBxwAvBd4PHB+RLy/2wVKkiSpsapbdE24DrisvCWwW4frkSRJUkWVglxEHBYRH6bYmutU4E/AE3BrLkmSpL5ptY7cwRRB7dnAgcB3gVcBX8zMP/WkOkmSJDXVatbqr4E/AGuBFwC/KY/vHRF7Tz05My/pfHmSJElqZrp15O4MHAssr/BaLggsSZLUQ62C3PN6VoUkSZLa1jTIZeapvSxEkiRJ7Wl3+RFJkiQNCIOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoamCAXEbtHxLci4sLyfrcW5945IkYi4v29rFGSJGmQDEyQA1YCZ2bmIcCZ5fNm3gT8T0+qkiRJGlCDFOSOAk4tH58KLGt0UkT8PbAP8M0e1SVJkjSQBinI7ZOZWwHK+72nnhARtwPeCazocW2SJEkDZ6devllEfBvYt0HTayq+xIuAMzLzioiY7r2OA44DOOCAA9opU5IkqRZ6GuQy84hmbRFxdUTsl5lbI2I/4JoGpz0EeHhEvAi4I7BzRPwpM291PV1mngycDDA8PJyd+Q4kSZIGR0+D3DTWA8uB1eX9V6eekJnPmngcEccCw41CnCRJ0lwwSNfIrQaOjIgLgSPL50TEcESc0tfKJEmSBlBkzv5Rx+Hh4dy4cWO/y5AkSZpWRJybmcNVzh2kHjlJkiS1wSAnSZJUUwY5SZKkmjLISZIk1ZRBTpIkqaYMcpIkSTVlkJMkSaopg5wkSVJNGeQkSZJqyiAnSZJUUwY5SZKkmjLISZIk1ZRBTpIkqaYMcpIkSTVlkJMkSaopg5wkSVJNGeQkSZJqyiAnSZJUUwY5SZKkmjLISZIk1ZRBTpIkqaYMcpIkSTVlkJMkSaopg5wkSVJNGeQkSZJqyiAnSZJUUwY5SZKkmjLISZIk1ZRBTpIkqaYMcpIkSTVlkJMkSaopg5wkSVJNGeQkSZJqyiAnSZJUUwY5SZKkmjLISZIk1dRO/S5gNli3aYQ1G7YwOjbOwgVDrFi6mGVLFvW7LEmSNMsZ5GZo3aYRVq3dzPi27QCMjI2zau1mAMOcJEnqKodWZ2jNhi23hLgJ49u2s2bDlj5VJEmS5gqD3AyNjo23dVySJKlTDHIztHDBUFvHJUmSOsUgN0Mrli5maP68HY4NzZ/HiqWL+1SRJEmaK5zsMEMTExqctSpJknrNINcBy5YsMrhJkqSec2hVkiSppgxykiRJNWWQkyRJqimDnCRJUk0Z5CRJkmrKICdJklRTBjlJkqSaMshJkiTVlEFOkiSppgxykiRJNWWQkyRJqimDnCRJUk0Z5CRJkmrKICdJklRTBjlJkqSaMshJkiTVlEFOkiSppgxykiRJNWWQkyRJqimDnCRJUk0NTJCLiN0j4lsRcWF5v1uT87ZHxHnlbX2v65QkSRoUAxPkgJXAmZl5CHBm+byR8cy8f3l7Uu/KkyRJGiyDFOSOAk4tH58KLOtjLZIkSQNvkILcPpm5FaC837vJebtExMaI+HFEGPYkSdKctVMv3ywivg3s26DpNW28zAGZORoRdwPOiojNmXlxg/c6DjgO4IADDrhN9UqSJA2ynga5zDyiWVtEXB0R+2Xm1ojYD7imyWuMlveXRMTZwBLgVkEuM08GTgYYHh7ODpQvSZI0UAZpaHU9sLx8vBz46tQTImK3iLh9+XhP4DDgFz2rUJIkaYD0tEduGquBL0TE84HLgacCRMQwcHxmvgA4FPhIRNxMEUJXZ6ZB7jZat2mENRu2MDo2zsIFQ6xYuphlSxb1uyxJklTRwAS5zLwOeHSD4xuBF5SPfwjcp8elzUrrNo2wau1mxrdtB2BkbJxVazcDGOYkSaqJQRpaVQ+t2bDllhA3YXzbdtZs2NKniiRJUrsMcnPU6Nh4W8clSdLgMcjNUQsXDLV1XJIkDR6D3By1YulihubP2+HY0Px5rFi6uE8VSZKkdg3MZAf11sSEBmetSpJUXwa5OWzZkkUGN0mSasyhVUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTRnkJEmSasogJ0mSVFORmf2uoesi4lrgN+XTPYHf9rEcdY6f5ezhZzm7+HnOHn6W/XHXzNyryolzIshNFhEbM3O433Vo5vwsZw8/y9nFz3P28LMcfA6tSpIk1ZRBTpIkqabmYpA7ud8FqGP8LGcPP8vZxc9z9vCzHHBz7ho5SZKk2WIu9shJkiTNCnMmyEXEYyNiS0RcFBEr+12PZiYiLouIzRFxXkRs7Hc9qi4iPh4R10TE+ZOO7R4R34qIC8v73fpZo6pp8lmeEBEj5e/meRHx+H7WqGoiYv+I+E5E/DIiLoiIl5XH/d0ccHMiyEXEPOADwOOAewLPiIh79rcqdcCjMvP+To2vnU8Cj51ybCVwZmYeApxZPtfg+yS3/iwB3l3+bt4/M8/ocU26bW4C/i0zDwUeDPxr+f9JfzcH3JwIcsADgYsy85LMvBH4HHBUn2uS5qTM/C7wuymHjwJOLR+fCizraVG6TZp8lqqhzNyamT8rH/8R+CWwCH83B95cCXKLgCsmPb+yPKb6SuCbEXFuRBzX72I0Y/tk5lYo/ocC7N3nejQzL46In5dDrw7F1UxEHAgsAX6Cv5sDb64EuWhwzOm69XZYZv4dxXD5v0bE4f0uSBIAHwLuDtwf2Aq8s7/lqB0RcUfgy8DLM/MP/a5H05srQe5KYP9Jz+8CjPapFnVAZo6W99cAX6EYPld9XR0R+wGU99f0uR7dRpl5dWZuz8ybgY/i72ZtRMR8ihD3mcxcWx72d3PAzZUg91PgkIg4KCJ2Bp4OrO9zTbqNIuIOEXGnicfAY4DzW3+VBtx6YHn5eDnw1T7WohmY+J9+6cn4u1kLERHAx4BfZua7JjX5uzng5syCwOUU+PcA84CPZ+Zb+lySbqOIuBtFLxzATsDpfp71ERGfBR4J7AlcDbwBWAd8ATgAuBx4amZ6Ef2Aa/JZPpJiWDWBy4AXTlxjpcEVEQ8DvgdsBm4uD/8HxXVy/m4OsDkT5CRJkmabuTK0KkmSNOsY5CRJkmrKICdJklRTBjlJkqSaMshJkiTVlEFOEgARcWxEZESMTd1WKSJ2KttO6ENdJ5TvvVOv37sdEXG7iHhPRGyNiJsjYl2Lc/eNiPUR8bvye3t5F+o5NiL+qdOvK2mwDPQ/jJL64m+AVwMr+11Izfwj8DLg34AfAde1OPf1wCOAYym2sbqsC/UcS/Fv/Me78NqSBoRBTtJU3wReEhHvycyr+l1ML0TE7TPzhhm+zKHl/XvK7ammO/d/M/Mr05w3UMotnG5KFyCVBoZDq5KmenN5/5pWJ00MeTY4/smIuGzS8wPL4cPjI+KkiLgqIv4YEZ+OiF0j4uCI2BARf4qIiyJi+dTXLB0aEd+JiD+Xw5cnRsQO/4ZFxJ4R8aGIGImIGyLiVxFx3JRzJoaQD4+IL0bEGMXq9a2+18dGxI8iYjwifh8R6yJi8aT2y4ATyqfby9c/tsHrHFj+zB4JPLw8LyPiwLL9oIj4TERcW9Z/XkQ8ecprHBwRp0XEpWU9l5Tf826TzjmbosfvsEnvcXbZ1u7n9qKIeHtEjAI3AAvaqPUeEfGViLgmIv4SEZeXP3M7EaQO8ZdJ0lRbgfcDL4+Id2Tmbzr0uquAsyn2a7wn8HaKrYCWUGyu/g7gX4BPRMTGzLxgytevoxgmPAlYCryu/PoTACLizsAPgKHy2KXleR8qe9zeN+X1PgN8lmJItOm/hRHxWOBrwFnAMcAdgROB70fE/TNzhGJP0ZdSDGc+pPzSixu83Nay/SPAduBFE8cjYn+KQHkN8Arg2vL9vhwRyzJzYn/ohcCVwMuB64G7UWyldMak934R8GmKLQlfWB77Q7PvcRqvodiv+rjy9f7SRq3/DYxRfK6/BRYBj8dOBKlzMtObN2/eoAghCRwM7E7xP+CPl207lW0nTDr/hOKfkFu9zieByyY9P7D82rOmnLe2PP7sScd2A24C3jD1fYCVU77+o8AfgQXl89cBfwEOaXDeb4Gdpnyf7674c9kIXDjx9eWxg4BtwLsmHXtzo59Hk9f8PnD2lGMfowhEe0w5/i3gvBavtRPwsPJ7WjLp+NnA9xuc3+7n9jPK7RzbqZVi/9UEntTv/7a9eZvNN/8qknQrWWyK/U7guZOHEGfo61Oe/6q83zDpfa+n6OXZv8HXf2HK889R9I7du3z+WIpeokvLWbY7lUN4G4A9KHoBJ5v2+rSIuAPwd8DnM/OmSXVeStH794jpXqMNj6XoVft9g/rvV/Y4EhE7R8R/lMPG4xSB8nvla3Tqs5psXWZOHYqtUut1wCXA6oj454g4pAu1SXOeQU5SM+8GfkcxjNgJ1095fmOL47s0+PqrmzxfVN7vDRxOEWwm375Ytu8x5eu3Tl8yuwHR5NyrKHouO2Vv4Lncuv41ZftE/SdR9Kp9GngC8EDg6LKt0c9tphp979PWWoa/Iyl6NE8Cfl1ez/cvXahRmrO8Rk5SQ5n5p4g4iaJnbk2DU/4CRQ9RZt446fjUwNQp+1D08Ex+DjBS3l9H0Zv3siZfv2XK8yozL68vz9u3Qdu+tF5ipF3XUfSsva1J+2h5/3TgU5k5MSmFiLhjG+/T7ufW6OdUqdbMvISiVzeA+wEvBj4YEZdl5tQeWkm3gUFOUisfBF7JX2eyTjYxCeLeFNdRERELgIdSXLvWaU8DVk96/nTgT8D55fNvAC8BLs/Mazrxhpn5fxFxLvDUiDghM7cDRMRdKb7PqRMoZuIbFJMVLsjM8Rbn7UrR+zXZ8xqcdwNwpwbHO/G5Va0VKC/Ig/Mi4pXA88v3NshJHWCQk9RUZt4QEScCJzdo/jrwe+CjEfEG4PbAv1OEq27453K5kZ9SzEZ9AcXki7Gy/d0UMye/FxHvpuiBuwPwt8DDM/Oo2/i+r6OYtfrfEfFBiuvy3kjxvb/ztn4zDbweOAf4bkS8n2KR4N0oQs/dMnNil4ZvAMsjYjNwEcWw6kMbvN4vgBdFxDEUM2j/mJlb6MznNm2tEXFf4L3A58s651FMNLmJYgawpA7wGjlJ0/kExazNHZQB6okUS4B8geI6qPcB3+lSHUdRXHO1Hng2RS/hmybV83uKQHMGxc4UGyiWKzlqJjVl5jcorkVbQPF9fhj4JfCwzBxt9bVtvs/lwDDwv8BbKWaAfohiQsXk4PMSip/BWyhC0p2AZzR4ybcBZwKnUITfj5TvM+PPrWKtVwGXU/TorqdY6mUh8MTMPLfqe0lqLW49GUmSJEl1YI+cJElSTRnkJEmSasogJ0mSVFMGOUmSpJoyyEmSJNWUQU6SJKmmDHKSJEk1ZZCTJEmqKYOcJElSTf1/dNSz9pqt3vYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "plt.scatter(result_table[\"Feature Count\"], result_table[\"Monetary Value Per Instance - Mean\"])\n",
    "plt.xlabel('Number of features', fontsize=16)\n",
    "plt.ylabel('Monetary Value Per Instance - Mean', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.7, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, eval_metric='error', gamma=0.3,\n",
      "       learning_rate=0.05, max_delta_step=3, max_depth=2,\n",
      "       min_child_weight=3, missing=None, n_estimators=500, n_jobs=-1,\n",
      "       nthread=None, objective='binary:logistic', random_state=42,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "['totalScanTimeInSeconds' 'lineItemVoids' 'scansWithoutRegistration'\n",
      " 'valuePerSecond' 'scannedLineItems'\n",
      " 'scansWithoutRegistrationPerScannedLineItem' 'pca_axis_1' 'pca_axis_2'\n",
      " 'tsne_axis_2']\n",
      "{'random_state': 42, 'objective': 'binary:logistic', 'n_jobs': -1, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 2, 'max_delta_step': 3, 'learning_rate': 0.05, 'gamma': 0.3, 'eval_metric': 'error', 'base_score': 0.7}\n"
     ]
    }
   ],
   "source": [
    "best_model = result_table.loc[result_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Raw Model\"]\n",
    "best_model_features = result_table.loc[result_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Features\"]\n",
    "best_parameters = result_table.loc[result_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Optimal Parameters\"]\n",
    "\n",
    "print(best_model)\n",
    "print(best_model_features)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative:  1775\n",
      "False positive:  0\n",
      "False negative:  0\n",
      "True positive:  104\n",
      "520 for 1879 instances in the test set\n",
      "0.2767429483767962 per instance in the test set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_monetary_value(cm):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(\"True negative: \", tn)\n",
    "        print(\"False positive: \", fp)\n",
    "        print(\"False negative: \", fn)\n",
    "        print(\"True positive: \", tp)\n",
    "        score = (-25)*fp + (-5)*fn + 5*tp\n",
    "        print(str(score) + \" for \" + str(sum(sum(cm))) + \" instances in the test set\")\n",
    "        print(str(score/sum(sum(cm))) + \" per instance in the test set\")\n",
    "        return score\n",
    "    \n",
    "cm = confusion_matrix(Y , best_model.predict(X[best_model_features]))\n",
    "\n",
    "monetary_value = get_monetary_value(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
