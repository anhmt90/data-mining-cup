{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "njobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv',sep='|')\n",
    "test=pd.read_csv('test.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     104\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.055349\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.fraud.value_counts())\n",
    "print(train.fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derviable directly from given features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training set\n",
    "\n",
    "train['scannedLineItems'] = train['scannedLineItemsPerSecond'] * train['totalScanTimeInSeconds']\n",
    "train['pricePerScannedLineItem'] = train['grandTotal'] / train['scannedLineItems']\n",
    "train['scansWithoutRegistrationPerScannedLineItem'] = train['scansWithoutRegistration'] / train['scannedLineItems']\n",
    "train['quantityModificationsPerScannedLineItem'] = train['quantityModifications'] / train['scannedLineItems']\n",
    "train['lineItemVoidsPerSecond'] = train['lineItemVoids'] / train['totalScanTimeInSeconds']\n",
    "train['scansWithoutRegistrationPerSecond'] = train['scansWithoutRegistration'] / train['totalScanTimeInSeconds']\n",
    "train['quantityModificationsPerSecond'] = train['quantityModifications'] / train['totalScanTimeInSeconds']\n",
    "train['secondsPerEuro'] = train['totalScanTimeInSeconds'] / train['grandTotal']\n",
    "train['lineItemVoidsPerEuro'] = train['lineItemVoids'] / train['grandTotal']\n",
    "train['scansWithoutRegistrationPerEuro'] = train['scansWithoutRegistration'] / train['grandTotal']\n",
    "train['quantityModificationsPerEuro'] = train['quantityModifications'] / train['grandTotal']\n",
    "\n",
    "test['scannedLineItems'] = test['scannedLineItemsPerSecond'] * test['totalScanTimeInSeconds']\n",
    "test['pricePerScannedLineItem'] = test['grandTotal'] / test['scannedLineItems']\n",
    "test['scansWithoutRegistrationPerScannedLineItem'] = test['scansWithoutRegistration'] / test['scannedLineItems']\n",
    "test['quantityModificationsPerScannedLineItem'] = test['quantityModifications'] / test['scannedLineItems']\n",
    "test['lineItemVoidsPerSecond'] = test['lineItemVoids'] / test['totalScanTimeInSeconds']\n",
    "test['scansWithoutRegistrationPerSecond'] = test['scansWithoutRegistration'] / test['totalScanTimeInSeconds']\n",
    "test['quantityModificationsPerSecond'] = test['quantityModifications'] / test['totalScanTimeInSeconds']\n",
    "test['secondsPerEuro'] = test['totalScanTimeInSeconds'] / test['grandTotal']\n",
    "test['lineItemVoidsPerEuro'] = test['lineItemVoids'] / test['grandTotal']\n",
    "test['scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / test['grandTotal']\n",
    "test['quantityModificationsPerEuro'] = test['quantityModifications'] / test['grandTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['grandTotal'] == 0.00, 'secondsPerEuro'] = test['totalScanTimeInSeconds'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'lineItemVoidsPerEuro'] = test['lineItemVoids'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'quantityModificationsPerEuro'] = test['quantityModifications'] / 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derivable from PCA / tSNE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['fraud'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_combined = pd.concat([train, test.sample(5000, random_state = 42)], ignore_index=True)\n",
    "\n",
    "train_test_combined = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 20) (500000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_test_combined = train_test_combined.drop('fraud',axis=1)\n",
    "Y_train_test_combined = train_test_combined['fraud']\n",
    "print(X_train_test_combined.shape, Y_train_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer \n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "X_train_test_combined = pd.DataFrame(feature_scaler.fit_transform(X_train_test_combined.values), columns=X_train_test_combined.columns, index=X_train_test_combined.index)\n",
    "\n",
    "#feature_scaler = StandardScaler()\n",
    "#X = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index)\n",
    "#data_preparation = \"StandardScaler\"\n",
    "\n",
    "#transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "#X_scaled = pd.DataFrame(transformer.transform(X), columns=X.columns, index=X.index)\n",
    "#data_preparation = \"LogScaler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derive features from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.16124041 0.1559011  0.14737624 0.13509126 0.13197732 0.11312753\n",
      " 0.11161208]\n",
      "Cumulative explained variation for 7 principal components: 0.956325939752108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train_test_combined_PCA = X_train_test_combined.copy()\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca_result = pca.fit_transform(X_train_test_combined_PCA)\n",
    "\n",
    "X_train_test_combined_PCA['pca-one'] = pca_result[:,0]\n",
    "X_train_test_combined_PCA['pca-two'] = pca_result[:,1] \n",
    "X_train_test_combined_PCA['pca-three'] = pca_result[:,2]\n",
    "\n",
    "X_train_test_combined_PCA['pca-one'] = pca_result[:,0]\n",
    "X_train_test_combined_PCA['pca-two'] = pca_result[:,1] \n",
    "X_train_test_combined_PCA['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Cumulative explained variation for 7 principal components: {}'.format(np.sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,20)\n",
    "\n",
    "plt.title('Grau Unlabeled, Blau: Fraud, Rot: No fraud')\n",
    "\n",
    "plt.scatter(X_train_test_combined_PCA[\"pca-one\"][Y_train_test_combined == -1].values, X_train_test_combined_PCA[\"pca-two\"][Y_train_test_combined == -1].values, color='grey', alpha = 0.1)\n",
    "plt.scatter(X_train_test_combined_PCA[\"pca-one\"][Y_train_test_combined == 0], X_train_test_combined_PCA[\"pca-two\"][Y_train_test_combined == 0], color='r')\n",
    "plt.scatter(X_train_test_combined_PCA[\"pca-one\"][Y_train_test_combined == 1], X_train_test_combined_PCA[\"pca-two\"][Y_train_test_combined == 1], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add PCA axes as additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pca_axis_1'] = X_train_test_combined_PCA['pca-one'].head(len(train))\n",
    "train['pca_axis_2'] = X_train_test_combined_PCA['pca-two'].head(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derive features from tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500000 samples in 3.783s...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_train_test_combined_tSNE = X_train_test_combined.copy()\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=300, init = 'pca')\n",
    "tsne_results = tsne.fit_transform(X_train_test_combined_tSNE)\n",
    "\n",
    "X_train_test_combined_tSNE['tsne-one'] = tsne_results[:,0]\n",
    "X_train_test_combined_tSNE['tsne-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,20)\n",
    "\n",
    "plt.title('Grau Unlabeled, Blau: Fraud, Rot: No fraud')\n",
    "\n",
    "plt.scatter(X_train_test_combined_tSNE[\"tsne-one\"][Y_train_test_combined == -1].values, X_train_test_combined_tSNE[\"tsne-two\"][Y_train_test_combined == -1].values, color='grey', alpha = 0.1)\n",
    "plt.scatter(X_train_test_combined_tSNE[\"tsne-one\"][Y_train_test_combined == 0], X_train_test_combined_tSNE[\"tsne-two\"][Y_train_test_combined == 0], color='r')\n",
    "plt.scatter(X_train_test_combined_tSNE[\"tsne-one\"][Y_train_test_combined == 1], X_train_test_combined_tSNE[\"tsne-two\"][Y_train_test_combined == 1], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tsne_axis_1'] = X_train_test_combined_tSNE['tsne-one'].head(len(train))\n",
    "train['tsne_axis_2'] = X_train_test_combined_tSNE['tsne-two'].head(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out center of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x176667d4ef0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "plt.scatter(train['tsne_axis_1'][train['fraud'] == 1], train['tsne_axis_2'][train['fraud'] == 1], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17666820da0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "\n",
    "combined_data = pd.DataFrame(train['tsne_axis_1'][train['fraud'] == 1])\n",
    "combined_data['tsne_axis_2'] = train['tsne_axis_2'][train['fraud'] == 1]\n",
    "\n",
    "kmeans.fit_predict(combined_data)\n",
    "\n",
    "plt.scatter(train['tsne_axis_1'][train['fraud'] == 1], train['tsne_axis_2'][train['fraud'] == 1], color='blue')\n",
    "\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "plt.scatter(cluster_centers[:,0], cluster_centers[:,1], color='red', marker = \"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance to cluster centers as additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dist(points1, points2):\n",
    "    result = []\n",
    "    for i in range(0, len(points1)):\n",
    "        result.append(np.sqrt( (points1['tsne_axis_1'][i] - points2['tsne_axis_1'][i])**2\n",
    "                              +(points1['tsne_axis_2'][i] - points2['tsne_axis_2'][i])**2))\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.DataFrame(\n",
    "            {'tsne_axis_1': train['tsne_axis_1'],\n",
    "             'tsne_axis_2': train['tsne_axis_2'],\n",
    "            })\n",
    "coordinates['tsne_axis_1']\n",
    "\n",
    "cluster_center_1 = pd.DataFrame([cluster_centers[0]] * len(train))\n",
    "cluster_center_2 = pd.DataFrame([cluster_centers[1]] * len(train))\n",
    "cluster_center_3 = pd.DataFrame([cluster_centers[2]] * len(train))\n",
    "\n",
    "cluster_center_1.columns = ['tsne_axis_1', 'tsne_axis_2']\n",
    "cluster_center_2.columns = ['tsne_axis_1', 'tsne_axis_2']\n",
    "cluster_center_3.columns = ['tsne_axis_1', 'tsne_axis_2']\n",
    "\n",
    "train['distance_cluster_center_1'] = dist(cluster_center_1, coordinates)\n",
    "train['distance_cluster_center_2'] = dist(cluster_center_2, coordinates)\n",
    "train['distance_cluster_center_3'] = dist(cluster_center_3, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "      <th>scannedLineItems</th>\n",
       "      <th>pricePerScannedLineItem</th>\n",
       "      <th>scansWithoutRegistrationPerScannedLineItem</th>\n",
       "      <th>quantityModificationsPerScannedLineItem</th>\n",
       "      <th>lineItemVoidsPerSecond</th>\n",
       "      <th>scansWithoutRegistrationPerSecond</th>\n",
       "      <th>quantityModificationsPerSecond</th>\n",
       "      <th>secondsPerEuro</th>\n",
       "      <th>lineItemVoidsPerEuro</th>\n",
       "      <th>scansWithoutRegistrationPerEuro</th>\n",
       "      <th>quantityModificationsPerEuro</th>\n",
       "      <th>pca_axis_1</th>\n",
       "      <th>pca_axis_2</th>\n",
       "      <th>tsne_axis_1</th>\n",
       "      <th>tsne_axis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.886207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>19.268739</td>\n",
       "      <td>0.127971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>-0.041017</td>\n",
       "      <td>-0.249076</td>\n",
       "      <td>2.291510</td>\n",
       "      <td>-5.640468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.954286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>0.182749</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.146199</td>\n",
       "      <td>0.115539</td>\n",
       "      <td>0.267326</td>\n",
       "      <td>1.481642</td>\n",
       "      <td>2.398213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.781538</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>24.388674</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.160875</td>\n",
       "      <td>0.080438</td>\n",
       "      <td>0.438573</td>\n",
       "      <td>0.273101</td>\n",
       "      <td>5.278484</td>\n",
       "      <td>6.027374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.183103</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>19.402015</td>\n",
       "      <td>0.086665</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.294578</td>\n",
       "      <td>-0.374467</td>\n",
       "      <td>3.357620</td>\n",
       "      <td>-7.026612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.019630</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>5.274132</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.024531</td>\n",
       "      <td>-0.018999</td>\n",
       "      <td>-0.392183</td>\n",
       "      <td>-0.736335</td>\n",
       "      <td>-9.648399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.426538</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>69.431921</td>\n",
       "      <td>0.991885</td>\n",
       "      <td>0.450857</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>-0.488244</td>\n",
       "      <td>0.334949</td>\n",
       "      <td>-6.418109</td>\n",
       "      <td>6.218063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>294</td>\n",
       "      <td>55.63</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037415</td>\n",
       "      <td>0.189218</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.057273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>5.284918</td>\n",
       "      <td>0.035952</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.017976</td>\n",
       "      <td>-0.200941</td>\n",
       "      <td>-0.051325</td>\n",
       "      <td>-3.007755</td>\n",
       "      <td>1.776288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1545</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>67.763158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.163977</td>\n",
       "      <td>0.383210</td>\n",
       "      <td>5.297117</td>\n",
       "      <td>7.485310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>962</td>\n",
       "      <td>65.44</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028067</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.423704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>14.700489</td>\n",
       "      <td>0.106968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>-0.068084</td>\n",
       "      <td>-0.503479</td>\n",
       "      <td>0.829160</td>\n",
       "      <td>-6.073065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>725</td>\n",
       "      <td>41.08</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.521481</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>17.648491</td>\n",
       "      <td>0.243427</td>\n",
       "      <td>0.048685</td>\n",
       "      <td>0.097371</td>\n",
       "      <td>-0.128823</td>\n",
       "      <td>0.365507</td>\n",
       "      <td>-3.321243</td>\n",
       "      <td>8.314712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1533</td>\n",
       "      <td>84.73</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.055271</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.295625</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>18.092765</td>\n",
       "      <td>0.047209</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>0.047209</td>\n",
       "      <td>0.310071</td>\n",
       "      <td>-0.116355</td>\n",
       "      <td>3.008145</td>\n",
       "      <td>-7.337041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>764</td>\n",
       "      <td>28.98</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.449000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.363009</td>\n",
       "      <td>0.276052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.514894</td>\n",
       "      <td>-0.300758</td>\n",
       "      <td>-7.237004</td>\n",
       "      <td>-4.395898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1736</td>\n",
       "      <td>5.46</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>317.948718</td>\n",
       "      <td>0.732601</td>\n",
       "      <td>1.831502</td>\n",
       "      <td>0.732601</td>\n",
       "      <td>0.375869</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>5.451623</td>\n",
       "      <td>6.534986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>1705</td>\n",
       "      <td>16.96</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.628148</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>100.530660</td>\n",
       "      <td>0.412736</td>\n",
       "      <td>0.235849</td>\n",
       "      <td>0.235849</td>\n",
       "      <td>0.076311</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.240064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>1659</td>\n",
       "      <td>52.53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.031664</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.501429</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>31.581953</td>\n",
       "      <td>0.038073</td>\n",
       "      <td>0.019037</td>\n",
       "      <td>0.076147</td>\n",
       "      <td>0.310864</td>\n",
       "      <td>-0.310105</td>\n",
       "      <td>3.279893</td>\n",
       "      <td>-6.192203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>32.45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.408333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>26.810478</td>\n",
       "      <td>0.092450</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.165564</td>\n",
       "      <td>0.752756</td>\n",
       "      <td>0.948456</td>\n",
       "      <td>9.741565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1295</td>\n",
       "      <td>42.90</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.033127</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.186480</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.453786</td>\n",
       "      <td>-0.227552</td>\n",
       "      <td>-5.629910</td>\n",
       "      <td>-2.260554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>590</td>\n",
       "      <td>79.84</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040678</td>\n",
       "      <td>0.135322</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.326667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>7.389780</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>0.125251</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.462997</td>\n",
       "      <td>-0.382638</td>\n",
       "      <td>6.386006</td>\n",
       "      <td>-7.388077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>59.00</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.424460</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>2.355932</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.514782</td>\n",
       "      <td>0.422194</td>\n",
       "      <td>5.876467</td>\n",
       "      <td>2.114941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1724</td>\n",
       "      <td>25.40</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.336842</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>67.874016</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>-0.079730</td>\n",
       "      <td>0.108762</td>\n",
       "      <td>-0.604102</td>\n",
       "      <td>0.155842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1691</td>\n",
       "      <td>59.61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.974000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>28.367724</td>\n",
       "      <td>0.016776</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>-0.194797</td>\n",
       "      <td>0.039379</td>\n",
       "      <td>-1.836084</td>\n",
       "      <td>1.517769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1505</td>\n",
       "      <td>2.70</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>557.407407</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.295255</td>\n",
       "      <td>-0.262198</td>\n",
       "      <td>-4.205016</td>\n",
       "      <td>-1.116313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>934</td>\n",
       "      <td>98.54</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.105503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.317500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>9.478384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050741</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>-0.110298</td>\n",
       "      <td>1.048803</td>\n",
       "      <td>-0.592465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>25.50</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>4.901961</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>-0.329137</td>\n",
       "      <td>0.162225</td>\n",
       "      <td>-6.625201</td>\n",
       "      <td>5.336575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>78.91</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>1.111408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.910000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.899759</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.403147</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>8.363058</td>\n",
       "      <td>6.735775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>81.54</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>0.099926</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>10.007358</td>\n",
       "      <td>0.098111</td>\n",
       "      <td>0.085847</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>-0.380261</td>\n",
       "      <td>-1.554787</td>\n",
       "      <td>-4.447748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>1503</td>\n",
       "      <td>23.00</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019295</td>\n",
       "      <td>0.015303</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>65.347826</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>-0.515099</td>\n",
       "      <td>-0.115126</td>\n",
       "      <td>-9.055705</td>\n",
       "      <td>-2.439164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>329</td>\n",
       "      <td>56.65</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.172188</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.697619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.030395</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>5.807590</td>\n",
       "      <td>0.176523</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>0.088261</td>\n",
       "      <td>0.297538</td>\n",
       "      <td>0.152559</td>\n",
       "      <td>3.592706</td>\n",
       "      <td>1.074626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>1629</td>\n",
       "      <td>40.42</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013505</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.837273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>40.301831</td>\n",
       "      <td>0.148441</td>\n",
       "      <td>0.173182</td>\n",
       "      <td>0.098961</td>\n",
       "      <td>0.394547</td>\n",
       "      <td>-0.357028</td>\n",
       "      <td>7.274017</td>\n",
       "      <td>-5.021105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>1435</td>\n",
       "      <td>91.96</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>15.604611</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0.146086</td>\n",
       "      <td>-0.234990</td>\n",
       "      <td>2.525899</td>\n",
       "      <td>-7.679103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>314</td>\n",
       "      <td>48.54</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.154586</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.022500</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>6.468892</td>\n",
       "      <td>0.123609</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>-0.174238</td>\n",
       "      <td>-0.579916</td>\n",
       "      <td>-5.421681</td>\n",
       "      <td>-6.560289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>285</td>\n",
       "      <td>6.23</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.207667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>45.746388</td>\n",
       "      <td>0.802568</td>\n",
       "      <td>0.963082</td>\n",
       "      <td>0.321027</td>\n",
       "      <td>-0.119605</td>\n",
       "      <td>-0.385611</td>\n",
       "      <td>-3.364026</td>\n",
       "      <td>-6.627456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>891</td>\n",
       "      <td>78.96</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>0.088620</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.158400</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>11.284195</td>\n",
       "      <td>0.025329</td>\n",
       "      <td>0.126646</td>\n",
       "      <td>0.025329</td>\n",
       "      <td>0.050645</td>\n",
       "      <td>-0.414961</td>\n",
       "      <td>-0.568405</td>\n",
       "      <td>-9.569429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>1355</td>\n",
       "      <td>48.87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.981429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>27.726622</td>\n",
       "      <td>0.040925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081850</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.474456</td>\n",
       "      <td>2.842475</td>\n",
       "      <td>8.743980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>866</td>\n",
       "      <td>39.38</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.045473</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.845000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>21.990858</td>\n",
       "      <td>0.253936</td>\n",
       "      <td>0.228542</td>\n",
       "      <td>0.025394</td>\n",
       "      <td>-0.169790</td>\n",
       "      <td>0.165909</td>\n",
       "      <td>-2.875839</td>\n",
       "      <td>1.616999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.042985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>23.263889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.428080</td>\n",
       "      <td>0.528127</td>\n",
       "      <td>1.952261</td>\n",
       "      <td>7.529419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>834</td>\n",
       "      <td>80.64</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015588</td>\n",
       "      <td>0.096691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.203077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>10.342262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124008</td>\n",
       "      <td>0.037202</td>\n",
       "      <td>0.344872</td>\n",
       "      <td>-0.257029</td>\n",
       "      <td>3.983405</td>\n",
       "      <td>-0.253358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>1397</td>\n",
       "      <td>62.59</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017895</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.503600</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>22.319859</td>\n",
       "      <td>0.111839</td>\n",
       "      <td>0.143793</td>\n",
       "      <td>0.063908</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>0.299678</td>\n",
       "      <td>-0.008178</td>\n",
       "      <td>5.653863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>1561</td>\n",
       "      <td>91.75</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.058776</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.828947</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>17.013624</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.065395</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>0.041643</td>\n",
       "      <td>-0.350189</td>\n",
       "      <td>-0.433653</td>\n",
       "      <td>-7.456149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>22.88</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.027013</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.542222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>37.019231</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.218531</td>\n",
       "      <td>0.087413</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>-0.100789</td>\n",
       "      <td>-1.865648</td>\n",
       "      <td>-1.925621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1520</td>\n",
       "      <td>41.88</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.940000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>36.294174</td>\n",
       "      <td>0.143266</td>\n",
       "      <td>0.191022</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>-0.046234</td>\n",
       "      <td>0.460097</td>\n",
       "      <td>6.282418</td>\n",
       "      <td>6.576899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>622</td>\n",
       "      <td>60.75</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.097669</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.593750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>10.238683</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.082305</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.168154</td>\n",
       "      <td>0.455299</td>\n",
       "      <td>3.343559</td>\n",
       "      <td>4.261848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>1012</td>\n",
       "      <td>59.90</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014822</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.993333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>16.894825</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.050083</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>-0.074133</td>\n",
       "      <td>-0.129078</td>\n",
       "      <td>-1.038483</td>\n",
       "      <td>-1.818782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>1451</td>\n",
       "      <td>23.10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>62.813853</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.216275</td>\n",
       "      <td>0.373713</td>\n",
       "      <td>6.305847</td>\n",
       "      <td>7.139262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>401</td>\n",
       "      <td>80.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.201646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.107500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.959189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.509207</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>-3.595303</td>\n",
       "      <td>3.838764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6</td>\n",
       "      <td>960</td>\n",
       "      <td>93.09</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.096969</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.309000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>10.312601</td>\n",
       "      <td>0.075196</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.334851</td>\n",
       "      <td>-0.332647</td>\n",
       "      <td>1.133462</td>\n",
       "      <td>-3.823445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6</td>\n",
       "      <td>1433</td>\n",
       "      <td>72.19</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.887600</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.850395</td>\n",
       "      <td>0.096966</td>\n",
       "      <td>0.096966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.228582</td>\n",
       "      <td>-0.746479</td>\n",
       "      <td>-1.578820</td>\n",
       "      <td>-7.881694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6</td>\n",
       "      <td>1424</td>\n",
       "      <td>66.90</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.676000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>21.285501</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.119581</td>\n",
       "      <td>0.044843</td>\n",
       "      <td>0.242373</td>\n",
       "      <td>-0.469967</td>\n",
       "      <td>4.787653</td>\n",
       "      <td>-5.749266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>1820</td>\n",
       "      <td>54.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.030022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.203077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>33.308931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018302</td>\n",
       "      <td>-0.078348</td>\n",
       "      <td>-0.545897</td>\n",
       "      <td>1.096457</td>\n",
       "      <td>-6.627123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>32.29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.018125</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.345417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.495509</td>\n",
       "      <td>0.061939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154847</td>\n",
       "      <td>-0.063479</td>\n",
       "      <td>0.660680</td>\n",
       "      <td>-2.404566</td>\n",
       "      <td>9.728538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>617</td>\n",
       "      <td>90.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.147050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>6.800397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055109</td>\n",
       "      <td>0.775119</td>\n",
       "      <td>0.381716</td>\n",
       "      <td>8.732438</td>\n",
       "      <td>6.564204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>1593</td>\n",
       "      <td>25.53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.911786</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>62.397180</td>\n",
       "      <td>0.078339</td>\n",
       "      <td>0.078339</td>\n",
       "      <td>0.078339</td>\n",
       "      <td>-0.358897</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>-0.968361</td>\n",
       "      <td>-1.003854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>85.05</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.631250</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>7.148736</td>\n",
       "      <td>0.035273</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>0.023516</td>\n",
       "      <td>-0.218367</td>\n",
       "      <td>0.417477</td>\n",
       "      <td>-2.901950</td>\n",
       "      <td>3.705740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1385</td>\n",
       "      <td>34.68</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.019495</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.284444</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>39.936563</td>\n",
       "      <td>0.144175</td>\n",
       "      <td>0.230681</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>-0.123766</td>\n",
       "      <td>0.468661</td>\n",
       "      <td>-0.372667</td>\n",
       "      <td>6.958865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>983</td>\n",
       "      <td>14.07</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019329</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.740526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.864961</td>\n",
       "      <td>0.142146</td>\n",
       "      <td>0.284293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.534646</td>\n",
       "      <td>-0.170078</td>\n",
       "      <td>-6.728629</td>\n",
       "      <td>-3.601081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>768</td>\n",
       "      <td>7.24</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.658182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>106.077348</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>1.381215</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>-0.069446</td>\n",
       "      <td>0.458316</td>\n",
       "      <td>1.747853</td>\n",
       "      <td>7.119153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>1474</td>\n",
       "      <td>60.64</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.041140</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.191579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>24.307388</td>\n",
       "      <td>0.148417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082454</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>0.677333</td>\n",
       "      <td>-1.976915</td>\n",
       "      <td>7.596049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>692</td>\n",
       "      <td>21.65</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>0.031286</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.443333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>31.963048</td>\n",
       "      <td>0.323326</td>\n",
       "      <td>0.323326</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.624758</td>\n",
       "      <td>-0.205781</td>\n",
       "      <td>7.073208</td>\n",
       "      <td>-3.765071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>50.75</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.144587</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.171875</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.916256</td>\n",
       "      <td>0.019704</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.511703</td>\n",
       "      <td>-0.003923</td>\n",
       "      <td>-4.087084</td>\n",
       "      <td>2.085103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>39.55</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.369626</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.464815</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>2.705436</td>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.151707</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>-0.137674</td>\n",
       "      <td>0.496277</td>\n",
       "      <td>-0.340919</td>\n",
       "      <td>8.913836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>1237</td>\n",
       "      <td>48.22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.822000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>25.653256</td>\n",
       "      <td>0.145168</td>\n",
       "      <td>0.041477</td>\n",
       "      <td>0.062215</td>\n",
       "      <td>0.203260</td>\n",
       "      <td>-0.160857</td>\n",
       "      <td>3.865201</td>\n",
       "      <td>-2.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>1450</td>\n",
       "      <td>62.63</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.043193</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.175333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>23.151844</td>\n",
       "      <td>0.079834</td>\n",
       "      <td>0.143701</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>-0.009664</td>\n",
       "      <td>0.257652</td>\n",
       "      <td>-1.286905</td>\n",
       "      <td>3.962601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>57.90</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.113976</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.135714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.773748</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.120898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.198592</td>\n",
       "      <td>-0.509611</td>\n",
       "      <td>-1.376561</td>\n",
       "      <td>-2.715564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>1748</td>\n",
       "      <td>26.31</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.754000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>66.438616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342075</td>\n",
       "      <td>0.038008</td>\n",
       "      <td>-0.437345</td>\n",
       "      <td>0.230964</td>\n",
       "      <td>-6.549467</td>\n",
       "      <td>1.752992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>61.24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.061240</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.804444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.329197</td>\n",
       "      <td>0.114304</td>\n",
       "      <td>0.048988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.124097</td>\n",
       "      <td>-0.617249</td>\n",
       "      <td>-1.709996</td>\n",
       "      <td>-4.619247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1123</td>\n",
       "      <td>28.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.025770</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.929333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>38.804423</td>\n",
       "      <td>0.034554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172771</td>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.693424</td>\n",
       "      <td>-0.933752</td>\n",
       "      <td>9.945416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>232</td>\n",
       "      <td>18.27</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.078750</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.135000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>12.698413</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>0.273673</td>\n",
       "      <td>0.109469</td>\n",
       "      <td>-0.120305</td>\n",
       "      <td>0.509492</td>\n",
       "      <td>-2.771090</td>\n",
       "      <td>3.306692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>1327</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.280800</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>189.031339</td>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.142450</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.467928</td>\n",
       "      <td>-2.202643</td>\n",
       "      <td>8.647305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6</td>\n",
       "      <td>449</td>\n",
       "      <td>21.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.046771</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>21.380952</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.431033</td>\n",
       "      <td>-0.314025</td>\n",
       "      <td>8.772422</td>\n",
       "      <td>1.874182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>1228</td>\n",
       "      <td>3.17</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>387.381703</td>\n",
       "      <td>2.208202</td>\n",
       "      <td>1.261830</td>\n",
       "      <td>1.261830</td>\n",
       "      <td>0.039822</td>\n",
       "      <td>-0.019797</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>-0.082569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>861</td>\n",
       "      <td>31.34</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.567000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.472878</td>\n",
       "      <td>0.350989</td>\n",
       "      <td>0.095724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.752514</td>\n",
       "      <td>0.193453</td>\n",
       "      <td>-9.426851</td>\n",
       "      <td>2.579887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>40.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>1.748252</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.148324</td>\n",
       "      <td>-0.153713</td>\n",
       "      <td>2.612095</td>\n",
       "      <td>-2.954630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6</td>\n",
       "      <td>1154</td>\n",
       "      <td>57.64</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.049948</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.882000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>20.020819</td>\n",
       "      <td>0.121443</td>\n",
       "      <td>0.173491</td>\n",
       "      <td>0.069396</td>\n",
       "      <td>0.486169</td>\n",
       "      <td>-0.364226</td>\n",
       "      <td>7.220492</td>\n",
       "      <td>-4.987102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>1393</td>\n",
       "      <td>99.58</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.241053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.988753</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.080337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.408322</td>\n",
       "      <td>-0.220590</td>\n",
       "      <td>-5.144193</td>\n",
       "      <td>-2.056725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>1068</td>\n",
       "      <td>23.64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.688571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>45.177665</td>\n",
       "      <td>0.169205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042301</td>\n",
       "      <td>-0.491409</td>\n",
       "      <td>0.157765</td>\n",
       "      <td>-8.690619</td>\n",
       "      <td>1.150595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>93.04</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.310133</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.304000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3.224420</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.032244</td>\n",
       "      <td>0.380793</td>\n",
       "      <td>-0.345798</td>\n",
       "      <td>2.005065</td>\n",
       "      <td>-1.689218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>33.95</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.425000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>7.363770</td>\n",
       "      <td>0.324006</td>\n",
       "      <td>0.294551</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.287106</td>\n",
       "      <td>-1.164025</td>\n",
       "      <td>4.711224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>1411</td>\n",
       "      <td>49.25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>28.649746</td>\n",
       "      <td>0.040609</td>\n",
       "      <td>0.162437</td>\n",
       "      <td>0.081218</td>\n",
       "      <td>0.485121</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>7.957685</td>\n",
       "      <td>1.416044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>1279</td>\n",
       "      <td>89.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.365000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>14.353047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>0.056443</td>\n",
       "      <td>-0.014843</td>\n",
       "      <td>1.939872</td>\n",
       "      <td>-1.268278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>1771</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.278889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>705.577689</td>\n",
       "      <td>1.195219</td>\n",
       "      <td>0.398406</td>\n",
       "      <td>1.593625</td>\n",
       "      <td>0.124520</td>\n",
       "      <td>0.280330</td>\n",
       "      <td>0.724071</td>\n",
       "      <td>10.539537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3</td>\n",
       "      <td>1642</td>\n",
       "      <td>6.25</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>262.720000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>-0.041729</td>\n",
       "      <td>0.049058</td>\n",
       "      <td>-4.233076</td>\n",
       "      <td>-0.266492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>1018</td>\n",
       "      <td>27.26</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.135833</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.344094</td>\n",
       "      <td>0.036684</td>\n",
       "      <td>0.330154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.489304</td>\n",
       "      <td>-0.242547</td>\n",
       "      <td>-6.257372</td>\n",
       "      <td>-3.666443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>78.64</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.787273</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.559512</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.127162</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>-0.014908</td>\n",
       "      <td>-0.026908</td>\n",
       "      <td>-0.335554</td>\n",
       "      <td>1.259151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>550</td>\n",
       "      <td>84.57</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.153764</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.844091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>6.503488</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035474</td>\n",
       "      <td>-0.131056</td>\n",
       "      <td>0.134721</td>\n",
       "      <td>-0.016288</td>\n",
       "      <td>2.413416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>24.32</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100917</td>\n",
       "      <td>0.223119</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.210909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>4.481908</td>\n",
       "      <td>0.411184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205592</td>\n",
       "      <td>0.167862</td>\n",
       "      <td>0.578846</td>\n",
       "      <td>3.694528</td>\n",
       "      <td>3.950156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>1660</td>\n",
       "      <td>12.58</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.838667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>131.955485</td>\n",
       "      <td>0.476948</td>\n",
       "      <td>0.397456</td>\n",
       "      <td>0.079491</td>\n",
       "      <td>-0.331618</td>\n",
       "      <td>-0.064990</td>\n",
       "      <td>-7.215877</td>\n",
       "      <td>-0.368866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>1078</td>\n",
       "      <td>58.61</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.054369</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.326250</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>18.392766</td>\n",
       "      <td>0.153557</td>\n",
       "      <td>0.170619</td>\n",
       "      <td>0.051186</td>\n",
       "      <td>0.100023</td>\n",
       "      <td>0.308193</td>\n",
       "      <td>5.269053</td>\n",
       "      <td>4.068360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>1464</td>\n",
       "      <td>58.21</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.039761</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.238846</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.150318</td>\n",
       "      <td>0.137433</td>\n",
       "      <td>0.051538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.705927</td>\n",
       "      <td>-0.027746</td>\n",
       "      <td>-8.902964</td>\n",
       "      <td>-0.702432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>1228</td>\n",
       "      <td>85.93</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.069976</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.296500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.008958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>14.290702</td>\n",
       "      <td>0.128011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>-0.235100</td>\n",
       "      <td>-0.386060</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-5.782523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6</td>\n",
       "      <td>1790</td>\n",
       "      <td>70.66</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.039475</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.435385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.332579</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.639821</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>-5.232473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>1052</td>\n",
       "      <td>67.09</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.063774</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.531053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>15.680429</td>\n",
       "      <td>0.089432</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.266703</td>\n",
       "      <td>-0.120838</td>\n",
       "      <td>2.963937</td>\n",
       "      <td>-6.551115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>996</td>\n",
       "      <td>71.94</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.072229</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.664444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>13.844871</td>\n",
       "      <td>0.097303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>-0.697928</td>\n",
       "      <td>0.261035</td>\n",
       "      <td>-10.169147</td>\n",
       "      <td>0.356178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>1515</td>\n",
       "      <td>7.69</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.366190</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>197.009103</td>\n",
       "      <td>1.430429</td>\n",
       "      <td>0.520156</td>\n",
       "      <td>0.130039</td>\n",
       "      <td>-0.518834</td>\n",
       "      <td>0.094548</td>\n",
       "      <td>-9.144720</td>\n",
       "      <td>-1.666552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6</td>\n",
       "      <td>1245</td>\n",
       "      <td>22.06</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.017719</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.206000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>56.436990</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.317316</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.530101</td>\n",
       "      <td>-0.283222</td>\n",
       "      <td>8.804177</td>\n",
       "      <td>-3.323750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>952</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1641.379310</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>8.620690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.595572</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>-5.722739</td>\n",
       "      <td>2.731173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>1570</td>\n",
       "      <td>47.79</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.895000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>32.852061</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.209249</td>\n",
       "      <td>0.104624</td>\n",
       "      <td>0.898808</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>9.448620</td>\n",
       "      <td>-0.520349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>1599</td>\n",
       "      <td>36.79</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0.023008</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.299375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>43.462898</td>\n",
       "      <td>0.244632</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>0.081544</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>-0.666655</td>\n",
       "      <td>-0.026841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>1305</td>\n",
       "      <td>87.65</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.021456</td>\n",
       "      <td>0.067165</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.130357</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>14.888762</td>\n",
       "      <td>0.079863</td>\n",
       "      <td>0.091272</td>\n",
       "      <td>0.045636</td>\n",
       "      <td>-0.005069</td>\n",
       "      <td>0.290251</td>\n",
       "      <td>-0.061397</td>\n",
       "      <td>5.488880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>14.32</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.117377</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.022857</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>8.519553</td>\n",
       "      <td>0.069832</td>\n",
       "      <td>0.349162</td>\n",
       "      <td>0.349162</td>\n",
       "      <td>0.607179</td>\n",
       "      <td>-0.185758</td>\n",
       "      <td>5.437742</td>\n",
       "      <td>-3.972778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6</td>\n",
       "      <td>861</td>\n",
       "      <td>97.36</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>0.113078</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.170000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>8.843468</td>\n",
       "      <td>0.061627</td>\n",
       "      <td>0.092440</td>\n",
       "      <td>0.051356</td>\n",
       "      <td>0.811504</td>\n",
       "      <td>-0.186643</td>\n",
       "      <td>7.877558</td>\n",
       "      <td>-1.742309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6</td>\n",
       "      <td>1577</td>\n",
       "      <td>78.41</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.049721</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.409130</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>20.112231</td>\n",
       "      <td>0.051014</td>\n",
       "      <td>0.076521</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>-0.065516</td>\n",
       "      <td>-0.642002</td>\n",
       "      <td>-0.610514</td>\n",
       "      <td>-8.484739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>4</td>\n",
       "      <td>597</td>\n",
       "      <td>45.98</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.028476</td>\n",
       "      <td>0.077018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.704706</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>12.983906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086994</td>\n",
       "      <td>0.086994</td>\n",
       "      <td>0.225813</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>1.891194</td>\n",
       "      <td>-0.140865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1319</td>\n",
       "      <td>37.10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014405</td>\n",
       "      <td>0.028127</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.952632</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.552561</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.666603</td>\n",
       "      <td>0.150451</td>\n",
       "      <td>-7.475861</td>\n",
       "      <td>0.901785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>1335</td>\n",
       "      <td>38.95</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>0.029176</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>34.274711</td>\n",
       "      <td>0.128370</td>\n",
       "      <td>0.025674</td>\n",
       "      <td>0.077022</td>\n",
       "      <td>-0.310403</td>\n",
       "      <td>0.478123</td>\n",
       "      <td>-4.297891</td>\n",
       "      <td>7.470648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6</td>\n",
       "      <td>894</td>\n",
       "      <td>77.50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.086689</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>11.535484</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.554097</td>\n",
       "      <td>-0.270644</td>\n",
       "      <td>6.861796</td>\n",
       "      <td>-1.661314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5</td>\n",
       "      <td>533</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>1903.571429</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.119074</td>\n",
       "      <td>-0.158487</td>\n",
       "      <td>-1.929096</td>\n",
       "      <td>-2.241485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>1636</td>\n",
       "      <td>70.40</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.043032</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.693333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>23.238636</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.127841</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>0.182228</td>\n",
       "      <td>5.195446</td>\n",
       "      <td>3.212117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>98.96</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>0.534919</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.665185</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>1.869442</td>\n",
       "      <td>0.040420</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>-0.439997</td>\n",
       "      <td>-0.096285</td>\n",
       "      <td>-7.824890</td>\n",
       "      <td>-3.938468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>23.38</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.206903</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.298889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.833191</td>\n",
       "      <td>0.470488</td>\n",
       "      <td>0.427716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.314018</td>\n",
       "      <td>-0.358384</td>\n",
       "      <td>-3.556854</td>\n",
       "      <td>-4.556876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4</td>\n",
       "      <td>1814</td>\n",
       "      <td>52.98</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.075385</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>34.239336</td>\n",
       "      <td>0.056625</td>\n",
       "      <td>0.132125</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.316169</td>\n",
       "      <td>0.028526</td>\n",
       "      <td>5.652216</td>\n",
       "      <td>5.887857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4</td>\n",
       "      <td>477</td>\n",
       "      <td>1.36</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.020964</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>350.735294</td>\n",
       "      <td>7.352941</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>-0.372219</td>\n",
       "      <td>-0.209986</td>\n",
       "      <td>-7.030723</td>\n",
       "      <td>-4.756164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6</td>\n",
       "      <td>1123</td>\n",
       "      <td>33.03</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.505000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>33.999394</td>\n",
       "      <td>0.302755</td>\n",
       "      <td>0.181653</td>\n",
       "      <td>0.090827</td>\n",
       "      <td>0.423091</td>\n",
       "      <td>-0.326854</td>\n",
       "      <td>8.459423</td>\n",
       "      <td>-1.171012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>1278</td>\n",
       "      <td>98.78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.077293</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.347500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>12.937842</td>\n",
       "      <td>0.020247</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>-0.312276</td>\n",
       "      <td>0.153726</td>\n",
       "      <td>-3.635951</td>\n",
       "      <td>3.682327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3</td>\n",
       "      <td>1171</td>\n",
       "      <td>90.98</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.686250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.870961</td>\n",
       "      <td>0.087931</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.511691</td>\n",
       "      <td>-0.128064</td>\n",
       "      <td>-7.756983</td>\n",
       "      <td>-1.314464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>1175</td>\n",
       "      <td>77.42</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.065889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.530000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>15.176957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.140036</td>\n",
       "      <td>-0.053956</td>\n",
       "      <td>0.583956</td>\n",
       "      <td>-0.297313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>1094</td>\n",
       "      <td>91.26</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.083419</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.037143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>11.987727</td>\n",
       "      <td>0.098619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032873</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>0.394974</td>\n",
       "      <td>-2.344936</td>\n",
       "      <td>4.863413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>990</td>\n",
       "      <td>19.42</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>50.978373</td>\n",
       "      <td>0.051493</td>\n",
       "      <td>0.360453</td>\n",
       "      <td>0.154480</td>\n",
       "      <td>-0.219253</td>\n",
       "      <td>0.421730</td>\n",
       "      <td>-4.529353</td>\n",
       "      <td>6.566694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>62.17</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.680270</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.143793</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.595142</td>\n",
       "      <td>0.144764</td>\n",
       "      <td>0.064340</td>\n",
       "      <td>0.064340</td>\n",
       "      <td>0.195995</td>\n",
       "      <td>-0.172074</td>\n",
       "      <td>3.783877</td>\n",
       "      <td>-3.970117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5</td>\n",
       "      <td>356</td>\n",
       "      <td>68.03</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.191096</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.718571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>5.232985</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.603364</td>\n",
       "      <td>0.049990</td>\n",
       "      <td>5.864615</td>\n",
       "      <td>-0.412701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6</td>\n",
       "      <td>493</td>\n",
       "      <td>86.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.174929</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.791111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>5.716605</td>\n",
       "      <td>0.069573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034787</td>\n",
       "      <td>0.203664</td>\n",
       "      <td>-0.357989</td>\n",
       "      <td>3.132778</td>\n",
       "      <td>-1.899959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>654</td>\n",
       "      <td>85.68</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.680000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>7.633053</td>\n",
       "      <td>0.046685</td>\n",
       "      <td>0.116713</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.599884</td>\n",
       "      <td>0.288805</td>\n",
       "      <td>10.029152</td>\n",
       "      <td>3.993459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>509</td>\n",
       "      <td>85.16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.167308</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.322500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>5.976984</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.058713</td>\n",
       "      <td>0.035228</td>\n",
       "      <td>-0.064162</td>\n",
       "      <td>0.289067</td>\n",
       "      <td>-1.892002</td>\n",
       "      <td>3.962385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>4</td>\n",
       "      <td>580</td>\n",
       "      <td>89.67</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.154603</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.274706</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>6.468161</td>\n",
       "      <td>0.033456</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>-0.154464</td>\n",
       "      <td>-0.262612</td>\n",
       "      <td>-5.020028</td>\n",
       "      <td>-4.164045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>435</td>\n",
       "      <td>9.79</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.052874</td>\n",
       "      <td>0.022506</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.425652</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>44.433095</td>\n",
       "      <td>0.204290</td>\n",
       "      <td>0.510725</td>\n",
       "      <td>0.408580</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.183129</td>\n",
       "      <td>0.855468</td>\n",
       "      <td>3.161745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>58.93</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.562174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>13.066350</td>\n",
       "      <td>0.135754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>-0.470037</td>\n",
       "      <td>-0.054661</td>\n",
       "      <td>-7.892016</td>\n",
       "      <td>-3.045475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5</td>\n",
       "      <td>1786</td>\n",
       "      <td>69.83</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.915000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>25.576400</td>\n",
       "      <td>0.085923</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>0.042961</td>\n",
       "      <td>0.538039</td>\n",
       "      <td>-0.126085</td>\n",
       "      <td>8.643748</td>\n",
       "      <td>0.354909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>485</td>\n",
       "      <td>17.63</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.036351</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>27.509926</td>\n",
       "      <td>0.567215</td>\n",
       "      <td>0.170164</td>\n",
       "      <td>0.283607</td>\n",
       "      <td>-0.045454</td>\n",
       "      <td>0.639408</td>\n",
       "      <td>-2.877071</td>\n",
       "      <td>8.670666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>690</td>\n",
       "      <td>58.35</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.084565</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.350000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>11.825193</td>\n",
       "      <td>0.137104</td>\n",
       "      <td>0.119966</td>\n",
       "      <td>0.051414</td>\n",
       "      <td>0.688224</td>\n",
       "      <td>-0.023057</td>\n",
       "      <td>9.598443</td>\n",
       "      <td>4.498495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6</td>\n",
       "      <td>1059</td>\n",
       "      <td>13.50</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.023607</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>78.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>-0.566241</td>\n",
       "      <td>-2.662472</td>\n",
       "      <td>-8.113151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>4</td>\n",
       "      <td>420</td>\n",
       "      <td>89.92</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.214095</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.087273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>4.670819</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.033363</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>-0.060080</td>\n",
       "      <td>1.573126</td>\n",
       "      <td>-0.938134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>1488</td>\n",
       "      <td>53.87</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.036203</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.071923</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>27.622053</td>\n",
       "      <td>0.129942</td>\n",
       "      <td>0.167069</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>-0.352221</td>\n",
       "      <td>-0.158487</td>\n",
       "      <td>-5.746249</td>\n",
       "      <td>-2.608056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5</td>\n",
       "      <td>827</td>\n",
       "      <td>40.50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024184</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.025000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>20.419753</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>-0.134363</td>\n",
       "      <td>4.178041</td>\n",
       "      <td>-4.973723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>13.58</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.790000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>49.263623</td>\n",
       "      <td>0.441826</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.166724</td>\n",
       "      <td>0.202663</td>\n",
       "      <td>-3.368636</td>\n",
       "      <td>1.122157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>4</td>\n",
       "      <td>270</td>\n",
       "      <td>78.69</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.291444</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.147600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>3.431186</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>-0.065074</td>\n",
       "      <td>-0.054270</td>\n",
       "      <td>1.674929</td>\n",
       "      <td>-0.762417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>48.17</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062232</td>\n",
       "      <td>0.103369</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.661034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.674071</td>\n",
       "      <td>0.166078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.594823</td>\n",
       "      <td>-0.346396</td>\n",
       "      <td>-6.933539</td>\n",
       "      <td>-5.509274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>959</td>\n",
       "      <td>11.63</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.465200</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.459157</td>\n",
       "      <td>0.515907</td>\n",
       "      <td>0.859845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.594076</td>\n",
       "      <td>-0.072731</td>\n",
       "      <td>-7.102866</td>\n",
       "      <td>1.122173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>282</td>\n",
       "      <td>70.79</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.251028</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.112857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>3.983614</td>\n",
       "      <td>0.056505</td>\n",
       "      <td>0.113010</td>\n",
       "      <td>0.056505</td>\n",
       "      <td>0.255659</td>\n",
       "      <td>0.427677</td>\n",
       "      <td>2.551279</td>\n",
       "      <td>5.520360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3</td>\n",
       "      <td>304</td>\n",
       "      <td>12.09</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029605</td>\n",
       "      <td>0.039770</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.343333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.144748</td>\n",
       "      <td>0.165426</td>\n",
       "      <td>0.661704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.345505</td>\n",
       "      <td>-0.139198</td>\n",
       "      <td>-4.167716</td>\n",
       "      <td>0.540601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>1237</td>\n",
       "      <td>96.40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.077930</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.771429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>12.831950</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.072192</td>\n",
       "      <td>0.199208</td>\n",
       "      <td>3.961724</td>\n",
       "      <td>5.320573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3</td>\n",
       "      <td>1152</td>\n",
       "      <td>91.91</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.079783</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.955000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>12.534001</td>\n",
       "      <td>0.108802</td>\n",
       "      <td>0.087042</td>\n",
       "      <td>0.054401</td>\n",
       "      <td>0.729235</td>\n",
       "      <td>0.449214</td>\n",
       "      <td>7.195333</td>\n",
       "      <td>3.121891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>92.86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.190513</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.095333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>0.053844</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.053844</td>\n",
       "      <td>0.309379</td>\n",
       "      <td>-0.069951</td>\n",
       "      <td>2.987622</td>\n",
       "      <td>-1.125592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5</td>\n",
       "      <td>726</td>\n",
       "      <td>12.28</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.364444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>59.120521</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>0.407166</td>\n",
       "      <td>0.325733</td>\n",
       "      <td>0.409993</td>\n",
       "      <td>-0.084070</td>\n",
       "      <td>4.961393</td>\n",
       "      <td>-3.539977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>414</td>\n",
       "      <td>98.72</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031401</td>\n",
       "      <td>0.238454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.593846</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>4.193679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>-0.326379</td>\n",
       "      <td>0.115879</td>\n",
       "      <td>-3.315692</td>\n",
       "      <td>3.210264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>898</td>\n",
       "      <td>2.64</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>340.151515</td>\n",
       "      <td>3.409091</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>1.893939</td>\n",
       "      <td>-0.113027</td>\n",
       "      <td>0.606027</td>\n",
       "      <td>-2.731879</td>\n",
       "      <td>8.654791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>788</td>\n",
       "      <td>80.87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.102627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.108750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>9.744034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098924</td>\n",
       "      <td>0.037097</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>0.479490</td>\n",
       "      <td>0.486314</td>\n",
       "      <td>4.017934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>1312</td>\n",
       "      <td>51.43</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.143000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>25.510402</td>\n",
       "      <td>0.136107</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>-0.509092</td>\n",
       "      <td>0.343767</td>\n",
       "      <td>-5.396738</td>\n",
       "      <td>2.116115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>81.05</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.764623</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.210000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>1.307835</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.338113</td>\n",
       "      <td>-0.128701</td>\n",
       "      <td>1.796333</td>\n",
       "      <td>-1.447730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4</td>\n",
       "      <td>921</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.695000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>271.681416</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>1.179941</td>\n",
       "      <td>0.589971</td>\n",
       "      <td>0.106477</td>\n",
       "      <td>-0.031264</td>\n",
       "      <td>-1.598890</td>\n",
       "      <td>-1.741543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>42.06</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.140669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.673333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>7.108892</td>\n",
       "      <td>0.213980</td>\n",
       "      <td>0.190204</td>\n",
       "      <td>0.071327</td>\n",
       "      <td>-0.052695</td>\n",
       "      <td>0.501894</td>\n",
       "      <td>-1.488741</td>\n",
       "      <td>4.413533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>1755</td>\n",
       "      <td>8.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.924444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>210.937500</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>0.458055</td>\n",
       "      <td>0.735757</td>\n",
       "      <td>10.523532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5</td>\n",
       "      <td>798</td>\n",
       "      <td>42.57</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.053346</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.520357</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>18.745595</td>\n",
       "      <td>0.258398</td>\n",
       "      <td>0.140944</td>\n",
       "      <td>0.093963</td>\n",
       "      <td>0.218758</td>\n",
       "      <td>-0.188690</td>\n",
       "      <td>5.473986</td>\n",
       "      <td>-4.980708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "      <td>37.25</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.097258</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.379630</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>10.281879</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>0.268456</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>-0.378128</td>\n",
       "      <td>0.273612</td>\n",
       "      <td>-6.979367</td>\n",
       "      <td>4.646704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>530</td>\n",
       "      <td>37.36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.049057</td>\n",
       "      <td>0.070491</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.436923</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>14.186296</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>-0.242783</td>\n",
       "      <td>0.255831</td>\n",
       "      <td>-4.272055</td>\n",
       "      <td>8.582722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5</td>\n",
       "      <td>1300</td>\n",
       "      <td>22.86</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.758462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>56.867892</td>\n",
       "      <td>0.131234</td>\n",
       "      <td>0.306212</td>\n",
       "      <td>0.131234</td>\n",
       "      <td>0.242220</td>\n",
       "      <td>-0.227259</td>\n",
       "      <td>8.688376</td>\n",
       "      <td>-3.238228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>4</td>\n",
       "      <td>1419</td>\n",
       "      <td>58.79</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.532222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>24.136758</td>\n",
       "      <td>0.119068</td>\n",
       "      <td>0.153087</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>-0.055481</td>\n",
       "      <td>-0.233830</td>\n",
       "      <td>-3.448108</td>\n",
       "      <td>-2.288245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3</td>\n",
       "      <td>1741</td>\n",
       "      <td>11.94</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>145.812395</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.418760</td>\n",
       "      <td>0.089835</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.781295</td>\n",
       "      <td>0.670698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>1035</td>\n",
       "      <td>61.75</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.059662</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.761134</td>\n",
       "      <td>0.129555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.570798</td>\n",
       "      <td>0.311459</td>\n",
       "      <td>-4.103974</td>\n",
       "      <td>3.622528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>818</td>\n",
       "      <td>88.58</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.921111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>9.234590</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>-0.136569</td>\n",
       "      <td>0.430927</td>\n",
       "      <td>-1.925032</td>\n",
       "      <td>4.237090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>93.103448</td>\n",
       "      <td>0.123153</td>\n",
       "      <td>0.123153</td>\n",
       "      <td>0.123153</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>-0.268841</td>\n",
       "      <td>-1.596551</td>\n",
       "      <td>-2.891938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2</td>\n",
       "      <td>735</td>\n",
       "      <td>89.47</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035374</td>\n",
       "      <td>0.121728</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.441154</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>8.215044</td>\n",
       "      <td>0.089415</td>\n",
       "      <td>0.100592</td>\n",
       "      <td>0.033531</td>\n",
       "      <td>-0.112171</td>\n",
       "      <td>0.209136</td>\n",
       "      <td>-5.801327</td>\n",
       "      <td>4.619169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>5</td>\n",
       "      <td>1262</td>\n",
       "      <td>81.87</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.148846</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.414682</td>\n",
       "      <td>0.048858</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430301</td>\n",
       "      <td>-0.533354</td>\n",
       "      <td>-4.721782</td>\n",
       "      <td>-8.500515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>1096</td>\n",
       "      <td>97.39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.491538</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>11.253722</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.449778</td>\n",
       "      <td>0.288271</td>\n",
       "      <td>-3.617204</td>\n",
       "      <td>3.726972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>4</td>\n",
       "      <td>767</td>\n",
       "      <td>9.18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.483158</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>83.551198</td>\n",
       "      <td>0.871460</td>\n",
       "      <td>0.871460</td>\n",
       "      <td>0.326797</td>\n",
       "      <td>0.086161</td>\n",
       "      <td>-0.079241</td>\n",
       "      <td>1.167066</td>\n",
       "      <td>0.728088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>6</td>\n",
       "      <td>1668</td>\n",
       "      <td>73.58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.044113</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.503810</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>22.669204</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>0.067953</td>\n",
       "      <td>0.040772</td>\n",
       "      <td>0.244189</td>\n",
       "      <td>-0.441749</td>\n",
       "      <td>3.539133</td>\n",
       "      <td>-8.199971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>6</td>\n",
       "      <td>488</td>\n",
       "      <td>38.44</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.047131</td>\n",
       "      <td>0.078770</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.671304</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>12.695109</td>\n",
       "      <td>0.208117</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>-0.021262</td>\n",
       "      <td>-0.478686</td>\n",
       "      <td>-0.370039</td>\n",
       "      <td>-5.817025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>1424</td>\n",
       "      <td>39.11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.259167</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>36.410125</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>0.255689</td>\n",
       "      <td>0.127845</td>\n",
       "      <td>0.436242</td>\n",
       "      <td>0.282948</td>\n",
       "      <td>5.289671</td>\n",
       "      <td>6.500751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>3</td>\n",
       "      <td>1518</td>\n",
       "      <td>81.03</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.053379</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.010000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>18.733802</td>\n",
       "      <td>0.098729</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.048182</td>\n",
       "      <td>0.129987</td>\n",
       "      <td>-1.545491</td>\n",
       "      <td>2.647589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2</td>\n",
       "      <td>569</td>\n",
       "      <td>32.98</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049209</td>\n",
       "      <td>0.057961</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.177857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.252881</td>\n",
       "      <td>0.121286</td>\n",
       "      <td>0.121286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.711949</td>\n",
       "      <td>-0.038300</td>\n",
       "      <td>-10.367793</td>\n",
       "      <td>-0.047320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3</td>\n",
       "      <td>1504</td>\n",
       "      <td>98.66</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.065598</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.289565</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.244273</td>\n",
       "      <td>0.070951</td>\n",
       "      <td>0.040543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.531961</td>\n",
       "      <td>-0.198836</td>\n",
       "      <td>-7.749126</td>\n",
       "      <td>-1.247620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3</td>\n",
       "      <td>1059</td>\n",
       "      <td>36.28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.034259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.140000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>29.189636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165380</td>\n",
       "      <td>0.110254</td>\n",
       "      <td>0.426205</td>\n",
       "      <td>0.322331</td>\n",
       "      <td>5.788334</td>\n",
       "      <td>7.497890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>51.58</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.636790</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.438667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>1.570376</td>\n",
       "      <td>0.174486</td>\n",
       "      <td>0.058162</td>\n",
       "      <td>0.096937</td>\n",
       "      <td>0.385382</td>\n",
       "      <td>0.181069</td>\n",
       "      <td>3.881656</td>\n",
       "      <td>1.277513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>4</td>\n",
       "      <td>1235</td>\n",
       "      <td>40.55</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.032834</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.550000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>30.456227</td>\n",
       "      <td>0.221948</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.123305</td>\n",
       "      <td>0.803163</td>\n",
       "      <td>0.398675</td>\n",
       "      <td>9.504715</td>\n",
       "      <td>5.486778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2</td>\n",
       "      <td>297</td>\n",
       "      <td>91.67</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>0.308653</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.666800</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>3.239882</td>\n",
       "      <td>0.054543</td>\n",
       "      <td>0.065452</td>\n",
       "      <td>0.043635</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.334092</td>\n",
       "      <td>0.579984</td>\n",
       "      <td>4.064927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>75.74</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>37.870000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.467500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.079218</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>-0.490288</td>\n",
       "      <td>-0.092458</td>\n",
       "      <td>-2.715019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>91.74</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.159271</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.340000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>6.278613</td>\n",
       "      <td>0.032701</td>\n",
       "      <td>0.043601</td>\n",
       "      <td>0.032701</td>\n",
       "      <td>-0.020109</td>\n",
       "      <td>0.329277</td>\n",
       "      <td>-2.429409</td>\n",
       "      <td>3.973566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>85.10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>0.074323</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.052381</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.454759</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.228264</td>\n",
       "      <td>-0.576476</td>\n",
       "      <td>-0.325787</td>\n",
       "      <td>-8.784315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>5</td>\n",
       "      <td>1138</td>\n",
       "      <td>78.70</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>0.069156</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.747619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.459975</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.063532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305047</td>\n",
       "      <td>-0.540129</td>\n",
       "      <td>-1.390865</td>\n",
       "      <td>-8.533010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>1075</td>\n",
       "      <td>31.95</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.389130</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.646322</td>\n",
       "      <td>0.093897</td>\n",
       "      <td>0.250391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.688529</td>\n",
       "      <td>0.117228</td>\n",
       "      <td>-7.424583</td>\n",
       "      <td>1.882678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>1382</td>\n",
       "      <td>36.76</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>0.026599</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.598261</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>37.595212</td>\n",
       "      <td>0.136017</td>\n",
       "      <td>0.190424</td>\n",
       "      <td>0.027203</td>\n",
       "      <td>-0.555546</td>\n",
       "      <td>0.217975</td>\n",
       "      <td>-7.575817</td>\n",
       "      <td>1.317277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3</td>\n",
       "      <td>876</td>\n",
       "      <td>42.68</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.048721</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>20.524836</td>\n",
       "      <td>0.210872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046860</td>\n",
       "      <td>-0.195174</td>\n",
       "      <td>0.108309</td>\n",
       "      <td>-5.592241</td>\n",
       "      <td>-0.922888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>89.69</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.114155</td>\n",
       "      <td>0.409543</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.587600</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>2.441744</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.049084</td>\n",
       "      <td>0.605592</td>\n",
       "      <td>0.597274</td>\n",
       "      <td>4.273287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>5</td>\n",
       "      <td>1439</td>\n",
       "      <td>36.09</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>39.872541</td>\n",
       "      <td>0.083126</td>\n",
       "      <td>0.138543</td>\n",
       "      <td>0.138543</td>\n",
       "      <td>0.575134</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>8.829349</td>\n",
       "      <td>-2.880936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2</td>\n",
       "      <td>1818</td>\n",
       "      <td>79.15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.575000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.969046</td>\n",
       "      <td>0.075805</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.345497</td>\n",
       "      <td>0.107747</td>\n",
       "      <td>-3.646421</td>\n",
       "      <td>2.085031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>41.93</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.096330</td>\n",
       "      <td>0.192339</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.996667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.032110</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>5.199141</td>\n",
       "      <td>0.095397</td>\n",
       "      <td>0.166945</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>-0.363598</td>\n",
       "      <td>0.336916</td>\n",
       "      <td>-6.570127</td>\n",
       "      <td>5.012038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>5</td>\n",
       "      <td>793</td>\n",
       "      <td>10.30</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>76.990291</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>-0.144783</td>\n",
       "      <td>-0.397530</td>\n",
       "      <td>-2.512090</td>\n",
       "      <td>-6.279280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>4</td>\n",
       "      <td>1437</td>\n",
       "      <td>92.55</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014614</td>\n",
       "      <td>0.064405</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.407143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>15.526742</td>\n",
       "      <td>0.118855</td>\n",
       "      <td>0.064830</td>\n",
       "      <td>0.054025</td>\n",
       "      <td>0.380279</td>\n",
       "      <td>0.100788</td>\n",
       "      <td>4.715898</td>\n",
       "      <td>0.877072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2</td>\n",
       "      <td>542</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>24.196429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.376476</td>\n",
       "      <td>0.639838</td>\n",
       "      <td>4.240830</td>\n",
       "      <td>9.109758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>6</td>\n",
       "      <td>1559</td>\n",
       "      <td>68.32</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.043823</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.846667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>22.819087</td>\n",
       "      <td>0.161007</td>\n",
       "      <td>0.117096</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.556722</td>\n",
       "      <td>-0.275797</td>\n",
       "      <td>6.351814</td>\n",
       "      <td>-5.126266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>6</td>\n",
       "      <td>671</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>958.571429</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.213352</td>\n",
       "      <td>-0.408419</td>\n",
       "      <td>4.726093</td>\n",
       "      <td>-4.863047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5</td>\n",
       "      <td>641</td>\n",
       "      <td>79.14</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.123463</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.826429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>8.099570</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.075815</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>-0.201755</td>\n",
       "      <td>-0.488956</td>\n",
       "      <td>-0.871901</td>\n",
       "      <td>-9.763773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2</td>\n",
       "      <td>277</td>\n",
       "      <td>76.34</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0.275596</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.905714</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.628504</td>\n",
       "      <td>0.065496</td>\n",
       "      <td>0.130993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.330713</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>-3.310713</td>\n",
       "      <td>2.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5</td>\n",
       "      <td>1719</td>\n",
       "      <td>94.59</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.055026</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.756429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>18.173168</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.063432</td>\n",
       "      <td>0.031716</td>\n",
       "      <td>0.259618</td>\n",
       "      <td>-0.241790</td>\n",
       "      <td>4.107404</td>\n",
       "      <td>-8.055572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>77.28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044177</td>\n",
       "      <td>0.310361</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.025455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>3.222050</td>\n",
       "      <td>0.116460</td>\n",
       "      <td>0.038820</td>\n",
       "      <td>0.051760</td>\n",
       "      <td>0.105041</td>\n",
       "      <td>0.450405</td>\n",
       "      <td>2.992060</td>\n",
       "      <td>4.516937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2</td>\n",
       "      <td>1803</td>\n",
       "      <td>7.51</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.682727</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.079893</td>\n",
       "      <td>0.798935</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.597277</td>\n",
       "      <td>0.058014</td>\n",
       "      <td>-8.218086</td>\n",
       "      <td>0.839357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>79.75</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.291667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>2.068966</td>\n",
       "      <td>0.025078</td>\n",
       "      <td>0.087774</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.552467</td>\n",
       "      <td>-0.074452</td>\n",
       "      <td>8.332582</td>\n",
       "      <td>-0.209721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5</td>\n",
       "      <td>1726</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.107143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>222.709677</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.267547</td>\n",
       "      <td>-0.179935</td>\n",
       "      <td>8.991406</td>\n",
       "      <td>-3.064890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>1767</td>\n",
       "      <td>25.97</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.014697</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.623125</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>68.040046</td>\n",
       "      <td>0.269542</td>\n",
       "      <td>0.192530</td>\n",
       "      <td>0.038506</td>\n",
       "      <td>-0.431857</td>\n",
       "      <td>0.100341</td>\n",
       "      <td>-7.490434</td>\n",
       "      <td>-0.109199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>65.47</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.211194</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.091875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>4.734993</td>\n",
       "      <td>0.076371</td>\n",
       "      <td>0.076371</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>-0.329633</td>\n",
       "      <td>0.379453</td>\n",
       "      <td>-4.114715</td>\n",
       "      <td>4.655803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4</td>\n",
       "      <td>1320</td>\n",
       "      <td>77.93</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017424</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.388261</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>16.938278</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>0.076992</td>\n",
       "      <td>0.012832</td>\n",
       "      <td>-0.255489</td>\n",
       "      <td>-0.294544</td>\n",
       "      <td>-5.115529</td>\n",
       "      <td>-3.438505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>796</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031407</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.702128</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.733890</td>\n",
       "      <td>-0.011076</td>\n",
       "      <td>-10.176246</td>\n",
       "      <td>-0.092242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>5</td>\n",
       "      <td>1559</td>\n",
       "      <td>61.66</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.276667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>25.283814</td>\n",
       "      <td>0.113526</td>\n",
       "      <td>0.081090</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.168236</td>\n",
       "      <td>-0.258277</td>\n",
       "      <td>1.364899</td>\n",
       "      <td>-4.625308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2</td>\n",
       "      <td>373</td>\n",
       "      <td>28.95</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.077614</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.158000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>12.884283</td>\n",
       "      <td>0.172712</td>\n",
       "      <td>0.069085</td>\n",
       "      <td>0.138169</td>\n",
       "      <td>-0.105431</td>\n",
       "      <td>0.373711</td>\n",
       "      <td>-3.324956</td>\n",
       "      <td>9.007625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>4</td>\n",
       "      <td>1221</td>\n",
       "      <td>93.06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.076216</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.158462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.120567</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.357284</td>\n",
       "      <td>-0.304311</td>\n",
       "      <td>-4.969786</td>\n",
       "      <td>-1.734718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3</td>\n",
       "      <td>460</td>\n",
       "      <td>50.97</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.110804</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.485000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>9.024917</td>\n",
       "      <td>0.176574</td>\n",
       "      <td>0.176574</td>\n",
       "      <td>0.078478</td>\n",
       "      <td>0.540127</td>\n",
       "      <td>0.342768</td>\n",
       "      <td>7.439904</td>\n",
       "      <td>3.267590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>66.64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.404444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.366146</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.045018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.212900</td>\n",
       "      <td>-0.458819</td>\n",
       "      <td>-1.237503</td>\n",
       "      <td>-3.121529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>1054</td>\n",
       "      <td>75.58</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.071708</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.435455</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>13.945488</td>\n",
       "      <td>0.145541</td>\n",
       "      <td>0.066155</td>\n",
       "      <td>0.052924</td>\n",
       "      <td>-0.098072</td>\n",
       "      <td>0.532812</td>\n",
       "      <td>-0.760610</td>\n",
       "      <td>5.651563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>49.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.248687</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.206667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>4.021121</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>0.081235</td>\n",
       "      <td>0.028293</td>\n",
       "      <td>0.660552</td>\n",
       "      <td>0.623692</td>\n",
       "      <td>9.496644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>524</td>\n",
       "      <td>38.78</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.846667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>13.512120</td>\n",
       "      <td>0.283651</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>-0.294928</td>\n",
       "      <td>0.473226</td>\n",
       "      <td>-5.830924</td>\n",
       "      <td>7.397348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>58.21</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.850833</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.029070</td>\n",
       "      <td>2.954819</td>\n",
       "      <td>0.137433</td>\n",
       "      <td>0.120254</td>\n",
       "      <td>0.085896</td>\n",
       "      <td>0.692629</td>\n",
       "      <td>-0.181283</td>\n",
       "      <td>7.142001</td>\n",
       "      <td>-2.879942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>5</td>\n",
       "      <td>1049</td>\n",
       "      <td>77.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.074175</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.968333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.481558</td>\n",
       "      <td>0.025704</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.090362</td>\n",
       "      <td>-0.472130</td>\n",
       "      <td>-0.026553</td>\n",
       "      <td>-6.059668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>6</td>\n",
       "      <td>1603</td>\n",
       "      <td>47.86</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.029857</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.860000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>33.493523</td>\n",
       "      <td>0.188048</td>\n",
       "      <td>0.188048</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.821403</td>\n",
       "      <td>-0.216518</td>\n",
       "      <td>9.506143</td>\n",
       "      <td>4.860652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4</td>\n",
       "      <td>1718</td>\n",
       "      <td>43.52</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.025332</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.176000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.476103</td>\n",
       "      <td>0.068934</td>\n",
       "      <td>0.137868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.402355</td>\n",
       "      <td>-0.375994</td>\n",
       "      <td>-6.078195</td>\n",
       "      <td>-3.374632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>4</td>\n",
       "      <td>813</td>\n",
       "      <td>59.43</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.962000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>13.679960</td>\n",
       "      <td>0.134612</td>\n",
       "      <td>0.151439</td>\n",
       "      <td>0.033653</td>\n",
       "      <td>0.030289</td>\n",
       "      <td>-0.164770</td>\n",
       "      <td>-2.542218</td>\n",
       "      <td>-3.789164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>5</td>\n",
       "      <td>1399</td>\n",
       "      <td>61.58</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.848750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>22.718415</td>\n",
       "      <td>0.081195</td>\n",
       "      <td>0.162390</td>\n",
       "      <td>0.081195</td>\n",
       "      <td>0.592663</td>\n",
       "      <td>-0.083170</td>\n",
       "      <td>8.219877</td>\n",
       "      <td>-4.659767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>5</td>\n",
       "      <td>1151</td>\n",
       "      <td>97.79</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.752353</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>11.770120</td>\n",
       "      <td>0.061356</td>\n",
       "      <td>0.081808</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>-0.043865</td>\n",
       "      <td>-0.446258</td>\n",
       "      <td>-0.713012</td>\n",
       "      <td>-7.624638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>909</td>\n",
       "      <td>64.11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.070528</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.822000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>14.178755</td>\n",
       "      <td>0.124786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046795</td>\n",
       "      <td>-0.127199</td>\n",
       "      <td>0.586495</td>\n",
       "      <td>-2.583321</td>\n",
       "      <td>5.090178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>704</td>\n",
       "      <td>23.16</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>30.397237</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>0.345423</td>\n",
       "      <td>0.129534</td>\n",
       "      <td>-0.305809</td>\n",
       "      <td>0.364799</td>\n",
       "      <td>-4.298893</td>\n",
       "      <td>6.498619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2</td>\n",
       "      <td>1530</td>\n",
       "      <td>8.91</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.445500</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>171.717172</td>\n",
       "      <td>0.448934</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>-0.210702</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>-3.112764</td>\n",
       "      <td>7.916149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>25.19</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>1.937692</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.325789</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.396983</td>\n",
       "      <td>0.198491</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>-0.353866</td>\n",
       "      <td>-0.056935</td>\n",
       "      <td>-5.119524</td>\n",
       "      <td>-1.171766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1</td>\n",
       "      <td>636</td>\n",
       "      <td>38.87</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.061116</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.159444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>16.362233</td>\n",
       "      <td>0.205814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102907</td>\n",
       "      <td>-0.159497</td>\n",
       "      <td>0.601737</td>\n",
       "      <td>-3.708540</td>\n",
       "      <td>7.511072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>6</td>\n",
       "      <td>1434</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217776</td>\n",
       "      <td>-0.751101</td>\n",
       "      <td>-2.835485</td>\n",
       "      <td>-9.537176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2</td>\n",
       "      <td>1459</td>\n",
       "      <td>77.21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.052920</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.969615</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>18.896516</td>\n",
       "      <td>0.051807</td>\n",
       "      <td>0.012952</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>-0.418173</td>\n",
       "      <td>0.166812</td>\n",
       "      <td>-9.945929</td>\n",
       "      <td>1.551949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5</td>\n",
       "      <td>1123</td>\n",
       "      <td>58.90</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021371</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.454167</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>19.066214</td>\n",
       "      <td>0.135823</td>\n",
       "      <td>0.152801</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>-0.132056</td>\n",
       "      <td>-0.484805</td>\n",
       "      <td>-1.851567</td>\n",
       "      <td>-7.518911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>6</td>\n",
       "      <td>1100</td>\n",
       "      <td>26.82</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.957857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>41.014169</td>\n",
       "      <td>0.298285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>-0.107010</td>\n",
       "      <td>-0.504705</td>\n",
       "      <td>1.657752</td>\n",
       "      <td>-5.830951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>4</td>\n",
       "      <td>352</td>\n",
       "      <td>21.69</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.061619</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.098571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.228677</td>\n",
       "      <td>0.461042</td>\n",
       "      <td>0.322729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.239579</td>\n",
       "      <td>-0.274911</td>\n",
       "      <td>-3.141572</td>\n",
       "      <td>-3.382677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1</td>\n",
       "      <td>473</td>\n",
       "      <td>15.14</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.582308</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.241744</td>\n",
       "      <td>0.726552</td>\n",
       "      <td>0.066050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.859299</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>-9.536509</td>\n",
       "      <td>2.686756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2</td>\n",
       "      <td>1597</td>\n",
       "      <td>11.14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013776</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.506364</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>143.357271</td>\n",
       "      <td>0.179533</td>\n",
       "      <td>0.448833</td>\n",
       "      <td>0.448833</td>\n",
       "      <td>0.112596</td>\n",
       "      <td>0.437069</td>\n",
       "      <td>1.333900</td>\n",
       "      <td>4.482952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>-0.182738</td>\n",
       "      <td>0.508154</td>\n",
       "      <td>-2.868293</td>\n",
       "      <td>8.314009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>4</td>\n",
       "      <td>1821</td>\n",
       "      <td>91.48</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.050236</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.717500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>19.905990</td>\n",
       "      <td>0.076519</td>\n",
       "      <td>0.109314</td>\n",
       "      <td>0.043725</td>\n",
       "      <td>0.356692</td>\n",
       "      <td>-0.010687</td>\n",
       "      <td>5.215620</td>\n",
       "      <td>-0.310604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>5</td>\n",
       "      <td>709</td>\n",
       "      <td>22.50</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028209</td>\n",
       "      <td>0.031735</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.511111</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.280513</td>\n",
       "      <td>-0.536580</td>\n",
       "      <td>-3.334269</td>\n",
       "      <td>-5.846305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>1537</td>\n",
       "      <td>38.44</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017567</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.423704</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>39.984391</td>\n",
       "      <td>0.130073</td>\n",
       "      <td>0.156087</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>-0.616972</td>\n",
       "      <td>0.202555</td>\n",
       "      <td>-7.781018</td>\n",
       "      <td>1.246108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>3</td>\n",
       "      <td>691</td>\n",
       "      <td>33.87</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.049016</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.612857</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>20.401535</td>\n",
       "      <td>0.265722</td>\n",
       "      <td>0.147623</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>-0.376250</td>\n",
       "      <td>-0.080296</td>\n",
       "      <td>-5.004246</td>\n",
       "      <td>-3.841211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2</td>\n",
       "      <td>1698</td>\n",
       "      <td>7.59</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.399474</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>223.715415</td>\n",
       "      <td>0.790514</td>\n",
       "      <td>0.922266</td>\n",
       "      <td>0.658762</td>\n",
       "      <td>0.174091</td>\n",
       "      <td>0.443350</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>7.394534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>6</td>\n",
       "      <td>1698</td>\n",
       "      <td>32.22</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>52.700186</td>\n",
       "      <td>0.124146</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.591725</td>\n",
       "      <td>-0.215112</td>\n",
       "      <td>10.255687</td>\n",
       "      <td>-0.400055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>21.51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.125789</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.265294</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>7.949791</td>\n",
       "      <td>0.046490</td>\n",
       "      <td>0.139470</td>\n",
       "      <td>0.232450</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.327714</td>\n",
       "      <td>1.821976</td>\n",
       "      <td>2.098419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>4</td>\n",
       "      <td>216</td>\n",
       "      <td>77.45</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.358565</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.302778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2.788896</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>0.119111</td>\n",
       "      <td>-0.065458</td>\n",
       "      <td>1.690947</td>\n",
       "      <td>-0.484340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>5</td>\n",
       "      <td>1026</td>\n",
       "      <td>24.44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022417</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.062609</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.980360</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.397359</td>\n",
       "      <td>-0.526416</td>\n",
       "      <td>-5.632982</td>\n",
       "      <td>-8.024721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2</td>\n",
       "      <td>1660</td>\n",
       "      <td>13.69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.651905</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>121.256392</td>\n",
       "      <td>0.073046</td>\n",
       "      <td>0.219138</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.369733</td>\n",
       "      <td>0.175326</td>\n",
       "      <td>-6.692914</td>\n",
       "      <td>6.302953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>6.72</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235772</td>\n",
       "      <td>0.054634</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.231724</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>18.303571</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>1.339286</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.156864</td>\n",
       "      <td>-0.046521</td>\n",
       "      <td>0.858162</td>\n",
       "      <td>0.297015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5</td>\n",
       "      <td>635</td>\n",
       "      <td>52.23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.801034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.014173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>12.157764</td>\n",
       "      <td>0.172315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095730</td>\n",
       "      <td>0.264877</td>\n",
       "      <td>-0.052284</td>\n",
       "      <td>3.227093</td>\n",
       "      <td>-3.775783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>4</td>\n",
       "      <td>942</td>\n",
       "      <td>90.29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.095849</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.311176</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>10.433049</td>\n",
       "      <td>0.077528</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.055377</td>\n",
       "      <td>0.345028</td>\n",
       "      <td>0.165763</td>\n",
       "      <td>3.332519</td>\n",
       "      <td>-0.751171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>4</td>\n",
       "      <td>581</td>\n",
       "      <td>87.17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032702</td>\n",
       "      <td>0.150034</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.587895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>6.665137</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>-0.248055</td>\n",
       "      <td>-0.243492</td>\n",
       "      <td>-7.507785</td>\n",
       "      <td>-4.939148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>63.23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.144032</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.903750</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.022779</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>6.942907</td>\n",
       "      <td>0.158153</td>\n",
       "      <td>0.047446</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>-0.273864</td>\n",
       "      <td>0.453134</td>\n",
       "      <td>-3.315823</td>\n",
       "      <td>5.038301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>5</td>\n",
       "      <td>1469</td>\n",
       "      <td>91.79</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.370952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>16.003922</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.215929</td>\n",
       "      <td>-0.294256</td>\n",
       "      <td>4.382703</td>\n",
       "      <td>-8.236549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>511</td>\n",
       "      <td>28.39</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.023483</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.365833</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>17.999296</td>\n",
       "      <td>0.352237</td>\n",
       "      <td>0.176118</td>\n",
       "      <td>0.070447</td>\n",
       "      <td>-0.315268</td>\n",
       "      <td>0.413079</td>\n",
       "      <td>-4.469857</td>\n",
       "      <td>4.931880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>6</td>\n",
       "      <td>1796</td>\n",
       "      <td>10.77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.196667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>166.759517</td>\n",
       "      <td>0.092851</td>\n",
       "      <td>0.185701</td>\n",
       "      <td>0.371402</td>\n",
       "      <td>0.438665</td>\n",
       "      <td>-0.248685</td>\n",
       "      <td>4.155362</td>\n",
       "      <td>-4.729152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>3</td>\n",
       "      <td>440</td>\n",
       "      <td>49.34</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.112136</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.868000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>8.917714</td>\n",
       "      <td>0.060803</td>\n",
       "      <td>0.101338</td>\n",
       "      <td>0.101338</td>\n",
       "      <td>0.473912</td>\n",
       "      <td>0.392202</td>\n",
       "      <td>4.476445</td>\n",
       "      <td>8.122116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>4</td>\n",
       "      <td>467</td>\n",
       "      <td>94.13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>0.201563</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.954211</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>4.961224</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.095612</td>\n",
       "      <td>0.042494</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>-0.007882</td>\n",
       "      <td>3.609606</td>\n",
       "      <td>1.583378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>20.05</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.542308</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>18.204489</td>\n",
       "      <td>0.399002</td>\n",
       "      <td>0.498753</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>-0.142716</td>\n",
       "      <td>0.192607</td>\n",
       "      <td>-1.526207</td>\n",
       "      <td>4.352262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5</td>\n",
       "      <td>1720</td>\n",
       "      <td>86.84</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.050488</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.108235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>19.806541</td>\n",
       "      <td>0.046062</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>0.034546</td>\n",
       "      <td>0.126261</td>\n",
       "      <td>-0.210574</td>\n",
       "      <td>2.332018</td>\n",
       "      <td>-7.445746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1</td>\n",
       "      <td>612</td>\n",
       "      <td>31.64</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.051699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.955000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011438</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>19.342604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.126422</td>\n",
       "      <td>0.093240</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>2.694578</td>\n",
       "      <td>7.484076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>3</td>\n",
       "      <td>790</td>\n",
       "      <td>84.05</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.106392</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.423684</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.399167</td>\n",
       "      <td>0.047591</td>\n",
       "      <td>0.071386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.451531</td>\n",
       "      <td>-0.187747</td>\n",
       "      <td>-5.593681</td>\n",
       "      <td>-4.102057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>65.62</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.988485</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.620000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.502895</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.234001</td>\n",
       "      <td>10.107505</td>\n",
       "      <td>4.188853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>3</td>\n",
       "      <td>1740</td>\n",
       "      <td>46.09</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.711176</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>37.752224</td>\n",
       "      <td>0.065090</td>\n",
       "      <td>0.173573</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>-0.274702</td>\n",
       "      <td>-0.111477</td>\n",
       "      <td>-5.332667</td>\n",
       "      <td>-2.619901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>2</td>\n",
       "      <td>1023</td>\n",
       "      <td>73.78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.072121</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.593333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>13.865546</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.040661</td>\n",
       "      <td>0.054215</td>\n",
       "      <td>0.251395</td>\n",
       "      <td>0.498596</td>\n",
       "      <td>3.721334</td>\n",
       "      <td>7.331653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>4</td>\n",
       "      <td>1826</td>\n",
       "      <td>79.52</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.043549</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.976000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>22.962777</td>\n",
       "      <td>0.113179</td>\n",
       "      <td>0.100604</td>\n",
       "      <td>0.025151</td>\n",
       "      <td>-0.043263</td>\n",
       "      <td>-0.199545</td>\n",
       "      <td>2.167970</td>\n",
       "      <td>-4.469305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>3</td>\n",
       "      <td>1422</td>\n",
       "      <td>6.21</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.105000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>228.985507</td>\n",
       "      <td>1.288245</td>\n",
       "      <td>1.127214</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>0.260491</td>\n",
       "      <td>0.233444</td>\n",
       "      <td>6.937700</td>\n",
       "      <td>4.085793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>6</td>\n",
       "      <td>1200</td>\n",
       "      <td>19.99</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.221111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>60.030015</td>\n",
       "      <td>0.350175</td>\n",
       "      <td>0.450225</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.578059</td>\n",
       "      <td>-0.285894</td>\n",
       "      <td>8.988087</td>\n",
       "      <td>-1.957669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1</td>\n",
       "      <td>808</td>\n",
       "      <td>11.71</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.975833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>69.000854</td>\n",
       "      <td>0.853971</td>\n",
       "      <td>0.341588</td>\n",
       "      <td>0.170794</td>\n",
       "      <td>-0.348468</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>-4.554185</td>\n",
       "      <td>5.093735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>2</td>\n",
       "      <td>410</td>\n",
       "      <td>62.06</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.151366</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.206000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>6.606510</td>\n",
       "      <td>0.145021</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>0.080567</td>\n",
       "      <td>0.279669</td>\n",
       "      <td>0.542635</td>\n",
       "      <td>3.313810</td>\n",
       "      <td>4.692804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>5</td>\n",
       "      <td>1413</td>\n",
       "      <td>28.11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.342500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>50.266809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.071149</td>\n",
       "      <td>0.049803</td>\n",
       "      <td>-0.298965</td>\n",
       "      <td>-0.488760</td>\n",
       "      <td>-3.202621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>6</td>\n",
       "      <td>421</td>\n",
       "      <td>21.09</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.047506</td>\n",
       "      <td>0.050095</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.054500</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>19.962067</td>\n",
       "      <td>0.379327</td>\n",
       "      <td>0.331911</td>\n",
       "      <td>0.189663</td>\n",
       "      <td>0.414502</td>\n",
       "      <td>-0.322570</td>\n",
       "      <td>6.540448</td>\n",
       "      <td>-4.044611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>6</td>\n",
       "      <td>1060</td>\n",
       "      <td>99.75</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.094104</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.650000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>10.626566</td>\n",
       "      <td>0.080201</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.032633</td>\n",
       "      <td>-0.551605</td>\n",
       "      <td>-0.728704</td>\n",
       "      <td>-4.917994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>79.66</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>7.241818</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.319167</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.138087</td>\n",
       "      <td>0.012553</td>\n",
       "      <td>0.062767</td>\n",
       "      <td>0.050213</td>\n",
       "      <td>0.290346</td>\n",
       "      <td>-0.169694</td>\n",
       "      <td>2.683262</td>\n",
       "      <td>-3.263415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>3</td>\n",
       "      <td>448</td>\n",
       "      <td>65.18</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037946</td>\n",
       "      <td>0.145491</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.834118</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>6.873274</td>\n",
       "      <td>0.030684</td>\n",
       "      <td>0.061369</td>\n",
       "      <td>0.076711</td>\n",
       "      <td>0.296002</td>\n",
       "      <td>0.312681</td>\n",
       "      <td>2.349315</td>\n",
       "      <td>0.667151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>5</td>\n",
       "      <td>1814</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.092500</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>216.726404</td>\n",
       "      <td>0.955795</td>\n",
       "      <td>0.716846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140908</td>\n",
       "      <td>-0.442109</td>\n",
       "      <td>-0.201772</td>\n",
       "      <td>-5.778431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>5</td>\n",
       "      <td>1184</td>\n",
       "      <td>88.05</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.074367</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.179412</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>13.446905</td>\n",
       "      <td>0.068143</td>\n",
       "      <td>0.090857</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>0.564043</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>7.835642</td>\n",
       "      <td>-1.934593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>6</td>\n",
       "      <td>1704</td>\n",
       "      <td>94.06</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.757500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>18.116096</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.460068</td>\n",
       "      <td>2.973524</td>\n",
       "      <td>-5.713658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>6</td>\n",
       "      <td>1488</td>\n",
       "      <td>41.73</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.477500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>35.657800</td>\n",
       "      <td>0.071891</td>\n",
       "      <td>0.215672</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>-0.603257</td>\n",
       "      <td>-0.054480</td>\n",
       "      <td>-7.985208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>3</td>\n",
       "      <td>527</td>\n",
       "      <td>80.08</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.151954</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.005000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>6.580919</td>\n",
       "      <td>0.137363</td>\n",
       "      <td>0.062438</td>\n",
       "      <td>0.062438</td>\n",
       "      <td>0.326105</td>\n",
       "      <td>0.324666</td>\n",
       "      <td>3.591532</td>\n",
       "      <td>2.032002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>3</td>\n",
       "      <td>1116</td>\n",
       "      <td>24.18</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.612000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>0.289495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.435748</td>\n",
       "      <td>-0.169103</td>\n",
       "      <td>-4.761547</td>\n",
       "      <td>-1.645827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>3</td>\n",
       "      <td>245</td>\n",
       "      <td>21.93</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>0.089510</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.482500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>11.171911</td>\n",
       "      <td>0.227998</td>\n",
       "      <td>0.227998</td>\n",
       "      <td>0.182399</td>\n",
       "      <td>0.318574</td>\n",
       "      <td>0.315980</td>\n",
       "      <td>2.291291</td>\n",
       "      <td>7.499232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>1</td>\n",
       "      <td>1814</td>\n",
       "      <td>91.08</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.050209</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.080000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.916557</td>\n",
       "      <td>0.043917</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.311164</td>\n",
       "      <td>0.302855</td>\n",
       "      <td>7.852192</td>\n",
       "      <td>4.638669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>4</td>\n",
       "      <td>1480</td>\n",
       "      <td>65.67</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020270</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.189000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>22.536927</td>\n",
       "      <td>0.030455</td>\n",
       "      <td>0.106594</td>\n",
       "      <td>0.076138</td>\n",
       "      <td>0.290276</td>\n",
       "      <td>0.028462</td>\n",
       "      <td>3.937660</td>\n",
       "      <td>0.784167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>5</td>\n",
       "      <td>1273</td>\n",
       "      <td>19.48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.019639</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>65.349076</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.102669</td>\n",
       "      <td>0.154004</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>-0.254663</td>\n",
       "      <td>2.987555</td>\n",
       "      <td>-5.197160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>5</td>\n",
       "      <td>1232</td>\n",
       "      <td>47.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.575000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>26.129374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.084836</td>\n",
       "      <td>0.514267</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>5.162522</td>\n",
       "      <td>-2.809939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20.01</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.053158</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.949525</td>\n",
       "      <td>0.349825</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.654406</td>\n",
       "      <td>0.424095</td>\n",
       "      <td>9.175161</td>\n",
       "      <td>5.486211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>4</td>\n",
       "      <td>919</td>\n",
       "      <td>58.56</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.693306</td>\n",
       "      <td>0.119536</td>\n",
       "      <td>0.068306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.334835</td>\n",
       "      <td>-0.297790</td>\n",
       "      <td>-3.726753</td>\n",
       "      <td>-3.410507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>5</td>\n",
       "      <td>1523</td>\n",
       "      <td>18.77</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.692500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>81.140117</td>\n",
       "      <td>0.319659</td>\n",
       "      <td>0.106553</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.434795</td>\n",
       "      <td>-0.019990</td>\n",
       "      <td>4.513860</td>\n",
       "      <td>-2.833282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>6</td>\n",
       "      <td>1307</td>\n",
       "      <td>75.25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>0.057575</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.703125</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>17.368771</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.079734</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.625110</td>\n",
       "      <td>-0.217714</td>\n",
       "      <td>7.113457</td>\n",
       "      <td>-1.908023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>6</td>\n",
       "      <td>428</td>\n",
       "      <td>4.57</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044393</td>\n",
       "      <td>0.010678</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.240526</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>93.654267</td>\n",
       "      <td>2.188184</td>\n",
       "      <td>1.969365</td>\n",
       "      <td>0.218818</td>\n",
       "      <td>-0.012221</td>\n",
       "      <td>-0.609770</td>\n",
       "      <td>-3.060755</td>\n",
       "      <td>-5.844836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>4</td>\n",
       "      <td>1082</td>\n",
       "      <td>79.13</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.930741</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>13.673702</td>\n",
       "      <td>0.139012</td>\n",
       "      <td>0.037912</td>\n",
       "      <td>0.037912</td>\n",
       "      <td>-0.051370</td>\n",
       "      <td>-0.087693</td>\n",
       "      <td>1.838761</td>\n",
       "      <td>-3.320831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>4</td>\n",
       "      <td>438</td>\n",
       "      <td>90.43</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.206461</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.607500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>4.843525</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>0.110583</td>\n",
       "      <td>0.055291</td>\n",
       "      <td>0.732811</td>\n",
       "      <td>0.190003</td>\n",
       "      <td>9.023623</td>\n",
       "      <td>0.444452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>5</td>\n",
       "      <td>1014</td>\n",
       "      <td>50.31</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.049615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.395714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.155039</td>\n",
       "      <td>0.139137</td>\n",
       "      <td>0.119261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.309435</td>\n",
       "      <td>-0.536263</td>\n",
       "      <td>-3.373116</td>\n",
       "      <td>-6.928945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>2</td>\n",
       "      <td>1117</td>\n",
       "      <td>80.84</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.072372</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.389333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>13.817417</td>\n",
       "      <td>0.061851</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.037110</td>\n",
       "      <td>-0.138141</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>-2.331820</td>\n",
       "      <td>4.710353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>4</td>\n",
       "      <td>1075</td>\n",
       "      <td>69.73</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.064865</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.432500</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>15.416607</td>\n",
       "      <td>0.114728</td>\n",
       "      <td>0.086046</td>\n",
       "      <td>0.028682</td>\n",
       "      <td>0.146714</td>\n",
       "      <td>-0.065524</td>\n",
       "      <td>6.437269</td>\n",
       "      <td>1.858359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>87.40</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.971111</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.925000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>1.029748</td>\n",
       "      <td>0.080092</td>\n",
       "      <td>0.022883</td>\n",
       "      <td>0.045767</td>\n",
       "      <td>0.428170</td>\n",
       "      <td>-0.038662</td>\n",
       "      <td>5.483471</td>\n",
       "      <td>-0.062813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>3</td>\n",
       "      <td>1219</td>\n",
       "      <td>11.24</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.009221</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.746667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.451957</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.533808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.298697</td>\n",
       "      <td>-0.071482</td>\n",
       "      <td>-3.835855</td>\n",
       "      <td>-1.408294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>4</td>\n",
       "      <td>944</td>\n",
       "      <td>28.13</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.557273</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>33.558478</td>\n",
       "      <td>0.284394</td>\n",
       "      <td>0.355492</td>\n",
       "      <td>0.142197</td>\n",
       "      <td>0.384086</td>\n",
       "      <td>0.041047</td>\n",
       "      <td>5.938570</td>\n",
       "      <td>1.502447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>2</td>\n",
       "      <td>522</td>\n",
       "      <td>6.78</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.398824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>76.991150</td>\n",
       "      <td>0.589971</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.589971</td>\n",
       "      <td>-0.014646</td>\n",
       "      <td>0.407759</td>\n",
       "      <td>-2.567194</td>\n",
       "      <td>9.260552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>4</td>\n",
       "      <td>1365</td>\n",
       "      <td>37.49</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.372500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>36.409709</td>\n",
       "      <td>0.133369</td>\n",
       "      <td>0.080021</td>\n",
       "      <td>0.106695</td>\n",
       "      <td>0.376222</td>\n",
       "      <td>0.143048</td>\n",
       "      <td>6.113767</td>\n",
       "      <td>4.355253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>5</td>\n",
       "      <td>678</td>\n",
       "      <td>69.69</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.102788</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.323000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>9.728799</td>\n",
       "      <td>0.143493</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>-0.023908</td>\n",
       "      <td>-0.253735</td>\n",
       "      <td>2.347776</td>\n",
       "      <td>-2.813657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>94.87</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.031196</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.717500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.969748</td>\n",
       "      <td>0.063244</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.545591</td>\n",
       "      <td>0.416393</td>\n",
       "      <td>3.399644</td>\n",
       "      <td>5.830930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>6</td>\n",
       "      <td>985</td>\n",
       "      <td>39.84</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.040447</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.064615</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>24.723896</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>0.175703</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>0.662522</td>\n",
       "      <td>-0.207532</td>\n",
       "      <td>8.540980</td>\n",
       "      <td>-4.596549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>96.15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.686786</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.683333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.456058</td>\n",
       "      <td>0.072803</td>\n",
       "      <td>0.041602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.359305</td>\n",
       "      <td>-0.100475</td>\n",
       "      <td>-2.731541</td>\n",
       "      <td>0.224744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>5</td>\n",
       "      <td>282</td>\n",
       "      <td>98.15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.099291</td>\n",
       "      <td>0.348050</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.505357</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>2.873153</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.061131</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.120248</td>\n",
       "      <td>-0.299016</td>\n",
       "      <td>-0.334932</td>\n",
       "      <td>-9.737473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>4</td>\n",
       "      <td>551</td>\n",
       "      <td>32.02</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>0.058113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.002500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.207995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.298808</td>\n",
       "      <td>-0.281976</td>\n",
       "      <td>-2.094450</td>\n",
       "      <td>-2.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1</td>\n",
       "      <td>1265</td>\n",
       "      <td>14.80</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>85.472973</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>-0.297617</td>\n",
       "      <td>0.426025</td>\n",
       "      <td>-5.340984</td>\n",
       "      <td>3.976819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>3</td>\n",
       "      <td>1396</td>\n",
       "      <td>41.60</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.942857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.557692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.271186</td>\n",
       "      <td>-0.166324</td>\n",
       "      <td>-3.440316</td>\n",
       "      <td>-0.056333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>3</td>\n",
       "      <td>1229</td>\n",
       "      <td>58.32</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.022783</td>\n",
       "      <td>0.047453</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.082857</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.008137</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>21.073388</td>\n",
       "      <td>0.102881</td>\n",
       "      <td>0.171468</td>\n",
       "      <td>0.085734</td>\n",
       "      <td>0.262022</td>\n",
       "      <td>0.197504</td>\n",
       "      <td>0.666392</td>\n",
       "      <td>5.269806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>4</td>\n",
       "      <td>1484</td>\n",
       "      <td>92.75</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.455882</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.118598</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.053908</td>\n",
       "      <td>0.354856</td>\n",
       "      <td>0.156861</td>\n",
       "      <td>3.885722</td>\n",
       "      <td>-1.148442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>5</td>\n",
       "      <td>599</td>\n",
       "      <td>24.54</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.040968</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.636000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>24.409128</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.244499</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>-0.316474</td>\n",
       "      <td>1.360068</td>\n",
       "      <td>-9.491315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>91.15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.243067</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.797917</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>4.114098</td>\n",
       "      <td>0.065826</td>\n",
       "      <td>0.043884</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.228598</td>\n",
       "      <td>-0.001727</td>\n",
       "      <td>-1.285422</td>\n",
       "      <td>2.696755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>4</td>\n",
       "      <td>405</td>\n",
       "      <td>97.38</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.869000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>4.158965</td>\n",
       "      <td>0.071883</td>\n",
       "      <td>0.041076</td>\n",
       "      <td>0.041076</td>\n",
       "      <td>0.221224</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>3.218581</td>\n",
       "      <td>0.541695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>3</td>\n",
       "      <td>1774</td>\n",
       "      <td>49.31</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.027796</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.739444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>35.976475</td>\n",
       "      <td>0.081119</td>\n",
       "      <td>0.202799</td>\n",
       "      <td>0.081119</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>5.147760</td>\n",
       "      <td>6.256430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1</td>\n",
       "      <td>1054</td>\n",
       "      <td>35.18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.180000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>29.960205</td>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.102948</td>\n",
       "      <td>0.637685</td>\n",
       "      <td>7.813169</td>\n",
       "      <td>6.737518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>88.98</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.505568</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>1.977973</td>\n",
       "      <td>0.056192</td>\n",
       "      <td>0.112385</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.108378</td>\n",
       "      <td>0.058673</td>\n",
       "      <td>-0.012084</td>\n",
       "      <td>1.149347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>3</td>\n",
       "      <td>1123</td>\n",
       "      <td>16.11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.805500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>69.708256</td>\n",
       "      <td>0.186220</td>\n",
       "      <td>0.124146</td>\n",
       "      <td>0.186220</td>\n",
       "      <td>-0.122149</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.126139</td>\n",
       "      <td>-1.472461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>2</td>\n",
       "      <td>1793</td>\n",
       "      <td>2.33</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011154</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>769.527897</td>\n",
       "      <td>4.291845</td>\n",
       "      <td>2.145923</td>\n",
       "      <td>0.429185</td>\n",
       "      <td>-0.495498</td>\n",
       "      <td>0.086217</td>\n",
       "      <td>-9.103867</td>\n",
       "      <td>-1.658163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>4</td>\n",
       "      <td>1683</td>\n",
       "      <td>74.66</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.295556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>22.542191</td>\n",
       "      <td>0.107152</td>\n",
       "      <td>0.093758</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>0.227220</td>\n",
       "      <td>-0.030307</td>\n",
       "      <td>5.779971</td>\n",
       "      <td>0.279971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>2</td>\n",
       "      <td>1649</td>\n",
       "      <td>55.81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.033845</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.201111</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.546676</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.179179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.386021</td>\n",
       "      <td>-0.009137</td>\n",
       "      <td>-3.585081</td>\n",
       "      <td>0.133017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>3</td>\n",
       "      <td>1315</td>\n",
       "      <td>81.66</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.062099</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>16.103355</td>\n",
       "      <td>0.097967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036738</td>\n",
       "      <td>0.185445</td>\n",
       "      <td>0.289187</td>\n",
       "      <td>4.488277</td>\n",
       "      <td>4.959719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>1116.393443</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>13.114754</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>-0.248151</td>\n",
       "      <td>0.168841</td>\n",
       "      <td>-5.767237</td>\n",
       "      <td>2.133558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>2</td>\n",
       "      <td>1210</td>\n",
       "      <td>25.72</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.720000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>47.045101</td>\n",
       "      <td>0.155521</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.201686</td>\n",
       "      <td>0.477755</td>\n",
       "      <td>8.090147</td>\n",
       "      <td>6.503971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>5</td>\n",
       "      <td>713</td>\n",
       "      <td>50.15</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035063</td>\n",
       "      <td>0.070337</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.006000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>14.217348</td>\n",
       "      <td>0.079761</td>\n",
       "      <td>0.159521</td>\n",
       "      <td>0.059821</td>\n",
       "      <td>0.148454</td>\n",
       "      <td>-0.295116</td>\n",
       "      <td>6.105335</td>\n",
       "      <td>-6.789245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>3</td>\n",
       "      <td>763</td>\n",
       "      <td>62.93</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039318</td>\n",
       "      <td>0.082477</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.097667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.124583</td>\n",
       "      <td>0.174797</td>\n",
       "      <td>0.063563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.627929</td>\n",
       "      <td>-0.214274</td>\n",
       "      <td>-7.089641</td>\n",
       "      <td>-2.950620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1</td>\n",
       "      <td>1709</td>\n",
       "      <td>34.83</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.966000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.066896</td>\n",
       "      <td>0.229687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.637606</td>\n",
       "      <td>0.285515</td>\n",
       "      <td>-8.141423</td>\n",
       "      <td>1.247737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>5</td>\n",
       "      <td>1631</td>\n",
       "      <td>82.26</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.050435</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.484000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>19.827377</td>\n",
       "      <td>0.012157</td>\n",
       "      <td>0.085096</td>\n",
       "      <td>0.012157</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>-0.441655</td>\n",
       "      <td>0.105124</td>\n",
       "      <td>-8.400446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1</td>\n",
       "      <td>673</td>\n",
       "      <td>77.29</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037147</td>\n",
       "      <td>0.114844</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.091600</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>8.707465</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>0.103506</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>-0.529674</td>\n",
       "      <td>0.211917</td>\n",
       "      <td>-6.095780</td>\n",
       "      <td>4.164765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>3</td>\n",
       "      <td>404</td>\n",
       "      <td>44.62</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.110446</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.718333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>9.054236</td>\n",
       "      <td>0.089646</td>\n",
       "      <td>0.112057</td>\n",
       "      <td>0.067234</td>\n",
       "      <td>0.049405</td>\n",
       "      <td>0.151905</td>\n",
       "      <td>1.999092</td>\n",
       "      <td>2.113326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>84.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.602270</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>1.660386</td>\n",
       "      <td>0.058879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035327</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.201598</td>\n",
       "      <td>0.977812</td>\n",
       "      <td>2.225179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>14.91</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.050034</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>19.986586</td>\n",
       "      <td>0.335345</td>\n",
       "      <td>0.536553</td>\n",
       "      <td>0.335345</td>\n",
       "      <td>0.105279</td>\n",
       "      <td>0.618791</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>7.841442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>3</td>\n",
       "      <td>533</td>\n",
       "      <td>32.81</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015009</td>\n",
       "      <td>0.061557</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.101250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>16.245047</td>\n",
       "      <td>0.060957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030479</td>\n",
       "      <td>-0.313776</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>-2.265918</td>\n",
       "      <td>-1.902734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>4</td>\n",
       "      <td>823</td>\n",
       "      <td>90.65</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.110146</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.130000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>9.078875</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>0.033094</td>\n",
       "      <td>0.281227</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>1.309526</td>\n",
       "      <td>-0.504359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>30.73</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.032937</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.841250</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.009646</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>30.361211</td>\n",
       "      <td>0.032541</td>\n",
       "      <td>0.292873</td>\n",
       "      <td>0.162707</td>\n",
       "      <td>0.474822</td>\n",
       "      <td>0.322344</td>\n",
       "      <td>5.168962</td>\n",
       "      <td>7.255159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>4</td>\n",
       "      <td>1220</td>\n",
       "      <td>93.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.076311</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.104189</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.220437</td>\n",
       "      <td>-0.194409</td>\n",
       "      <td>-1.635763</td>\n",
       "      <td>-0.554316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>89.78</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.068274</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.926667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>14.646915</td>\n",
       "      <td>0.055692</td>\n",
       "      <td>0.033415</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>-0.322789</td>\n",
       "      <td>0.375512</td>\n",
       "      <td>-3.618550</td>\n",
       "      <td>3.436115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1</td>\n",
       "      <td>1236</td>\n",
       "      <td>67.97</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.054992</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.855000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>18.184493</td>\n",
       "      <td>0.102987</td>\n",
       "      <td>0.058849</td>\n",
       "      <td>0.029425</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.389413</td>\n",
       "      <td>-5.198931</td>\n",
       "      <td>1.490263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>4</td>\n",
       "      <td>482</td>\n",
       "      <td>93.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.193154</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>5.177229</td>\n",
       "      <td>0.032223</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>-0.140254</td>\n",
       "      <td>-0.152917</td>\n",
       "      <td>-0.749149</td>\n",
       "      <td>-1.919194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>3</td>\n",
       "      <td>558</td>\n",
       "      <td>65.51</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.117401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.377500</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>8.517784</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>0.106854</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>0.069466</td>\n",
       "      <td>0.090338</td>\n",
       "      <td>-0.280058</td>\n",
       "      <td>-0.181070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>4</td>\n",
       "      <td>179</td>\n",
       "      <td>30.19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>0.168659</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.744545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.027933</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>5.929116</td>\n",
       "      <td>0.099371</td>\n",
       "      <td>0.165618</td>\n",
       "      <td>0.066247</td>\n",
       "      <td>-0.004192</td>\n",
       "      <td>-0.105917</td>\n",
       "      <td>2.004466</td>\n",
       "      <td>-2.600361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>5</td>\n",
       "      <td>1692</td>\n",
       "      <td>73.74</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.043582</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.193333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>22.945484</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.078270</td>\n",
       "      <td>-0.270758</td>\n",
       "      <td>1.406152</td>\n",
       "      <td>-6.989536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>3</td>\n",
       "      <td>474</td>\n",
       "      <td>32.30</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.068143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.794444</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>14.674923</td>\n",
       "      <td>0.278638</td>\n",
       "      <td>0.216718</td>\n",
       "      <td>0.092879</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.110314</td>\n",
       "      <td>1.911248</td>\n",
       "      <td>2.116036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>2</td>\n",
       "      <td>456</td>\n",
       "      <td>88.51</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.194101</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.510000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.151960</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>0.067789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.137395</td>\n",
       "      <td>0.177337</td>\n",
       "      <td>8.413266</td>\n",
       "      <td>4.778818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>4</td>\n",
       "      <td>474</td>\n",
       "      <td>86.63</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.182764</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.208519</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>5.471546</td>\n",
       "      <td>0.103890</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>-0.254610</td>\n",
       "      <td>-0.312557</td>\n",
       "      <td>-3.640046</td>\n",
       "      <td>-5.364482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>3</td>\n",
       "      <td>1478</td>\n",
       "      <td>68.55</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>0.046380</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.856250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.560904</td>\n",
       "      <td>0.072939</td>\n",
       "      <td>0.087527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.524678</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>-5.931244</td>\n",
       "      <td>-2.463631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.07</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.070000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.058703</td>\n",
       "      <td>0.146757</td>\n",
       "      <td>0.264162</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>0.503238</td>\n",
       "      <td>0.754483</td>\n",
       "      <td>9.038996</td>\n",
       "      <td>5.709252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>4</td>\n",
       "      <td>1210</td>\n",
       "      <td>16.35</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>74.006116</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.611621</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.167466</td>\n",
       "      <td>-0.078530</td>\n",
       "      <td>-0.076543</td>\n",
       "      <td>0.346947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>3</td>\n",
       "      <td>559</td>\n",
       "      <td>52.69</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.094258</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.053077</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.609224</td>\n",
       "      <td>0.056937</td>\n",
       "      <td>0.170810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.348352</td>\n",
       "      <td>-0.175365</td>\n",
       "      <td>-3.775267</td>\n",
       "      <td>1.614201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>26.44</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.440000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>25.226929</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.264750</td>\n",
       "      <td>0.151286</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.782043</td>\n",
       "      <td>9.148281</td>\n",
       "      <td>5.458436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>88.23</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.291188</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.803333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>3.434206</td>\n",
       "      <td>0.124674</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>-0.291136</td>\n",
       "      <td>0.164908</td>\n",
       "      <td>-2.465115</td>\n",
       "      <td>2.159211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>6</td>\n",
       "      <td>1450</td>\n",
       "      <td>61.94</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.580833</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>23.409751</td>\n",
       "      <td>0.048434</td>\n",
       "      <td>0.113013</td>\n",
       "      <td>0.032289</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>-0.560456</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>-8.715660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>1</td>\n",
       "      <td>1309</td>\n",
       "      <td>27.63</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.021108</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>47.376041</td>\n",
       "      <td>0.072385</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.144770</td>\n",
       "      <td>0.030377</td>\n",
       "      <td>0.593534</td>\n",
       "      <td>4.362004</td>\n",
       "      <td>8.267942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>3</td>\n",
       "      <td>562</td>\n",
       "      <td>73.28</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>0.130391</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.931200</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>7.669214</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>0.136463</td>\n",
       "      <td>0.040939</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.025813</td>\n",
       "      <td>0.269875</td>\n",
       "      <td>3.446269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>6</td>\n",
       "      <td>407</td>\n",
       "      <td>62.09</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039312</td>\n",
       "      <td>0.152555</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.880625</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.017199</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>6.555001</td>\n",
       "      <td>0.112740</td>\n",
       "      <td>0.048317</td>\n",
       "      <td>0.048317</td>\n",
       "      <td>0.263760</td>\n",
       "      <td>-0.366196</td>\n",
       "      <td>3.309290</td>\n",
       "      <td>-2.596354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>97.99</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.117213</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.532667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>8.531483</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.091846</td>\n",
       "      <td>0.040820</td>\n",
       "      <td>0.271483</td>\n",
       "      <td>0.185260</td>\n",
       "      <td>3.744615</td>\n",
       "      <td>2.699343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>385</td>\n",
       "      <td>44.73</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.116182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.066364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.020779</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>8.607199</td>\n",
       "      <td>0.089425</td>\n",
       "      <td>0.178851</td>\n",
       "      <td>0.044713</td>\n",
       "      <td>-0.230273</td>\n",
       "      <td>0.382407</td>\n",
       "      <td>-4.041372</td>\n",
       "      <td>2.549493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1</td>\n",
       "      <td>1538</td>\n",
       "      <td>60.68</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.039454</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.193684</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>25.346078</td>\n",
       "      <td>0.131839</td>\n",
       "      <td>0.098879</td>\n",
       "      <td>0.082399</td>\n",
       "      <td>0.095483</td>\n",
       "      <td>0.624063</td>\n",
       "      <td>-0.589579</td>\n",
       "      <td>6.392539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>4</td>\n",
       "      <td>839</td>\n",
       "      <td>82.62</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>0.098474</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.508000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>10.154926</td>\n",
       "      <td>0.096829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036311</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>2.981706</td>\n",
       "      <td>-1.124331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>93.35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>0.175470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.558333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>5.698982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042849</td>\n",
       "      <td>0.042849</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.626335</td>\n",
       "      <td>3.359876</td>\n",
       "      <td>6.962106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>3</td>\n",
       "      <td>421</td>\n",
       "      <td>79.04</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.187743</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.346667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.326417</td>\n",
       "      <td>0.050607</td>\n",
       "      <td>0.025304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.317981</td>\n",
       "      <td>-0.050349</td>\n",
       "      <td>-3.070290</td>\n",
       "      <td>0.163052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>73.98</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>5.690769</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.893684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.175723</td>\n",
       "      <td>0.135172</td>\n",
       "      <td>0.121655</td>\n",
       "      <td>0.067586</td>\n",
       "      <td>0.461423</td>\n",
       "      <td>0.107540</td>\n",
       "      <td>7.610621</td>\n",
       "      <td>-1.873757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>1</td>\n",
       "      <td>1367</td>\n",
       "      <td>65.92</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.048222</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.441481</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.737257</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.838558</td>\n",
       "      <td>0.150768</td>\n",
       "      <td>-10.055054</td>\n",
       "      <td>0.769138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2</td>\n",
       "      <td>1265</td>\n",
       "      <td>10.51</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.656875</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>120.361560</td>\n",
       "      <td>0.570885</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.475737</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>0.466568</td>\n",
       "      <td>0.627473</td>\n",
       "      <td>7.477462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2</td>\n",
       "      <td>922</td>\n",
       "      <td>26.50</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.028742</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>34.792453</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.033818</td>\n",
       "      <td>0.267997</td>\n",
       "      <td>-2.465698</td>\n",
       "      <td>2.136254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2</td>\n",
       "      <td>1553</td>\n",
       "      <td>63.32</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.040773</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.106667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>24.526216</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>0.126342</td>\n",
       "      <td>0.015793</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>0.168209</td>\n",
       "      <td>-3.011511</td>\n",
       "      <td>1.141794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>48.98</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.452727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.898734</td>\n",
       "      <td>0.102082</td>\n",
       "      <td>0.163332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.534878</td>\n",
       "      <td>0.199007</td>\n",
       "      <td>-4.341489</td>\n",
       "      <td>2.310202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>3</td>\n",
       "      <td>429</td>\n",
       "      <td>88.55</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.206410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.550000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.844720</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.042084</td>\n",
       "      <td>-0.054800</td>\n",
       "      <td>9.708371</td>\n",
       "      <td>2.976890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>1</td>\n",
       "      <td>679</td>\n",
       "      <td>90.50</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>0.133284</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.027778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>7.502762</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.101614</td>\n",
       "      <td>0.654072</td>\n",
       "      <td>1.590423</td>\n",
       "      <td>5.373973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>14.49</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>24.154589</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>-0.315002</td>\n",
       "      <td>0.366606</td>\n",
       "      <td>-1.591089</td>\n",
       "      <td>4.976254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>5</td>\n",
       "      <td>1600</td>\n",
       "      <td>43.51</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.027194</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.553929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.773156</td>\n",
       "      <td>0.091933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.498235</td>\n",
       "      <td>-0.536114</td>\n",
       "      <td>-5.106455</td>\n",
       "      <td>-8.633089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>2</td>\n",
       "      <td>1576</td>\n",
       "      <td>60.52</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.038401</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.501818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>26.040978</td>\n",
       "      <td>0.082617</td>\n",
       "      <td>0.115664</td>\n",
       "      <td>0.033047</td>\n",
       "      <td>-0.154503</td>\n",
       "      <td>0.202168</td>\n",
       "      <td>-2.365052</td>\n",
       "      <td>2.754789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1</td>\n",
       "      <td>1772</td>\n",
       "      <td>39.42</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.022246</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.855000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>44.951801</td>\n",
       "      <td>0.076104</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>0.076104</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>0.502271</td>\n",
       "      <td>5.815296</td>\n",
       "      <td>7.292999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>5</td>\n",
       "      <td>1442</td>\n",
       "      <td>92.56</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.428148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>15.579084</td>\n",
       "      <td>0.108038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021608</td>\n",
       "      <td>-0.154990</td>\n",
       "      <td>-0.336170</td>\n",
       "      <td>0.164986</td>\n",
       "      <td>-6.050881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>6</td>\n",
       "      <td>583</td>\n",
       "      <td>71.90</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048027</td>\n",
       "      <td>0.123328</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.567857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.108484</td>\n",
       "      <td>0.125174</td>\n",
       "      <td>0.111266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236803</td>\n",
       "      <td>-0.754987</td>\n",
       "      <td>-3.284574</td>\n",
       "      <td>-6.488367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>5</td>\n",
       "      <td>570</td>\n",
       "      <td>24.44</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>23.322422</td>\n",
       "      <td>0.040917</td>\n",
       "      <td>0.368249</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>-0.237442</td>\n",
       "      <td>7.880153</td>\n",
       "      <td>-4.071717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>3</td>\n",
       "      <td>1308</td>\n",
       "      <td>90.30</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.209091</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>14.485050</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>-0.186875</td>\n",
       "      <td>-0.069209</td>\n",
       "      <td>-2.256251</td>\n",
       "      <td>0.078734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>3</td>\n",
       "      <td>929</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011841</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.467273</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>180.739300</td>\n",
       "      <td>0.194553</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.194553</td>\n",
       "      <td>-0.279672</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-6.589663</td>\n",
       "      <td>1.588630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8.62</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.155000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.436667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.464037</td>\n",
       "      <td>0.580046</td>\n",
       "      <td>1.160093</td>\n",
       "      <td>0.116009</td>\n",
       "      <td>-0.110546</td>\n",
       "      <td>-0.030078</td>\n",
       "      <td>-3.984585</td>\n",
       "      <td>0.781309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>3</td>\n",
       "      <td>1371</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>125.779817</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.233540</td>\n",
       "      <td>0.227336</td>\n",
       "      <td>5.181474</td>\n",
       "      <td>6.929360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>4</td>\n",
       "      <td>502</td>\n",
       "      <td>75.97</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.151335</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.426429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.607872</td>\n",
       "      <td>0.065815</td>\n",
       "      <td>0.039489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.357424</td>\n",
       "      <td>-0.300202</td>\n",
       "      <td>-6.527399</td>\n",
       "      <td>-4.733041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>2</td>\n",
       "      <td>987</td>\n",
       "      <td>26.32</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026342</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.012308</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>0.189970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.684151</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-8.546973</td>\n",
       "      <td>0.015983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>3</td>\n",
       "      <td>703</td>\n",
       "      <td>47.17</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.067098</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.792500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>14.903540</td>\n",
       "      <td>0.169599</td>\n",
       "      <td>0.169599</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.397583</td>\n",
       "      <td>0.292865</td>\n",
       "      <td>6.506152</td>\n",
       "      <td>3.067188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>6</td>\n",
       "      <td>1504</td>\n",
       "      <td>89.37</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.059422</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.191786</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>16.828914</td>\n",
       "      <td>0.089515</td>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.033568</td>\n",
       "      <td>0.171494</td>\n",
       "      <td>-0.466429</td>\n",
       "      <td>3.227532</td>\n",
       "      <td>-7.113527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>4</td>\n",
       "      <td>1738</td>\n",
       "      <td>70.03</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.003000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>24.817935</td>\n",
       "      <td>0.142796</td>\n",
       "      <td>0.128516</td>\n",
       "      <td>0.028559</td>\n",
       "      <td>0.089241</td>\n",
       "      <td>-0.144764</td>\n",
       "      <td>6.064500</td>\n",
       "      <td>1.157601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>1</td>\n",
       "      <td>467</td>\n",
       "      <td>87.58</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057816</td>\n",
       "      <td>0.187537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.243704</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>5.332268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091345</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>-0.378776</td>\n",
       "      <td>0.280051</td>\n",
       "      <td>-7.844985</td>\n",
       "      <td>4.068583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1</td>\n",
       "      <td>1308</td>\n",
       "      <td>74.42</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.056896</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.631429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>17.575920</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>0.067186</td>\n",
       "      <td>0.040312</td>\n",
       "      <td>-0.063134</td>\n",
       "      <td>0.517527</td>\n",
       "      <td>4.714210</td>\n",
       "      <td>5.322341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>2</td>\n",
       "      <td>453</td>\n",
       "      <td>36.03</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.030000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.572856</td>\n",
       "      <td>0.055509</td>\n",
       "      <td>0.111019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.330649</td>\n",
       "      <td>0.132157</td>\n",
       "      <td>-3.711656</td>\n",
       "      <td>0.418196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>4</td>\n",
       "      <td>745</td>\n",
       "      <td>21.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.028805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.073000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>34.715750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046598</td>\n",
       "      <td>-0.357602</td>\n",
       "      <td>-0.220881</td>\n",
       "      <td>-7.236362</td>\n",
       "      <td>-7.298626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>1</td>\n",
       "      <td>511</td>\n",
       "      <td>60.59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.050881</td>\n",
       "      <td>0.118571</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.330385</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>8.433735</td>\n",
       "      <td>0.049513</td>\n",
       "      <td>0.049513</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>-0.478661</td>\n",
       "      <td>0.335519</td>\n",
       "      <td>-8.472413</td>\n",
       "      <td>4.532022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>3</td>\n",
       "      <td>1421</td>\n",
       "      <td>10.78</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.829231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>131.818182</td>\n",
       "      <td>0.463822</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>0.371058</td>\n",
       "      <td>0.210968</td>\n",
       "      <td>0.205756</td>\n",
       "      <td>5.092225</td>\n",
       "      <td>6.681635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>92.21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.576313</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.093077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.735170</td>\n",
       "      <td>0.065069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.038859</td>\n",
       "      <td>0.456665</td>\n",
       "      <td>0.597581</td>\n",
       "      <td>3.242662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>12.86</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.233818</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.918571</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>4.276827</td>\n",
       "      <td>0.855365</td>\n",
       "      <td>0.699844</td>\n",
       "      <td>0.155521</td>\n",
       "      <td>-0.177282</td>\n",
       "      <td>0.206160</td>\n",
       "      <td>-1.485528</td>\n",
       "      <td>4.478005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2</td>\n",
       "      <td>1637</td>\n",
       "      <td>70.76</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.586667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.134539</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>0.056529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.396273</td>\n",
       "      <td>0.079846</td>\n",
       "      <td>-4.876172</td>\n",
       "      <td>0.557323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>4</td>\n",
       "      <td>1791</td>\n",
       "      <td>84.09</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.046951</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.114444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>21.298609</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.071352</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>-0.144412</td>\n",
       "      <td>-0.233730</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>-9.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>54.84</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.958571</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.958571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>0.054705</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>-0.560200</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>-6.846248</td>\n",
       "      <td>7.009752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>5.88</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.034014</td>\n",
       "      <td>0.680272</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.548464</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>-5.115762</td>\n",
       "      <td>0.328213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>29.69</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.249496</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.474167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>4.008084</td>\n",
       "      <td>0.134725</td>\n",
       "      <td>0.168407</td>\n",
       "      <td>0.067363</td>\n",
       "      <td>0.079544</td>\n",
       "      <td>-0.280694</td>\n",
       "      <td>2.040120</td>\n",
       "      <td>-2.845488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>2</td>\n",
       "      <td>741</td>\n",
       "      <td>51.85</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.069973</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.925000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>14.291225</td>\n",
       "      <td>0.077146</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.077146</td>\n",
       "      <td>0.452433</td>\n",
       "      <td>0.485561</td>\n",
       "      <td>6.288129</td>\n",
       "      <td>7.161877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>2</td>\n",
       "      <td>1560</td>\n",
       "      <td>33.53</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.765000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>46.525500</td>\n",
       "      <td>0.089472</td>\n",
       "      <td>0.029824</td>\n",
       "      <td>0.119296</td>\n",
       "      <td>0.214501</td>\n",
       "      <td>0.533055</td>\n",
       "      <td>1.860765</td>\n",
       "      <td>10.056735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>43.28</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.090343</td>\n",
       "      <td>0.134829</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.492414</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>7.416821</td>\n",
       "      <td>0.254159</td>\n",
       "      <td>0.161738</td>\n",
       "      <td>0.115527</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.585012</td>\n",
       "      <td>-2.453825</td>\n",
       "      <td>8.194140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>4</td>\n",
       "      <td>1413</td>\n",
       "      <td>33.23</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.329200</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.521818</td>\n",
       "      <td>0.180560</td>\n",
       "      <td>0.150466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.481011</td>\n",
       "      <td>-0.383146</td>\n",
       "      <td>-6.319633</td>\n",
       "      <td>-3.314936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>58.90</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>0.521239</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.031034</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.918506</td>\n",
       "      <td>0.152801</td>\n",
       "      <td>0.067912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.514366</td>\n",
       "      <td>-0.374555</td>\n",
       "      <td>-4.955513</td>\n",
       "      <td>-5.252791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>2</td>\n",
       "      <td>1178</td>\n",
       "      <td>26.85</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.022793</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.983333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.873371</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.588638</td>\n",
       "      <td>0.084644</td>\n",
       "      <td>-7.477822</td>\n",
       "      <td>1.844912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.151852</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>-0.236160</td>\n",
       "      <td>0.246033</td>\n",
       "      <td>-0.895336</td>\n",
       "      <td>2.639490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>3</td>\n",
       "      <td>1085</td>\n",
       "      <td>53.76</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.752000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.182292</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>-0.105971</td>\n",
       "      <td>-3.396359</td>\n",
       "      <td>-0.535480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>2</td>\n",
       "      <td>1493</td>\n",
       "      <td>12.28</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.116364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>121.579805</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.570033</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>-0.192747</td>\n",
       "      <td>0.219940</td>\n",
       "      <td>-4.512022</td>\n",
       "      <td>4.607533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>39.24</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.162149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.905000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>6.167176</td>\n",
       "      <td>0.203874</td>\n",
       "      <td>0.127421</td>\n",
       "      <td>0.101937</td>\n",
       "      <td>0.061398</td>\n",
       "      <td>0.627893</td>\n",
       "      <td>0.955770</td>\n",
       "      <td>8.386696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>3</td>\n",
       "      <td>596</td>\n",
       "      <td>10.74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.342500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>55.493482</td>\n",
       "      <td>0.186220</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.186220</td>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.110514</td>\n",
       "      <td>-2.081894</td>\n",
       "      <td>-1.955158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>5</td>\n",
       "      <td>302</td>\n",
       "      <td>39.38</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056291</td>\n",
       "      <td>0.130397</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.316471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>7.668867</td>\n",
       "      <td>0.050787</td>\n",
       "      <td>0.076181</td>\n",
       "      <td>0.076181</td>\n",
       "      <td>0.146839</td>\n",
       "      <td>-0.205681</td>\n",
       "      <td>2.675555</td>\n",
       "      <td>-2.991265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1</td>\n",
       "      <td>1625</td>\n",
       "      <td>89.93</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>0.055342</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.733158</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.069610</td>\n",
       "      <td>0.122317</td>\n",
       "      <td>0.033359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.710022</td>\n",
       "      <td>0.181576</td>\n",
       "      <td>-7.833744</td>\n",
       "      <td>-0.558582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>5</td>\n",
       "      <td>1073</td>\n",
       "      <td>93.97</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.087577</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.492500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>11.418538</td>\n",
       "      <td>0.063850</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.162423</td>\n",
       "      <td>-0.204214</td>\n",
       "      <td>1.005684</td>\n",
       "      <td>-3.866466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>2</td>\n",
       "      <td>941</td>\n",
       "      <td>90.78</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.096472</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.052000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>10.365719</td>\n",
       "      <td>0.099141</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.033047</td>\n",
       "      <td>-0.115199</td>\n",
       "      <td>0.328513</td>\n",
       "      <td>-2.107337</td>\n",
       "      <td>4.943964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>3</td>\n",
       "      <td>667</td>\n",
       "      <td>14.56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035982</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>45.810440</td>\n",
       "      <td>0.206044</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.137363</td>\n",
       "      <td>-0.225870</td>\n",
       "      <td>-0.028378</td>\n",
       "      <td>-0.755084</td>\n",
       "      <td>1.027171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>3</td>\n",
       "      <td>557</td>\n",
       "      <td>65.74</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.118025</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.287000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>8.472772</td>\n",
       "      <td>0.167326</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>0.045634</td>\n",
       "      <td>-0.091465</td>\n",
       "      <td>0.140155</td>\n",
       "      <td>1.274046</td>\n",
       "      <td>2.258114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>5</td>\n",
       "      <td>589</td>\n",
       "      <td>25.03</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>0.042496</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.275455</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>23.531762</td>\n",
       "      <td>0.079904</td>\n",
       "      <td>0.279664</td>\n",
       "      <td>0.199760</td>\n",
       "      <td>0.586399</td>\n",
       "      <td>-0.017983</td>\n",
       "      <td>8.363355</td>\n",
       "      <td>-3.987318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>65.81</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.700714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>19.176417</td>\n",
       "      <td>0.136757</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.075976</td>\n",
       "      <td>0.106342</td>\n",
       "      <td>0.684112</td>\n",
       "      <td>-0.419446</td>\n",
       "      <td>7.710482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>76.01</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.075482</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.005000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>13.248257</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.078937</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>-0.232097</td>\n",
       "      <td>0.362438</td>\n",
       "      <td>-3.140653</td>\n",
       "      <td>3.021931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>2</td>\n",
       "      <td>826</td>\n",
       "      <td>34.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.235000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>23.962866</td>\n",
       "      <td>0.029011</td>\n",
       "      <td>0.029011</td>\n",
       "      <td>0.058021</td>\n",
       "      <td>-0.123915</td>\n",
       "      <td>0.329782</td>\n",
       "      <td>-4.551945</td>\n",
       "      <td>4.246637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>2</td>\n",
       "      <td>467</td>\n",
       "      <td>92.95</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.057816</td>\n",
       "      <td>0.199036</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.442593</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>5.024207</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>-0.069208</td>\n",
       "      <td>0.347730</td>\n",
       "      <td>-0.471632</td>\n",
       "      <td>3.691104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1</td>\n",
       "      <td>1681</td>\n",
       "      <td>60.33</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.035889</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.623043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.863418</td>\n",
       "      <td>0.165755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.826515</td>\n",
       "      <td>0.185734</td>\n",
       "      <td>-9.189062</td>\n",
       "      <td>-0.643166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>23.92</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.144096</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.993333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>6.939799</td>\n",
       "      <td>0.459866</td>\n",
       "      <td>0.083612</td>\n",
       "      <td>0.209030</td>\n",
       "      <td>0.189893</td>\n",
       "      <td>0.557001</td>\n",
       "      <td>3.653892</td>\n",
       "      <td>3.974497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>6</td>\n",
       "      <td>1019</td>\n",
       "      <td>35.72</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.035054</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.968889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>28.527436</td>\n",
       "      <td>0.223964</td>\n",
       "      <td>0.223964</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>0.728138</td>\n",
       "      <td>-0.179199</td>\n",
       "      <td>7.935737</td>\n",
       "      <td>-2.873689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2</td>\n",
       "      <td>772</td>\n",
       "      <td>73.41</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024611</td>\n",
       "      <td>0.095091</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.863684</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>10.516278</td>\n",
       "      <td>0.095355</td>\n",
       "      <td>0.095355</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>-0.386563</td>\n",
       "      <td>0.076503</td>\n",
       "      <td>-5.999290</td>\n",
       "      <td>3.552078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>2</td>\n",
       "      <td>1767</td>\n",
       "      <td>63.45</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>0.035908</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.758696</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>27.848700</td>\n",
       "      <td>0.173365</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>-0.559368</td>\n",
       "      <td>0.099316</td>\n",
       "      <td>-8.929683</td>\n",
       "      <td>-1.015705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1</td>\n",
       "      <td>498</td>\n",
       "      <td>61.62</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>0.123735</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.243158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>8.081792</td>\n",
       "      <td>0.032457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032457</td>\n",
       "      <td>-0.454373</td>\n",
       "      <td>0.396840</td>\n",
       "      <td>-8.721907</td>\n",
       "      <td>4.732460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>3</td>\n",
       "      <td>1451</td>\n",
       "      <td>11.90</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>121.932773</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>0.271472</td>\n",
       "      <td>0.228548</td>\n",
       "      <td>1.558208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>6</td>\n",
       "      <td>575</td>\n",
       "      <td>8.55</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050435</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.294828</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.251462</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.116959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.408360</td>\n",
       "      <td>-0.701087</td>\n",
       "      <td>-6.720244</td>\n",
       "      <td>-6.820616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>6</td>\n",
       "      <td>865</td>\n",
       "      <td>31.84</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.036809</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.122667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>27.167085</td>\n",
       "      <td>0.314070</td>\n",
       "      <td>0.219849</td>\n",
       "      <td>0.094221</td>\n",
       "      <td>0.319001</td>\n",
       "      <td>-0.391723</td>\n",
       "      <td>6.539560</td>\n",
       "      <td>-3.156917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2</td>\n",
       "      <td>1571</td>\n",
       "      <td>12.01</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.201000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>130.807660</td>\n",
       "      <td>0.666112</td>\n",
       "      <td>0.666112</td>\n",
       "      <td>0.416320</td>\n",
       "      <td>0.305648</td>\n",
       "      <td>0.495070</td>\n",
       "      <td>1.032434</td>\n",
       "      <td>7.445225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>6</td>\n",
       "      <td>1807</td>\n",
       "      <td>65.04</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.035993</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.501538</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.782903</td>\n",
       "      <td>0.138376</td>\n",
       "      <td>0.076876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.285962</td>\n",
       "      <td>-0.735913</td>\n",
       "      <td>-1.650151</td>\n",
       "      <td>-7.612187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1</td>\n",
       "      <td>1381</td>\n",
       "      <td>69.57</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.024783</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>19.850510</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>0.129366</td>\n",
       "      <td>0.057496</td>\n",
       "      <td>-0.034013</td>\n",
       "      <td>0.470970</td>\n",
       "      <td>0.441294</td>\n",
       "      <td>5.547047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>3</td>\n",
       "      <td>956</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.262222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>405.084746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.542373</td>\n",
       "      <td>2.118644</td>\n",
       "      <td>0.383494</td>\n",
       "      <td>0.339717</td>\n",
       "      <td>4.961590</td>\n",
       "      <td>7.381038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>1</td>\n",
       "      <td>796</td>\n",
       "      <td>28.96</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.036382</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>27.486188</td>\n",
       "      <td>0.172652</td>\n",
       "      <td>0.103591</td>\n",
       "      <td>0.069061</td>\n",
       "      <td>-0.395912</td>\n",
       "      <td>0.392903</td>\n",
       "      <td>-4.619734</td>\n",
       "      <td>7.339599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "      <td>36.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.518750</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>9.272977</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>0.104222</td>\n",
       "      <td>0.585888</td>\n",
       "      <td>-0.437698</td>\n",
       "      <td>6.872810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>4</td>\n",
       "      <td>1175</td>\n",
       "      <td>74.52</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.063421</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.968000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>15.767579</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>0.040258</td>\n",
       "      <td>0.104429</td>\n",
       "      <td>-0.043319</td>\n",
       "      <td>1.649832</td>\n",
       "      <td>-0.523160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>2</td>\n",
       "      <td>1027</td>\n",
       "      <td>39.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011685</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>25.739348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100251</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>-0.226330</td>\n",
       "      <td>0.221037</td>\n",
       "      <td>-5.331325</td>\n",
       "      <td>5.990990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>6</td>\n",
       "      <td>1507</td>\n",
       "      <td>23.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>62.896494</td>\n",
       "      <td>0.041736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166945</td>\n",
       "      <td>0.243958</td>\n",
       "      <td>-0.314566</td>\n",
       "      <td>3.223017</td>\n",
       "      <td>-5.546333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>42.82</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.329385</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.646923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>3.035965</td>\n",
       "      <td>0.140121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116768</td>\n",
       "      <td>0.107911</td>\n",
       "      <td>0.310642</td>\n",
       "      <td>1.174698</td>\n",
       "      <td>2.373464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>1</td>\n",
       "      <td>1380</td>\n",
       "      <td>54.08</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.862857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>25.517751</td>\n",
       "      <td>0.147929</td>\n",
       "      <td>0.073964</td>\n",
       "      <td>0.018491</td>\n",
       "      <td>-0.500914</td>\n",
       "      <td>0.296445</td>\n",
       "      <td>-5.283191</td>\n",
       "      <td>1.486939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>2</td>\n",
       "      <td>755</td>\n",
       "      <td>56.06</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.074252</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.737333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>13.467713</td>\n",
       "      <td>0.196218</td>\n",
       "      <td>0.089190</td>\n",
       "      <td>0.053514</td>\n",
       "      <td>-0.084942</td>\n",
       "      <td>0.313461</td>\n",
       "      <td>-1.702273</td>\n",
       "      <td>4.643777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>114.328358</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>2.388060</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>-0.389951</td>\n",
       "      <td>0.301226</td>\n",
       "      <td>-4.521966</td>\n",
       "      <td>1.756332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>2</td>\n",
       "      <td>1461</td>\n",
       "      <td>39.82</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.592800</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>36.690105</td>\n",
       "      <td>0.150678</td>\n",
       "      <td>0.226017</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>-0.445423</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-7.407547</td>\n",
       "      <td>1.006333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>3</td>\n",
       "      <td>916</td>\n",
       "      <td>21.73</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.810833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>42.153705</td>\n",
       "      <td>0.184077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092039</td>\n",
       "      <td>-0.218194</td>\n",
       "      <td>0.093791</td>\n",
       "      <td>-1.991095</td>\n",
       "      <td>-1.965868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>3</td>\n",
       "      <td>557</td>\n",
       "      <td>69.06</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.123986</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.932857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>8.065450</td>\n",
       "      <td>0.144802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072401</td>\n",
       "      <td>0.253119</td>\n",
       "      <td>0.377354</td>\n",
       "      <td>3.561305</td>\n",
       "      <td>4.125284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2</td>\n",
       "      <td>770</td>\n",
       "      <td>9.17</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.398696</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>83.969466</td>\n",
       "      <td>1.199564</td>\n",
       "      <td>1.090513</td>\n",
       "      <td>0.545256</td>\n",
       "      <td>0.187698</td>\n",
       "      <td>0.418184</td>\n",
       "      <td>-0.213774</td>\n",
       "      <td>6.881392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1</td>\n",
       "      <td>866</td>\n",
       "      <td>44.22</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.763750</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>19.583899</td>\n",
       "      <td>0.067843</td>\n",
       "      <td>0.203528</td>\n",
       "      <td>0.113071</td>\n",
       "      <td>0.185605</td>\n",
       "      <td>0.618242</td>\n",
       "      <td>1.175430</td>\n",
       "      <td>6.936861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>3</td>\n",
       "      <td>1563</td>\n",
       "      <td>87.86</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.056212</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.762222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.789665</td>\n",
       "      <td>0.045527</td>\n",
       "      <td>0.011382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.434341</td>\n",
       "      <td>-0.101966</td>\n",
       "      <td>-5.957708</td>\n",
       "      <td>-0.603845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2</td>\n",
       "      <td>1775</td>\n",
       "      <td>5.79</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>306.563040</td>\n",
       "      <td>1.899827</td>\n",
       "      <td>1.381693</td>\n",
       "      <td>0.690846</td>\n",
       "      <td>-0.036067</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-2.124451</td>\n",
       "      <td>7.101188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>28.55</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075893</td>\n",
       "      <td>0.127455</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.679412</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>7.845884</td>\n",
       "      <td>0.175131</td>\n",
       "      <td>0.245184</td>\n",
       "      <td>0.140105</td>\n",
       "      <td>0.362854</td>\n",
       "      <td>-0.137358</td>\n",
       "      <td>6.660828</td>\n",
       "      <td>-3.836380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>3</td>\n",
       "      <td>774</td>\n",
       "      <td>41.22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.053256</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.122000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>18.777293</td>\n",
       "      <td>0.097040</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.305074</td>\n",
       "      <td>0.381886</td>\n",
       "      <td>2.764474</td>\n",
       "      <td>2.239516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>4</td>\n",
       "      <td>930</td>\n",
       "      <td>40.27</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.135000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>23.094115</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.124162</td>\n",
       "      <td>0.074497</td>\n",
       "      <td>0.354076</td>\n",
       "      <td>0.084956</td>\n",
       "      <td>7.416952</td>\n",
       "      <td>3.067899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>4</td>\n",
       "      <td>1501</td>\n",
       "      <td>51.16</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011326</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.009412</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>29.339328</td>\n",
       "      <td>0.136826</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>0.097733</td>\n",
       "      <td>0.366335</td>\n",
       "      <td>0.136529</td>\n",
       "      <td>3.983505</td>\n",
       "      <td>1.238935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2</td>\n",
       "      <td>1689</td>\n",
       "      <td>13.70</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>123.284672</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>-0.662985</td>\n",
       "      <td>0.063058</td>\n",
       "      <td>-9.473579</td>\n",
       "      <td>-1.388091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>4</td>\n",
       "      <td>1178</td>\n",
       "      <td>74.02</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.626250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>15.914618</td>\n",
       "      <td>0.148608</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>0.040530</td>\n",
       "      <td>0.121521</td>\n",
       "      <td>-0.052398</td>\n",
       "      <td>5.149657</td>\n",
       "      <td>1.203134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2</td>\n",
       "      <td>837</td>\n",
       "      <td>8.07</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>103.717472</td>\n",
       "      <td>0.247831</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.123916</td>\n",
       "      <td>-0.561812</td>\n",
       "      <td>0.022895</td>\n",
       "      <td>-7.129368</td>\n",
       "      <td>5.270863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>35.02</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.972778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.891111</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1.027984</td>\n",
       "      <td>0.228441</td>\n",
       "      <td>0.285551</td>\n",
       "      <td>0.028555</td>\n",
       "      <td>-0.328814</td>\n",
       "      <td>0.297557</td>\n",
       "      <td>-4.359249</td>\n",
       "      <td>2.572219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>5</td>\n",
       "      <td>1455</td>\n",
       "      <td>90.53</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.062220</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.121724</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>16.072020</td>\n",
       "      <td>0.110461</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>0.145190</td>\n",
       "      <td>-0.168548</td>\n",
       "      <td>2.970952</td>\n",
       "      <td>-6.837061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1</td>\n",
       "      <td>1133</td>\n",
       "      <td>24.49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>0.021615</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.883846</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>46.263781</td>\n",
       "      <td>0.122499</td>\n",
       "      <td>0.122499</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>-0.521240</td>\n",
       "      <td>0.307079</td>\n",
       "      <td>-6.778986</td>\n",
       "      <td>2.526335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>3</td>\n",
       "      <td>1421</td>\n",
       "      <td>2.42</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019704</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.086429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>587.190083</td>\n",
       "      <td>2.892562</td>\n",
       "      <td>3.305785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.577690</td>\n",
       "      <td>-0.247480</td>\n",
       "      <td>-6.443964</td>\n",
       "      <td>-2.567855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>66.01</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.857273</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.357500</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>1.166490</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>0.045448</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.442556</td>\n",
       "      <td>0.222823</td>\n",
       "      <td>3.865767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>6</td>\n",
       "      <td>1701</td>\n",
       "      <td>8.09</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014109</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>210.259580</td>\n",
       "      <td>1.112485</td>\n",
       "      <td>0.988875</td>\n",
       "      <td>0.494438</td>\n",
       "      <td>0.364356</td>\n",
       "      <td>-0.368483</td>\n",
       "      <td>6.764425</td>\n",
       "      <td>-4.953679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>52.22</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.740667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.934074</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.574493</td>\n",
       "      <td>0.172348</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>-0.155154</td>\n",
       "      <td>-0.192013</td>\n",
       "      <td>-4.027856</td>\n",
       "      <td>-4.661971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>6</td>\n",
       "      <td>680</td>\n",
       "      <td>92.40</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.135882</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>7.359307</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.108225</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.384303</td>\n",
       "      <td>-0.443470</td>\n",
       "      <td>6.310797</td>\n",
       "      <td>-7.676450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>3</td>\n",
       "      <td>1536</td>\n",
       "      <td>33.57</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.398750</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>45.755139</td>\n",
       "      <td>0.327674</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>-0.320658</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>-9.086072</td>\n",
       "      <td>-2.415003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>46.79</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.154422</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.684286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>6.475743</td>\n",
       "      <td>0.064116</td>\n",
       "      <td>0.042744</td>\n",
       "      <td>0.064116</td>\n",
       "      <td>-0.033193</td>\n",
       "      <td>0.380053</td>\n",
       "      <td>-3.573747</td>\n",
       "      <td>5.524268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64.94</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>21.646667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.638571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.061595</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.028692</td>\n",
       "      <td>0.149325</td>\n",
       "      <td>0.098078</td>\n",
       "      <td>-2.371513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>3</td>\n",
       "      <td>1736</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.553333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>372.532189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.716738</td>\n",
       "      <td>1.072961</td>\n",
       "      <td>0.541676</td>\n",
       "      <td>0.372560</td>\n",
       "      <td>5.761696</td>\n",
       "      <td>7.081137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>15.41</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.284167</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>49.059053</td>\n",
       "      <td>0.648929</td>\n",
       "      <td>0.259572</td>\n",
       "      <td>0.129786</td>\n",
       "      <td>-0.345301</td>\n",
       "      <td>0.419073</td>\n",
       "      <td>-4.543165</td>\n",
       "      <td>5.082536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>1</td>\n",
       "      <td>1465</td>\n",
       "      <td>58.95</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.358000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>24.851569</td>\n",
       "      <td>0.169635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033927</td>\n",
       "      <td>-0.540618</td>\n",
       "      <td>0.365386</td>\n",
       "      <td>-9.943054</td>\n",
       "      <td>0.251460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>1</td>\n",
       "      <td>358</td>\n",
       "      <td>34.74</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.097039</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.370000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>10.305124</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.172712</td>\n",
       "      <td>0.115141</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>0.701160</td>\n",
       "      <td>3.189190</td>\n",
       "      <td>7.629879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>5</td>\n",
       "      <td>1555</td>\n",
       "      <td>33.38</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>46.584781</td>\n",
       "      <td>0.239664</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.196065</td>\n",
       "      <td>-0.178417</td>\n",
       "      <td>0.483268</td>\n",
       "      <td>-4.208192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>2</td>\n",
       "      <td>1539</td>\n",
       "      <td>11.13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>138.274933</td>\n",
       "      <td>0.808625</td>\n",
       "      <td>0.089847</td>\n",
       "      <td>0.449236</td>\n",
       "      <td>0.219435</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>1.293981</td>\n",
       "      <td>9.526946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>14.52</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.904000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>49.862259</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.250494</td>\n",
       "      <td>0.748200</td>\n",
       "      <td>1.660101</td>\n",
       "      <td>8.853664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>5</td>\n",
       "      <td>1248</td>\n",
       "      <td>16.29</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021635</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>76.611418</td>\n",
       "      <td>0.613874</td>\n",
       "      <td>0.368324</td>\n",
       "      <td>0.306937</td>\n",
       "      <td>0.361625</td>\n",
       "      <td>-0.095189</td>\n",
       "      <td>6.456516</td>\n",
       "      <td>-4.907660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>2</td>\n",
       "      <td>1259</td>\n",
       "      <td>20.78</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.308889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>60.587103</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.240616</td>\n",
       "      <td>0.192493</td>\n",
       "      <td>0.121445</td>\n",
       "      <td>0.425099</td>\n",
       "      <td>4.521530</td>\n",
       "      <td>7.961914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>5</td>\n",
       "      <td>1238</td>\n",
       "      <td>45.82</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.037011</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.545714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>27.018769</td>\n",
       "      <td>0.130947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087298</td>\n",
       "      <td>0.362845</td>\n",
       "      <td>-0.030255</td>\n",
       "      <td>4.337762</td>\n",
       "      <td>-2.487364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>66.72</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.516364</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.149880</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.074940</td>\n",
       "      <td>0.599689</td>\n",
       "      <td>0.264537</td>\n",
       "      <td>6.046237</td>\n",
       "      <td>1.797339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>3</td>\n",
       "      <td>1171</td>\n",
       "      <td>25.56</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.021827</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.065000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>45.813772</td>\n",
       "      <td>0.430360</td>\n",
       "      <td>0.039124</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>-0.186881</td>\n",
       "      <td>0.122008</td>\n",
       "      <td>-9.181171</td>\n",
       "      <td>-2.838308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>2</td>\n",
       "      <td>1211</td>\n",
       "      <td>88.88</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.220000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>13.625113</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.056256</td>\n",
       "      <td>0.352766</td>\n",
       "      <td>0.608844</td>\n",
       "      <td>4.357925</td>\n",
       "      <td>4.961932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>3</td>\n",
       "      <td>703</td>\n",
       "      <td>8.20</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.731707</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.301564</td>\n",
       "      <td>-0.090145</td>\n",
       "      <td>-3.622889</td>\n",
       "      <td>-1.654950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>6</td>\n",
       "      <td>680</td>\n",
       "      <td>51.89</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.076309</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.256087</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>13.104644</td>\n",
       "      <td>0.154172</td>\n",
       "      <td>0.096358</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>-0.516685</td>\n",
       "      <td>-3.043913</td>\n",
       "      <td>-7.160035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>4</td>\n",
       "      <td>981</td>\n",
       "      <td>36.26</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.036962</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>27.054606</td>\n",
       "      <td>0.165472</td>\n",
       "      <td>0.110314</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>-0.064467</td>\n",
       "      <td>-0.121219</td>\n",
       "      <td>-2.041299</td>\n",
       "      <td>-2.894363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>1</td>\n",
       "      <td>801</td>\n",
       "      <td>73.63</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034956</td>\n",
       "      <td>0.091923</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.629643</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>10.878718</td>\n",
       "      <td>0.081489</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>-0.228058</td>\n",
       "      <td>0.528369</td>\n",
       "      <td>-1.736382</td>\n",
       "      <td>5.927167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>2</td>\n",
       "      <td>1397</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>164.740566</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.589623</td>\n",
       "      <td>0.353774</td>\n",
       "      <td>-0.214021</td>\n",
       "      <td>0.240313</td>\n",
       "      <td>-5.343004</td>\n",
       "      <td>6.472922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>6</td>\n",
       "      <td>656</td>\n",
       "      <td>95.58</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.145701</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.580000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>6.863361</td>\n",
       "      <td>0.052312</td>\n",
       "      <td>0.062775</td>\n",
       "      <td>0.031387</td>\n",
       "      <td>0.796724</td>\n",
       "      <td>-0.196206</td>\n",
       "      <td>9.937723</td>\n",
       "      <td>4.108630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>3</td>\n",
       "      <td>1636</td>\n",
       "      <td>8.60</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>190.232558</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>-0.336671</td>\n",
       "      <td>-0.030846</td>\n",
       "      <td>-7.261403</td>\n",
       "      <td>-0.302938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>5</td>\n",
       "      <td>1764</td>\n",
       "      <td>79.93</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.045312</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.993000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>22.069311</td>\n",
       "      <td>0.100088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.183057</td>\n",
       "      <td>-0.152703</td>\n",
       "      <td>1.266842</td>\n",
       "      <td>-4.495432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>59.43</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.583913</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>23.557126</td>\n",
       "      <td>0.050480</td>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.033653</td>\n",
       "      <td>-0.402975</td>\n",
       "      <td>0.313592</td>\n",
       "      <td>-7.690426</td>\n",
       "      <td>2.947644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>4</td>\n",
       "      <td>1830</td>\n",
       "      <td>23.73</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.117573</td>\n",
       "      <td>0.252845</td>\n",
       "      <td>0.168563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.541436</td>\n",
       "      <td>-0.395605</td>\n",
       "      <td>-5.110292</td>\n",
       "      <td>-8.551067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>6</td>\n",
       "      <td>451</td>\n",
       "      <td>54.85</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.121619</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.493182</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>8.222425</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.091158</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>-0.072937</td>\n",
       "      <td>-0.614835</td>\n",
       "      <td>-6.318127</td>\n",
       "      <td>-6.666389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>2</td>\n",
       "      <td>431</td>\n",
       "      <td>12.24</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053364</td>\n",
       "      <td>0.028399</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.532174</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.212418</td>\n",
       "      <td>0.816993</td>\n",
       "      <td>0.408497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.660203</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-6.314555</td>\n",
       "      <td>3.436418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>6</td>\n",
       "      <td>370</td>\n",
       "      <td>56.26</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072973</td>\n",
       "      <td>0.152054</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.083704</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.576609</td>\n",
       "      <td>0.195521</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.201039</td>\n",
       "      <td>-0.758078</td>\n",
       "      <td>-3.395929</td>\n",
       "      <td>-6.123923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>88.01</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.415142</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.336667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>2.408817</td>\n",
       "      <td>0.034087</td>\n",
       "      <td>0.068174</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>0.694814</td>\n",
       "      <td>0.246615</td>\n",
       "      <td>8.221653</td>\n",
       "      <td>0.542709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>14.51</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.836667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>78.152998</td>\n",
       "      <td>0.482426</td>\n",
       "      <td>0.137836</td>\n",
       "      <td>0.275672</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.691328</td>\n",
       "      <td>1.694020</td>\n",
       "      <td>9.509952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>78.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.770000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>12.858240</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.124540</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>1.806451</td>\n",
       "      <td>-1.250343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>2</td>\n",
       "      <td>1827</td>\n",
       "      <td>68.94</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.037734</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.596000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>26.501305</td>\n",
       "      <td>0.087032</td>\n",
       "      <td>0.072527</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>-0.390615</td>\n",
       "      <td>0.098756</td>\n",
       "      <td>-5.775617</td>\n",
       "      <td>0.531482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>6</td>\n",
       "      <td>660</td>\n",
       "      <td>90.53</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.137167</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.265000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>7.290401</td>\n",
       "      <td>0.110461</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.176489</td>\n",
       "      <td>-0.423078</td>\n",
       "      <td>8.293224</td>\n",
       "      <td>2.701620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>2</td>\n",
       "      <td>206</td>\n",
       "      <td>71.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.346117</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.240909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>2.889201</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>-0.077012</td>\n",
       "      <td>0.402924</td>\n",
       "      <td>-0.024459</td>\n",
       "      <td>3.007612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>5</td>\n",
       "      <td>794</td>\n",
       "      <td>29.91</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.037670</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.719091</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>26.546306</td>\n",
       "      <td>0.167168</td>\n",
       "      <td>0.100301</td>\n",
       "      <td>0.066867</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>-0.266000</td>\n",
       "      <td>-1.026168</td>\n",
       "      <td>-2.987634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>4</td>\n",
       "      <td>452</td>\n",
       "      <td>44.59</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.098650</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.938696</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>10.136802</td>\n",
       "      <td>0.156986</td>\n",
       "      <td>0.201839</td>\n",
       "      <td>0.067280</td>\n",
       "      <td>0.087640</td>\n",
       "      <td>-0.110890</td>\n",
       "      <td>0.296960</td>\n",
       "      <td>-0.639632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112821</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.095455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>-0.525993</td>\n",
       "      <td>0.098815</td>\n",
       "      <td>-7.403222</td>\n",
       "      <td>0.422384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>3</td>\n",
       "      <td>1434</td>\n",
       "      <td>69.97</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.664667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>20.494498</td>\n",
       "      <td>0.114335</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.057167</td>\n",
       "      <td>0.098324</td>\n",
       "      <td>0.252156</td>\n",
       "      <td>1.952418</td>\n",
       "      <td>1.719391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>3</td>\n",
       "      <td>338</td>\n",
       "      <td>88.93</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.073964</td>\n",
       "      <td>0.263107</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.557200</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>3.800742</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>0.033734</td>\n",
       "      <td>0.056224</td>\n",
       "      <td>0.206482</td>\n",
       "      <td>0.273511</td>\n",
       "      <td>2.256691</td>\n",
       "      <td>0.565354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>2</td>\n",
       "      <td>767</td>\n",
       "      <td>50.95</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022164</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.997059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.053974</td>\n",
       "      <td>0.137390</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.623033</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>-9.540482</td>\n",
       "      <td>0.919365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>76.03</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071651</td>\n",
       "      <td>0.236854</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.305652</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>4.222018</td>\n",
       "      <td>0.105222</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>0.026305</td>\n",
       "      <td>-0.368408</td>\n",
       "      <td>0.328203</td>\n",
       "      <td>-5.891068</td>\n",
       "      <td>4.447347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1</td>\n",
       "      <td>397</td>\n",
       "      <td>41.89</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.611154</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.477202</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.762581</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>-10.497591</td>\n",
       "      <td>0.265843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>4</td>\n",
       "      <td>316</td>\n",
       "      <td>41.83</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.132373</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.394333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>7.554387</td>\n",
       "      <td>0.119531</td>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>-0.310003</td>\n",
       "      <td>-0.328558</td>\n",
       "      <td>-4.616800</td>\n",
       "      <td>-4.810662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>2</td>\n",
       "      <td>685</td>\n",
       "      <td>62.68</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035036</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.611667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>10.928526</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.095724</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>-0.305633</td>\n",
       "      <td>0.142684</td>\n",
       "      <td>-8.220529</td>\n",
       "      <td>4.169440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>4</td>\n",
       "      <td>1140</td>\n",
       "      <td>38.03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.001579</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>29.976334</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.078885</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>-0.048512</td>\n",
       "      <td>0.969935</td>\n",
       "      <td>-2.455174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1879 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  fraud  scannedLineItems  pricePerScannedLineItem  scansWithoutRegistrationPerScannedLineItem  quantityModificationsPerScannedLineItem  lineItemVoidsPerSecond  scansWithoutRegistrationPerSecond  quantityModificationsPerSecond  secondsPerEuro  lineItemVoidsPerEuro  scansWithoutRegistrationPerEuro  quantityModificationsPerEuro  pca_axis_1  pca_axis_2  tsne_axis_1  tsne_axis_2\n",
       "0              5                    1054       54.70              7                         0                      3                   0.027514        0.051898                  0.241379      0              29.0                 1.886207                                    0.000000                                 0.103448                0.006641                           0.000000                        0.002846       19.268739              0.127971                         0.000000                      0.054845   -0.041017   -0.249076     2.291510    -5.640468\n",
       "1              3                     108       27.36              5                         2                      4                   0.129630        0.253333                  0.357143      0              14.0                 1.954286                                    0.142857                                 0.285714                0.046296                           0.018519                        0.037037        3.947368              0.182749                         0.073099                      0.146199    0.115539    0.267326     1.481642     2.398213\n",
       "2              3                    1516       62.16              3                        10                      5                   0.008575        0.041003                  0.230769      0              13.0                 4.781538                                    0.769231                                 0.384615                0.001979                           0.006596                        0.003298       24.388674              0.048263                         0.160875                      0.080438    0.438573    0.273101     5.278484     6.027374\n",
       "3              6                    1791       92.31              8                         4                      4                   0.016192        0.051541                  0.275862      0              29.0                 3.183103                                    0.137931                                 0.137931                0.004467                           0.002233                        0.002233       19.402015              0.086665                         0.043332                      0.043332    0.294578   -0.374467     3.357620    -7.026612\n",
       "4              5                     430       81.53              3                         7                      2                   0.062791        0.189605                  0.111111      0              27.0                 3.019630                                    0.259259                                 0.074074                0.006977                           0.016279                        0.004651        5.274132              0.036796                         0.085858                      0.024531   -0.018999   -0.392183    -0.736335    -9.648399\n",
       "5              1                     770       11.09             11                         5                      2                   0.033766        0.014403                  0.423077      1              26.0                 0.426538                                    0.192308                                 0.076923                0.014286                           0.006494                        0.002597       69.431921              0.991885                         0.450857                      0.180343   -0.488244    0.334949    -6.418109     6.218063\n",
       "6              3                     294       55.63              2                         7                      1                   0.037415        0.189218                  0.181818      0              11.0                 5.057273                                    0.636364                                 0.090909                0.006803                           0.023810                        0.003401        5.284918              0.035952                         0.125831                      0.017976   -0.200941   -0.051325    -3.007755     1.776288\n",
       "7              2                    1545       22.80              0                         8                      4                   0.006472        0.014757                  0.000000      0              10.0                 2.280000                                    0.800000                                 0.400000                0.000000                           0.005178                        0.002589       67.763158              0.000000                         0.350877                      0.175439    0.163977    0.383210     5.297117     7.485310\n",
       "8              6                     962       65.44              7                         0                      2                   0.028067        0.068025                  0.259259      0              27.0                 2.423704                                    0.000000                                 0.074074                0.007277                           0.000000                        0.002079       14.700489              0.106968                         0.000000                      0.030562   -0.068084   -0.503479     0.829160    -6.073065\n",
       "9              2                     725       41.08             10                         2                      4                   0.037241        0.056662                  0.370370      0              27.0                 1.521481                                    0.074074                                 0.148148                0.013793                           0.002759                        0.005517       17.648491              0.243427                         0.048685                      0.097371   -0.128823    0.365507    -3.321243     8.314712\n",
       "10             5                    1533       84.73              4                         2                      4                   0.010437        0.055271                  0.250000      0              16.0                 5.295625                                    0.125000                                 0.250000                0.002609                           0.001305                        0.002609       18.092765              0.047209                         0.023604                      0.047209    0.310071   -0.116355     3.008145    -7.337041\n",
       "11             4                     764       28.98              8                         0                      0                   0.026178        0.037932                  0.400000      0              20.0                 1.449000                                    0.000000                                 0.000000                0.010471                           0.000000                        0.000000       26.363009              0.276052                         0.000000                      0.000000   -0.514894   -0.300758    -7.237004    -4.395898\n",
       "12             4                    1736        5.46              4                        10                      4                   0.005760        0.003145                  0.400000      0              10.0                 0.546000                                    1.000000                                 0.400000                0.002304                           0.005760                        0.002304      317.948718              0.732601                         1.831502                      0.732601    0.375869    0.029979     5.451623     6.534986\n",
       "13             4                    1705       16.96              7                         4                      4                   0.015836        0.009947                  0.259259      0              27.0                 0.628148                                    0.148148                                 0.148148                0.004106                           0.002346                        0.002346      100.530660              0.412736                         0.235849                      0.235849    0.076311   -0.012065     0.691358     0.240064\n",
       "14             6                    1659       52.53              2                         1                      4                   0.012658        0.031664                  0.095238      0              21.0                 2.501429                                    0.047619                                 0.190476                0.001206                           0.000603                        0.002411       31.581953              0.038073                         0.019037                      0.076147    0.310864   -0.310105     3.279893    -6.192203\n",
       "15             1                     870       32.45              3                         1                      5                   0.006897        0.037299                  0.500000      0               6.0                 5.408333                                    0.166667                                 0.833333                0.003448                           0.001149                        0.005747       26.810478              0.092450                         0.030817                      0.154083    0.165564    0.752756     0.948456     9.741565\n",
       "16             3                    1295       42.90             11                        10                      0                   0.016988        0.033127                  0.500000      0              22.0                 1.950000                                    0.454545                                 0.000000                0.008494                           0.007722                        0.000000       30.186480              0.256410                         0.233100                      0.000000   -0.453786   -0.227552    -5.629910    -2.260554\n",
       "17             6                     590       79.84              6                        10                      4                   0.040678        0.135322                  0.250000      0              24.0                 3.326667                                    0.416667                                 0.166667                0.010169                           0.016949                        0.006780        7.389780              0.075150                         0.125251                      0.050100    0.462997   -0.382638     6.386006    -7.388077\n",
       "18             3                     139       59.00              8                         5                      5                   0.028777        0.424460                  2.000000      0               4.0                14.750000                                    1.250000                                 1.250000                0.057554                           0.035971                        0.035971        2.355932              0.135593                         0.084746                      0.084746    0.514782    0.422194     5.876467     2.114941\n",
       "19             3                    1724       25.40              7                         4                      3                   0.011021        0.014733                  0.368421      0              19.0                 1.336842                                    0.210526                                 0.157895                0.004060                           0.002320                        0.001740       67.874016              0.275591                         0.157480                      0.118110   -0.079730    0.108762    -0.604102     0.155842\n",
       "20             3                    1691       59.61              1                         2                      2                   0.008870        0.035251                  0.066667      0              15.0                 3.974000                                    0.133333                                 0.133333                0.000591                           0.001183                        0.001183       28.367724              0.016776                         0.033551                      0.033551   -0.194797    0.039379    -1.836084     1.517769\n",
       "21             4                    1505        2.70              6                         4                      0                   0.003322        0.001794                  1.200000      0               5.0                 0.540000                                    0.800000                                 0.000000                0.003987                           0.002658                        0.000000      557.407407              2.222222                         1.481481                      0.000000   -0.295255   -0.262198    -4.205016    -1.116313\n",
       "22             4                     934       98.54              0                         5                      2                   0.008565        0.105503                  0.000000      0               8.0                12.317500                                    0.625000                                 0.250000                0.000000                           0.005353                        0.002141        9.478384              0.000000                         0.050741                      0.020296    0.078335   -0.110298     1.048803    -0.592465\n",
       "23             2                     125       25.50              5                         6                      2                   0.192000        0.204000                  0.208333      0              24.0                 1.062500                                    0.250000                                 0.083333                0.040000                           0.048000                        0.016000        4.901961              0.196078                         0.235294                      0.078431   -0.329137    0.162225    -6.625201     5.336575\n",
       "24             1                      71       78.91              1                         4                      4                   0.014085        1.111408                  1.000000      0               1.0                78.910000                                    4.000000                                 4.000000                0.014085                           0.056338                        0.056338        0.899759              0.012673                         0.050691                      0.050691    0.403147    0.770950     8.363058     6.735775\n",
       "25             5                     816       81.54              8                         7                      1                   0.011029        0.099926                  0.888889      0               9.0                 9.060000                                    0.777778                                 0.111111                0.009804                           0.008578                        0.001225       10.007358              0.098111                         0.085847                      0.012264    0.026040   -0.380261    -1.554787    -4.447748\n",
       "26             3                    1503       23.00             10                         3                      1                   0.019295        0.015303                  0.344828      0              29.0                 0.793103                                    0.103448                                 0.034483                0.006653                           0.001996                        0.000665       65.347826              0.434783                         0.130435                      0.043478   -0.515099   -0.115126    -9.055705    -2.439164\n",
       "27             4                     329       56.65             10                         2                      5                   0.063830        0.172188                  0.476190      0              21.0                 2.697619                                    0.095238                                 0.238095                0.030395                           0.006079                        0.015198        5.807590              0.176523                         0.035305                      0.088261    0.297538    0.152559     3.592706     1.074626\n",
       "28             6                    1629       40.42              6                         7                      4                   0.013505        0.024813                  0.272727      0              22.0                 1.837273                                    0.318182                                 0.181818                0.003683                           0.004297                        0.002455       40.301831              0.148441                         0.173182                      0.098961    0.394547   -0.357028     7.274017    -5.021105\n",
       "29             5                    1435       91.96              4                         3                      3                   0.013240        0.064084                  0.210526      0              19.0                 4.840000                                    0.157895                                 0.157895                0.002787                           0.002091                        0.002091       15.604611              0.043497                         0.032623                      0.032623    0.146086   -0.234990     2.525899    -7.679103\n",
       "30             6                     314       48.54              6                         1                      1                   0.076433        0.154586                  0.250000      0              24.0                 2.022500                                    0.041667                                 0.041667                0.019108                           0.003185                        0.003185        6.468892              0.123609                         0.020602                      0.020602   -0.174238   -0.579916    -5.421681    -6.560289\n",
       "31             5                     285        6.23              5                         6                      2                   0.105263        0.021860                  0.166667      0              30.0                 0.207667                                    0.200000                                 0.066667                0.017544                           0.021053                        0.007018       45.746388              0.802568                         0.963082                      0.321027   -0.119605   -0.385611    -3.364026    -6.627456\n",
       "32             5                     891       78.96              2                        10                      2                   0.028058        0.088620                  0.080000      0              25.0                 3.158400                                    0.400000                                 0.080000                0.002245                           0.011223                        0.002245       11.284195              0.025329                         0.126646                      0.025329    0.050645   -0.414961    -0.568405    -9.569429\n",
       "33             2                    1355       48.87              2                         0                      4                   0.005166        0.036066                  0.285714      0               7.0                 6.981429                                    0.000000                                 0.571429                0.001476                           0.000000                        0.002952       27.726622              0.040925                         0.000000                      0.081850    0.076826    0.474456     2.842475     8.743980\n",
       "34             2                     866       39.38             10                         9                      1                   0.004619        0.045473                  2.500000      0               4.0                 9.845000                                    2.250000                                 0.250000                0.011547                           0.010393                        0.001155       21.990858              0.253936                         0.228542                      0.025394   -0.169790    0.165909    -2.875839     1.616999\n",
       "35             2                     335       14.40              0                         9                      5                   0.014925        0.042985                  0.000000      0               5.0                 2.880000                                    1.800000                                 1.000000                0.000000                           0.026866                        0.014925       23.263889              0.000000                         0.625000                      0.347222    0.428080    0.528127     1.952261     7.529419\n",
       "36             5                     834       80.64              0                        10                      3                   0.015588        0.096691                  0.000000      0              13.0                 6.203077                                    0.769231                                 0.230769                0.000000                           0.011990                        0.003597       10.342262              0.000000                         0.124008                      0.037202    0.344872   -0.257029     3.983405    -0.253358\n",
       "37             2                    1397       62.59              7                         9                      4                   0.017895        0.044803                  0.280000      1              25.0                 2.503600                                    0.360000                                 0.160000                0.005011                           0.006442                        0.002863       22.319859              0.111839                         0.143793                      0.063908    0.028174    0.299678    -0.008178     5.653863\n",
       "38             5                    1561       91.75              7                         6                      2                   0.012172        0.058776                  0.368421      0              19.0                 4.828947                                    0.315789                                 0.105263                0.004484                           0.003844                        0.001281       17.013624              0.076294                         0.065395                      0.021798    0.041643   -0.350189    -0.433653    -7.456149\n",
       "39             4                     847       22.88              4                         5                      2                   0.010626        0.027013                  0.444444      0               9.0                 2.542222                                    0.555556                                 0.222222                0.004723                           0.005903                        0.002361       37.019231              0.174825                         0.218531                      0.087413    0.007517   -0.100789    -1.865648    -1.925621\n",
       "40             1                    1520       41.88              6                         8                      2                   0.001316        0.027553                  3.000000      0               2.0                20.940000                                    4.000000                                 1.000000                0.003947                           0.005263                        0.001316       36.294174              0.143266                         0.191022                      0.047755   -0.046234    0.460097     6.282418     6.576899\n",
       "41             2                     622       60.75             11                         5                      4                   0.012862        0.097669                  1.375000      0               8.0                 7.593750                                    0.625000                                 0.500000                0.017685                           0.008039                        0.006431       10.238683              0.181070                         0.082305                      0.065844    0.168154    0.455299     3.343559     4.261848\n",
       "42             4                    1012       59.90              2                         3                      2                   0.014822        0.059190                  0.133333      0              15.0                 3.993333                                    0.200000                                 0.133333                0.001976                           0.002964                        0.001976       16.894825              0.033389                         0.050083                      0.033389   -0.074133   -0.129078    -1.038483    -1.818782\n",
       "43             2                    1451       23.10              3                         9                      3                   0.001378        0.015920                  1.500000      0               2.0                11.550000                                    4.500000                                 1.500000                0.002068                           0.006203                        0.002068       62.813853              0.129870                         0.389610                      0.129870    0.216275    0.373713     6.305847     7.139262\n",
       "44             2                     401       80.86              0                         1                      0                   0.019950        0.201646                  0.000000      0               8.0                10.107500                                    0.125000                                 0.000000                0.000000                           0.002494                        0.000000        4.959189              0.000000                         0.012367                      0.000000   -0.509207    0.084602    -3.595303     3.838764\n",
       "45             6                     960       93.09              7                         2                      3                   0.010417        0.096969                  0.700000      0              10.0                 9.309000                                    0.200000                                 0.300000                0.007292                           0.002083                        0.003125       10.312601              0.075196                         0.021485                      0.032227    0.334851   -0.332647     1.133462    -3.823445\n",
       "46             6                    1433       72.19              7                         7                      0                   0.017446        0.050377                  0.280000      0              25.0                 2.887600                                    0.280000                                 0.000000                0.004885                           0.004885                        0.000000       19.850395              0.096966                         0.096966                      0.000000   -0.228582   -0.746479    -1.578820    -7.881694\n",
       "47             6                    1424       66.90              9                         8                      3                   0.017556        0.046980                  0.360000      0              25.0                 2.676000                                    0.320000                                 0.120000                0.006320                           0.005618                        0.002107       21.285501              0.134529                         0.119581                      0.044843    0.242373   -0.469967     4.787653    -5.749266\n",
       "48             6                    1820       54.64              0                         0                      1                   0.007143        0.030022                  0.000000      0              13.0                 4.203077                                    0.000000                                 0.076923                0.000000                           0.000000                        0.000549       33.308931              0.000000                         0.000000                      0.018302   -0.078348   -0.545897     1.096457    -6.627123\n",
       "49             1                      16       32.29              2                         0                      5                   1.500000        2.018125                  0.083333      0              24.0                 1.345417                                    0.000000                                 0.208333                0.125000                           0.000000                        0.312500        0.495509              0.061939                         0.000000                      0.154847   -0.063479    0.660680    -2.404566     9.728538\n",
       "50             4                     617       90.73              0                         0                      5                   0.001621        0.147050                  0.000000      0               1.0                90.730000                                    0.000000                                 5.000000                0.000000                           0.000000                        0.008104        6.800397              0.000000                         0.000000                      0.055109    0.775119    0.381716     8.732438     6.564204\n",
       "51             3                    1593       25.53              2                         2                      2                   0.017577        0.016026                  0.071429      0              28.0                 0.911786                                    0.071429                                 0.071429                0.001255                           0.001255                        0.001255       62.397180              0.078339                         0.078339                      0.078339   -0.358897   -0.023995    -0.968361    -1.003854\n",
       "52             1                     608       85.05              3                         5                      2                   0.013158        0.139885                  0.375000      0               8.0                10.631250                                    0.625000                                 0.250000                0.004934                           0.008224                        0.003289        7.148736              0.035273                         0.058789                      0.023516   -0.218367    0.417477    -2.901950     3.705740\n",
       "53             1                    1385       34.68              5                         8                      4                   0.019495        0.025040                  0.185185      1              27.0                 1.284444                                    0.296296                                 0.148148                0.003610                           0.005776                        0.002888       39.936563              0.144175                         0.230681                      0.115340   -0.123766    0.468661    -0.372667     6.958865\n",
       "54             3                     983       14.07              2                         4                      0                   0.019329        0.014313                  0.105263      0              19.0                 0.740526                                    0.210526                                 0.000000                0.002035                           0.004069                        0.000000       69.864961              0.142146                         0.284293                      0.000000   -0.534646   -0.170078    -6.728629    -3.601081\n",
       "55             1                     768        7.24              4                        10                      3                   0.014323        0.009427                  0.363636      0              11.0                 0.658182                                    0.909091                                 0.272727                0.005208                           0.013021                        0.003906      106.077348              0.552486                         1.381215                      0.414365   -0.069446    0.458316     1.747853     7.119153\n",
       "56             1                    1474       60.64              9                         0                      5                   0.012890        0.041140                  0.473684      0              19.0                 3.191579                                    0.000000                                 0.263158                0.006106                           0.000000                        0.003392       24.307388              0.148417                         0.000000                      0.082454   -0.012436    0.677333    -1.976915     7.596049\n",
       "57             6                     692       21.65              7                         7                      5                   0.021676        0.031286                  0.466667      0              15.0                 1.443333                                    0.466667                                 0.333333                0.010116                           0.010116                        0.007225       31.963048              0.323326                         0.323326                      0.230947    0.624758   -0.205781     7.073208    -3.765071\n",
       "58             2                     351       50.75              1                         7                      0                   0.045584        0.144587                  0.062500      0              16.0                 3.171875                                    0.437500                                 0.000000                0.002849                           0.019943                        0.000000        6.916256              0.019704                         0.137931                      0.000000   -0.511703   -0.003923    -4.087084     2.085103\n",
       "59             1                     107       39.55              1                         6                      4                   0.252336        0.369626                  0.037037      0              27.0                 1.464815                                    0.222222                                 0.148148                0.009346                           0.056075                        0.037383        2.705436              0.025284                         0.151707                      0.101138   -0.137674    0.496277    -0.340919     8.913836\n",
       "60             5                    1237       48.22              7                         2                      3                   0.008084        0.038981                  0.700000      0              10.0                 4.822000                                    0.200000                                 0.300000                0.005659                           0.001617                        0.002425       25.653256              0.145168                         0.041477                      0.062215    0.203260   -0.160857     3.865201    -2.680700\n",
       "61             2                    1450       62.63              5                         9                      3                   0.010345        0.043193                  0.333333      0              15.0                 4.175333                                    0.600000                                 0.200000                0.003448                           0.006207                        0.002069       23.151844              0.079834                         0.143701                      0.047900   -0.009664    0.257652    -1.286905     3.962601\n",
       "62             5                     508       57.90              2                         7                      0                   0.027559        0.113976                  0.142857      0              14.0                 4.135714                                    0.500000                                 0.000000                0.003937                           0.013780                        0.000000        8.773748              0.034542                         0.120898                      0.000000   -0.198592   -0.509611    -1.376561    -2.715564\n",
       "63             1                    1748       26.31              0                         9                      1                   0.008581        0.015051                  0.000000      0              15.0                 1.754000                                    0.600000                                 0.066667                0.000000                           0.005149                        0.000572       66.438616              0.000000                         0.342075                      0.038008   -0.437345    0.230964    -6.549467     1.752992\n",
       "64             6                    1000       61.24              7                         3                      0                   0.009000        0.061240                  0.777778      0               9.0                 6.804444                                    0.333333                                 0.000000                0.007000                           0.003000                        0.000000       16.329197              0.114304                         0.048988                      0.000000   -0.124097   -0.617249    -1.709996    -4.619247\n",
       "65             1                    1123       28.94              1                         0                      5                   0.013357        0.025770                  0.066667      0              15.0                 1.929333                                    0.000000                                 0.333333                0.000890                           0.000000                        0.004452       38.804423              0.034554                         0.000000                      0.172771    0.023608    0.693424    -0.933752     9.945416\n",
       "66             1                     232       18.27              9                         5                      2                   0.008621        0.078750                  4.500000      0               2.0                 9.135000                                    2.500000                                 1.000000                0.038793                           0.021552                        0.008621       12.698413              0.492611                         0.273673                      0.109469   -0.120305    0.509492    -2.771090     3.306692\n",
       "67             2                    1327        7.02              7                         1                      5                   0.018839        0.005290                  0.280000      0              25.0                 0.280800                                    0.040000                                 0.200000                0.005275                           0.000754                        0.003768      189.031339              0.997151                         0.142450                      0.712251    0.002764    0.467928    -2.202643     8.647305\n",
       "68             6                     449       21.00              5                         4                      2                   0.002227        0.046771                  5.000000      0               1.0                21.000000                                    4.000000                                 2.000000                0.011136                           0.008909                        0.004454       21.380952              0.238095                         0.190476                      0.095238    0.431033   -0.314025     8.772422     1.874182\n",
       "69             4                    1228        3.17              7                         4                      4                   0.024430        0.002581                  0.233333      0              30.0                 0.105667                                    0.133333                                 0.133333                0.005700                           0.003257                        0.003257      387.381703              2.208202                         1.261830                      1.261830    0.039822   -0.019797     0.777900    -0.082569\n",
       "70             1                     861       31.34             11                         3                      0                   0.023229        0.036400                  0.550000      0              20.0                 1.567000                                    0.150000                                 0.000000                0.012776                           0.003484                        0.000000       27.472878              0.350989                         0.095724                      0.000000   -0.752514    0.193453    -9.426851     2.579887\n",
       "71             5                      70       40.04              1                         1                      4                   0.400000        0.572000                  0.035714      0              28.0                 1.430000                                    0.035714                                 0.142857                0.014286                           0.014286                        0.057143        1.748252              0.024975                         0.024975                      0.099900    0.148324   -0.153713     2.612095    -2.954630\n",
       "72             6                    1154       57.64              7                        10                      4                   0.017331        0.049948                  0.350000      0              20.0                 2.882000                                    0.500000                                 0.200000                0.006066                           0.008666                        0.003466       20.020819              0.121443                         0.173491                      0.069396    0.486169   -0.364226     7.220492    -4.987102\n",
       "73             3                    1393       99.58              1                         8                      0                   0.013640        0.071486                  0.052632      0              19.0                 5.241053                                    0.421053                                 0.000000                0.000718                           0.005743                        0.000000       13.988753              0.010042                         0.080337                      0.000000   -0.408322   -0.220590    -5.144193    -2.056725\n",
       "74             2                    1068       23.64              4                         0                      1                   0.013109        0.022135                  0.285714      0              14.0                 1.688571                                    0.000000                                 0.071429                0.003745                           0.000000                        0.000936       45.177665              0.169205                         0.000000                      0.042301   -0.491409    0.157765    -8.690619     1.150595\n",
       "75             6                     300       93.04              4                         4                      3                   0.033333        0.310133                  0.400000      0              10.0                 9.304000                                    0.400000                                 0.300000                0.013333                           0.013333                        0.010000        3.224420              0.042992                         0.042992                      0.032244    0.380793   -0.345798     2.005065    -1.689218\n",
       "76             2                     250       33.95             11                        10                      3                   0.056000        0.135800                  0.785714      0              14.0                 2.425000                                    0.714286                                 0.214286                0.044000                           0.040000                        0.012000        7.363770              0.324006                         0.294551                      0.088365    0.007638    0.287106    -1.164025     4.711224\n",
       "77             4                    1411       49.25              2                         8                      4                   0.002835        0.034904                  0.500000      0               4.0                12.312500                                    2.000000                                 1.000000                0.001417                           0.005670                        0.002835       28.649746              0.040609                         0.162437                      0.081218    0.485121    0.094908     7.957685     1.416044\n",
       "78             4                    1279       89.11              0                         0                      3                   0.010946        0.069672                  0.000000      0              14.0                 6.365000                                    0.000000                                 0.214286                0.000000                           0.000000                        0.002346       14.353047              0.000000                         0.000000                      0.033666    0.056443   -0.014843     1.939872    -1.268278\n",
       "79             3                    1771        2.51              3                         1                      4                   0.005082        0.001417                  0.333333      0               9.0                 0.278889                                    0.111111                                 0.444444                0.001694                           0.000565                        0.002259      705.577689              1.195219                         0.398406                      1.593625    0.124520    0.280330     0.724071    10.539537\n",
       "80             3                    1642        6.25              7                         8                      2                   0.004872        0.003806                  0.875000      0               8.0                 0.781250                                    1.000000                                 0.250000                0.004263                           0.004872                        0.001218      262.720000              1.120000                         1.280000                      0.320000   -0.041729    0.049058    -4.233076    -0.266492\n",
       "81             3                    1018       27.26              1                         9                      0                   0.023576        0.026778                  0.041667      0              24.0                 1.135833                                    0.375000                                 0.000000                0.000982                           0.008841                        0.000000       37.344094              0.036684                         0.330154                      0.000000   -0.489304   -0.242547    -6.257372    -3.666443\n",
       "82             3                      44       78.64              1                        10                      1                   0.090909        1.787273                  0.250000      0               4.0                19.660000                                    2.500000                                 0.250000                0.022727                           0.227273                        0.022727        0.559512              0.012716                         0.127162                      0.012716   -0.014908   -0.026908    -0.335554     1.259151\n",
       "83             3                     550       84.57              6                         0                      3                   0.040000        0.153764                  0.272727      0              22.0                 3.844091                                    0.000000                                 0.136364                0.010909                           0.000000                        0.005455        6.503488              0.070947                         0.000000                      0.035474   -0.131056    0.134721    -0.016288     2.413416\n",
       "84             2                     109       24.32             10                         0                      5                   0.100917        0.223119                  0.909091      0              11.0                 2.210909                                    0.000000                                 0.454545                0.091743                           0.000000                        0.045872        4.481908              0.411184                         0.000000                      0.205592    0.167862    0.578846     3.694528     3.950156\n",
       "85             3                    1660       12.58              6                         5                      1                   0.009036        0.007578                  0.400000      0              15.0                 0.838667                                    0.333333                                 0.066667                0.003614                           0.003012                        0.000602      131.955485              0.476948                         0.397456                      0.079491   -0.331618   -0.064990    -7.215877    -0.368866\n",
       "86             2                    1078       58.61              9                        10                      3                   0.007421        0.054369                  1.125000      0               8.0                 7.326250                                    1.250000                                 0.375000                0.008349                           0.009276                        0.002783       18.392766              0.153557                         0.170619                      0.051186    0.100023    0.308193     5.269053     4.068360\n",
       "87             2                    1464       58.21              8                         3                      0                   0.017760        0.039761                  0.307692      0              26.0                 2.238846                                    0.115385                                 0.000000                0.005464                           0.002049                        0.000000       25.150318              0.137433                         0.051538                      0.000000   -0.705927   -0.027746    -8.902964    -0.702432\n",
       "88             5                    1228       85.93             11                         0                      1                   0.016287        0.069976                  0.550000      0              20.0                 4.296500                                    0.000000                                 0.050000                0.008958                           0.000000                        0.000814       14.290702              0.128011                         0.000000                      0.011637   -0.235100   -0.386060    -0.104191    -5.782523\n",
       "89             6                    1790       70.66              5                         1                      0                   0.007263        0.039475                  0.384615      0              13.0                 5.435385                                    0.076923                                 0.000000                0.002793                           0.000559                        0.000000       25.332579              0.070761                         0.014152                      0.000000   -0.207470   -0.639821     0.085387    -5.232473\n",
       "90             5                    1052       67.09              6                         2                      4                   0.018061        0.063774                  0.315789      0              19.0                 3.531053                                    0.105263                                 0.210526                0.005703                           0.001901                        0.003802       15.680429              0.089432                         0.029811                      0.059621    0.266703   -0.120838     2.963937    -6.551115\n",
       "91             1                     996       71.94              7                         0                      1                   0.027108        0.072229                  0.259259      1              27.0                 2.664444                                    0.000000                                 0.037037                0.007028                           0.000000                        0.001004       13.844871              0.097303                         0.000000                      0.013900   -0.697928    0.261035   -10.169147     0.356178\n",
       "92             2                    1515        7.69             11                         4                      1                   0.013861        0.005076                  0.523810      0              21.0                 0.366190                                    0.190476                                 0.047619                0.007261                           0.002640                        0.000660      197.009103              1.430429                         0.520156                      0.130039   -0.518834    0.094548    -9.144720    -1.666552\n",
       "93             6                    1245       22.06              4                         7                      4                   0.008032        0.017719                  0.400000      0              10.0                 2.206000                                    0.700000                                 0.400000                0.003213                           0.005622                        0.003213       56.436990              0.181324                         0.317316                      0.181324    0.530101   -0.283222     8.804177    -3.323750\n",
       "94             2                     952        0.58              8                         5                      0                   0.016807        0.000609                  0.500000      0              16.0                 0.036250                                    0.312500                                 0.000000                0.008403                           0.005252                        0.000000     1641.379310             13.793103                         8.620690                      0.000000   -0.595572    0.022622    -5.722739     2.731173\n",
       "95             5                    1570       47.79              4                        10                      5                   0.001274        0.030439                  2.000000      0               2.0                23.895000                                    5.000000                                 2.500000                0.002548                           0.006369                        0.003185       32.852061              0.083700                         0.209249                      0.104624    0.898808    0.061187     9.448620    -0.520349\n",
       "96             3                    1599       36.79              9                         5                      3                   0.010006        0.023008                  0.562500      0              16.0                 2.299375                                    0.312500                                 0.187500                0.005629                           0.003127                        0.001876       43.462898              0.244632                         0.135906                      0.081544   -0.020716    0.121688    -0.666655    -0.026841\n",
       "97             2                    1305       87.65              7                         8                      4                   0.021456        0.067165                  0.250000      1              28.0                 3.130357                                    0.285714                                 0.142857                0.005364                           0.006130                        0.003065       14.888762              0.079863                         0.091272                      0.045636   -0.005069    0.290251    -0.061397     5.488880\n",
       "98             6                     122       14.32              1                         5                      5                   0.114754        0.117377                  0.071429      0              14.0                 1.022857                                    0.357143                                 0.357143                0.008197                           0.040984                        0.040984        8.519553              0.069832                         0.349162                      0.349162    0.607179   -0.185758     5.437742    -3.972778\n",
       "99             6                     861       97.36              6                         9                      5                   0.009292        0.113078                  0.750000      0               8.0                12.170000                                    1.125000                                 0.625000                0.006969                           0.010453                        0.005807        8.843468              0.061627                         0.092440                      0.051356    0.811504   -0.186643     7.877558    -1.742309\n",
       "100            6                    1577       78.41              4                         6                      1                   0.014585        0.049721                  0.173913      0              23.0                 3.409130                                    0.260870                                 0.043478                0.002536                           0.003805                        0.000634       20.112231              0.051014                         0.076521                      0.012753   -0.065516   -0.642002    -0.610514    -8.484739\n",
       "101            4                     597       45.98              0                         4                      4                   0.028476        0.077018                  0.000000      0              17.0                 2.704706                                    0.235294                                 0.235294                0.000000                           0.006700                        0.006700       12.983906              0.000000                         0.086994                      0.086994    0.225813    0.042935     1.891194    -0.140865\n",
       "102            1                    1319       37.10              7                         7                      0                   0.014405        0.028127                  0.368421      0              19.0                 1.952632                                    0.368421                                 0.000000                0.005307                           0.005307                        0.000000       35.552561              0.188679                         0.188679                      0.000000   -0.666603    0.150451    -7.475861     0.901785\n",
       "103            1                    1335       38.95              5                         1                      3                   0.014232        0.029176                  0.263158      0              19.0                 2.050000                                    0.052632                                 0.157895                0.003745                           0.000749                        0.002247       34.274711              0.128370                         0.025674                      0.077022   -0.310403    0.478123    -4.297891     7.470648\n",
       "104            6                     894       77.50              6                         6                      4                   0.011186        0.086689                  0.600000      0              10.0                 7.750000                                    0.600000                                 0.400000                0.006711                           0.006711                        0.004474       11.535484              0.077419                         0.077419                      0.051613    0.554097   -0.270644     6.861796    -1.661314\n",
       "105            5                     533        0.28              6                         0                      2                   0.003752        0.000525                  3.000000      0               2.0                 0.140000                                    0.000000                                 1.000000                0.011257                           0.000000                        0.003752     1903.571429             21.428571                         0.000000                      7.142857    0.119074   -0.158487    -1.929096    -2.241485\n",
       "106            3                    1636       70.40              8                         9                      4                   0.009169        0.043032                  0.533333      0              15.0                 4.693333                                    0.600000                                 0.266667                0.004890                           0.005501                        0.002445       23.238636              0.113636                         0.127841                      0.056818    0.241066    0.182228     5.195446     3.212117\n",
       "107            3                     185       98.96              4                         2                      1                   0.145946        0.534919                  0.148148      0              27.0                 3.665185                                    0.074074                                 0.037037                0.021622                           0.010811                        0.005405        1.869442              0.040420                         0.020210                      0.010105   -0.439997   -0.096285    -7.824890    -3.938468\n",
       "108            4                     113       23.38             11                        10                      0                   0.159292        0.206903                  0.611111      0              18.0                 1.298889                                    0.555556                                 0.000000                0.097345                           0.088496                        0.000000        4.833191              0.470488                         0.427716                      0.000000   -0.314018   -0.358384    -3.556854    -4.556876\n",
       "109            4                    1814       52.98              3                         7                      4                   0.007166        0.029206                  0.230769      0              13.0                 4.075385                                    0.538462                                 0.307692                0.001654                           0.003859                        0.002205       34.239336              0.056625                         0.132125                      0.075500    0.316169    0.028526     5.652216     5.887857\n",
       "110            4                     477        1.36             10                         1                      1                   0.044025        0.002851                  0.476190      0              21.0                 0.064762                                    0.047619                                 0.047619                0.020964                           0.002096                        0.002096      350.735294              7.352941                         0.735294                      0.735294   -0.372219   -0.209986    -7.030723    -4.756164\n",
       "111            6                    1123       33.03             10                         6                      3                   0.005343        0.029412                  1.666667      0               6.0                 5.505000                                    1.000000                                 0.500000                0.008905                           0.005343                        0.002671       33.999394              0.302755                         0.181653                      0.090827    0.423091   -0.326854     8.459423    -1.171012\n",
       "112            2                    1278       98.78              2                         3                      1                   0.006260        0.077293                  0.250000      0               8.0                12.347500                                    0.375000                                 0.125000                0.001565                           0.002347                        0.000782       12.937842              0.020247                         0.030371                      0.010124   -0.312276    0.153726    -3.635951     3.682327\n",
       "113            3                    1171       90.98              8                         1                      0                   0.013664        0.077694                  0.500000      0              16.0                 5.686250                                    0.062500                                 0.000000                0.006832                           0.000854                        0.000000       12.870961              0.087931                         0.010991                      0.000000   -0.511691   -0.128064    -7.756983    -1.314464\n",
       "114            4                    1175       77.42              0                         5                      3                   0.011915        0.065889                  0.000000      0              14.0                 5.530000                                    0.357143                                 0.214286                0.000000                           0.004255                        0.002553       15.176957              0.000000                         0.064583                      0.038750    0.140036   -0.053956     0.583956    -0.297313\n",
       "115            2                    1094       91.26              9                         0                      3                   0.006399        0.083419                  1.285714      0               7.0                13.037143                                    0.000000                                 0.428571                0.008227                           0.000000                        0.002742       11.987727              0.098619                         0.000000                      0.032873   -0.047491    0.394974    -2.344936     4.863413\n",
       "116            1                     990       19.42              1                         7                      3                   0.020202        0.019616                  0.050000      0              20.0                 0.971000                                    0.350000                                 0.150000                0.001010                           0.007071                        0.003030       50.978373              0.051493                         0.360453                      0.154480   -0.219253    0.421730    -4.529353     6.566694\n",
       "117            5                      37       62.17              9                         4                      4                   0.783784        1.680270                  0.310345      0              29.0                 2.143793                                    0.137931                                 0.137931                0.243243                           0.108108                        0.108108        0.595142              0.144764                         0.064340                      0.064340    0.195995   -0.172074     3.783877    -3.970117\n",
       "118            5                     356       68.03              5                         3                      5                   0.019663        0.191096                  0.714286      0               7.0                 9.718571                                    0.428571                                 0.714286                0.014045                           0.008427                        0.014045        5.232985              0.073497                         0.044098                      0.073497    0.603364    0.049990     5.864615    -0.412701\n",
       "119            6                     493       86.24              6                         0                      3                   0.036511        0.174929                  0.333333      0              18.0                 4.791111                                    0.000000                                 0.166667                0.012170                           0.000000                        0.006085        5.716605              0.069573                         0.000000                      0.034787    0.203664   -0.357989     3.132778    -1.899959\n",
       "120            3                     654       85.68              4                        10                      3                   0.001529        0.131009                  4.000000      0               1.0                85.680000                                   10.000000                                 3.000000                0.006116                           0.015291                        0.004587        7.633053              0.046685                         0.116713                      0.035014    0.599884    0.288805    10.029152     3.993459\n",
       "121            2                     509       85.16              1                         5                      3                   0.031434        0.167308                  0.062500      0              16.0                 5.322500                                    0.312500                                 0.187500                0.001965                           0.009823                        0.005894        5.976984              0.011743                         0.058713                      0.035228   -0.064162    0.289067    -1.892002     3.962385\n",
       "122            4                     580       89.67              3                         7                      1                   0.029310        0.154603                  0.176471      0              17.0                 5.274706                                    0.411765                                 0.058824                0.005172                           0.012069                        0.001724        6.468161              0.033456                         0.078064                      0.011152   -0.154464   -0.262612    -5.020028    -4.164045\n",
       "123            3                     435        9.79              2                         5                      4                   0.052874        0.022506                  0.086957      0              23.0                 0.425652                                    0.217391                                 0.173913                0.004598                           0.011494                        0.009195       44.433095              0.204290                         0.510725                      0.408580    0.056000    0.183129     0.855468     3.161745\n",
       "124            3                     770       58.93              8                         0                      1                   0.029870        0.076532                  0.347826      0              23.0                 2.562174                                    0.000000                                 0.043478                0.010390                           0.000000                        0.001299       13.066350              0.135754                         0.000000                      0.016969   -0.470037   -0.054661    -7.892016    -3.045475\n",
       "125            5                    1786       69.83              6                         8                      3                   0.001120        0.039099                  3.000000      0               2.0                34.915000                                    4.000000                                 1.500000                0.003359                           0.004479                        0.001680       25.576400              0.085923                         0.114564                      0.042961    0.538039   -0.126085     8.643748     0.354909\n",
       "126            1                     485       17.63             10                         3                      5                   0.051546        0.036351                  0.400000      1              25.0                 0.705200                                    0.120000                                 0.200000                0.020619                           0.006186                        0.010309       27.509926              0.567215                         0.170164                      0.283607   -0.045454    0.639408    -2.877071     8.670666\n",
       "127            5                     690       58.35              8                         7                      3                   0.001449        0.084565                  8.000000      0               1.0                58.350000                                    7.000000                                 3.000000                0.011594                           0.010145                        0.004348       11.825193              0.137104                         0.119966                      0.051414    0.688224   -0.023057     9.598443     4.498495\n",
       "128            6                    1059       13.50              6                         9                      2                   0.023607        0.012748                  0.240000      0              25.0                 0.540000                                    0.360000                                 0.080000                0.005666                           0.008499                        0.001889       78.444444              0.444444                         0.666667                      0.148148    0.079045   -0.566241    -2.662472    -8.113151\n",
       "129            4                     420       89.92              2                         2                      3                   0.052381        0.214095                  0.090909      0              22.0                 4.087273                                    0.090909                                 0.136364                0.004762                           0.004762                        0.007143        4.670819              0.022242                         0.022242                      0.033363    0.010298   -0.060080     1.573126    -0.938134\n",
       "130            3                    1488       53.87              7                         9                      1                   0.017473        0.036203                  0.269231      0              26.0                 2.071923                                    0.346154                                 0.038462                0.004704                           0.006048                        0.000672       27.622053              0.129942                         0.167069                      0.018563   -0.352221   -0.158487    -5.746249    -2.608056\n",
       "131            5                     827       40.50              3                         3                      4                   0.024184        0.048972                  0.150000      0              20.0                 2.025000                                    0.150000                                 0.200000                0.003628                           0.003628                        0.004837       20.419753              0.074074                         0.074074                      0.098765    0.261068   -0.134363     4.178041    -4.973723\n",
       "132            2                     669       13.58              6                         7                      1                   0.002990        0.020299                  3.000000      0               2.0                 6.790000                                    3.500000                                 0.500000                0.008969                           0.010463                        0.001495       49.263623              0.441826                         0.515464                      0.073638   -0.166724    0.202663    -3.368636     1.122157\n",
       "133            4                     270       78.69              3                         0                      3                   0.092593        0.291444                  0.120000      0              25.0                 3.147600                                    0.000000                                 0.120000                0.011111                           0.000000                        0.011111        3.431186              0.038124                         0.000000                      0.038124   -0.065074   -0.054270     1.674929    -0.762417\n",
       "134            4                     466       48.17              8                         0                      0                   0.062232        0.103369                  0.275862      0              29.0                 1.661034                                    0.000000                                 0.000000                0.017167                           0.000000                        0.000000        9.674071              0.166078                         0.000000                      0.000000   -0.594823   -0.346396    -6.933539    -5.509274\n",
       "135            2                     959       11.63              6                        10                      0                   0.026069        0.012127                  0.240000      0              25.0                 0.465200                                    0.400000                                 0.000000                0.006257                           0.010428                        0.000000       82.459157              0.515907                         0.859845                      0.000000   -0.594076   -0.072731    -7.102866     1.122173\n",
       "136            2                     282       70.79              4                         8                      4                   0.024823        0.251028                  0.571429      0               7.0                10.112857                                    1.142857                                 0.571429                0.014184                           0.028369                        0.014184        3.983614              0.056505                         0.113010                      0.056505    0.255659    0.427677     2.551279     5.520360\n",
       "137            3                     304       12.09              2                         8                      0                   0.029605        0.039770                  0.222222      0               9.0                 1.343333                                    0.888889                                 0.000000                0.006579                           0.026316                        0.000000       25.144748              0.165426                         0.661704                      0.000000   -0.345505   -0.139198    -4.167716     0.540601\n",
       "138            3                    1237       96.40              3                         1                      3                   0.005659        0.077930                  0.428571      0               7.0                13.771429                                    0.142857                                 0.428571                0.002425                           0.000808                        0.002425       12.831950              0.031120                         0.010373                      0.031120    0.072192    0.199208     3.961724     5.320573\n",
       "139            3                    1152       91.91             10                         8                      5                   0.001736        0.079783                  5.000000      0               2.0                45.955000                                    4.000000                                 2.500000                0.008681                           0.006944                        0.004340       12.534001              0.108802                         0.087042                      0.054401    0.729235    0.449214     7.195333     3.121891\n",
       "140            5                      78       92.86              5                         1                      5                   0.384615        1.190513                  0.166667      0              30.0                 3.095333                                    0.033333                                 0.166667                0.064103                           0.012821                        0.064103        0.839974              0.053844                         0.010769                      0.053844    0.309379   -0.069951     2.987622    -1.125592\n",
       "141            5                     726       12.28              2                         5                      4                   0.012397        0.016915                  0.222222      0               9.0                 1.364444                                    0.555556                                 0.444444                0.002755                           0.006887                        0.005510       59.120521              0.162866                         0.407166                      0.325733    0.409993   -0.084070     4.961393    -3.539977\n",
       "142            2                     414       98.72              0                         5                      1                   0.031401        0.238454                  0.000000      0              13.0                 7.593846                                    0.384615                                 0.076923                0.000000                           0.012077                        0.002415        4.193679              0.000000                         0.050648                      0.010130   -0.326379    0.115879    -3.315692     3.210264\n",
       "143            1                     898        2.64              9                         3                      5                   0.033408        0.002940                  0.300000      1              30.0                 0.088000                                    0.100000                                 0.166667                0.010022                           0.003341                        0.005568      340.151515              3.409091                         1.136364                      1.893939   -0.113027    0.606027    -2.731879     8.654791\n",
       "144            1                     788       80.87              0                         8                      3                   0.010152        0.102627                  0.000000      0               8.0                10.108750                                    1.000000                                 0.375000                0.000000                           0.010152                        0.003807        9.744034              0.000000                         0.098924                      0.037097   -0.009384    0.479490     0.486314     4.017934\n",
       "145            1                    1312       51.43              7                         1                      1                   0.007622        0.039200                  0.700000      0              10.0                 5.143000                                    0.100000                                 0.100000                0.005335                           0.000762                        0.000762       25.510402              0.136107                         0.019444                      0.019444   -0.509092    0.343767    -5.396738     2.116115\n",
       "146            5                     106       81.05              2                         3                      3                   0.047170        0.764623                  0.400000      0               5.0                16.210000                                    0.600000                                 0.600000                0.018868                           0.028302                        0.028302        1.307835              0.024676                         0.037014                      0.037014    0.338113   -0.128701     1.796333    -1.447730\n",
       "147            4                     921        3.39              3                         4                      2                   0.002172        0.003681                  1.500000      0               2.0                 1.695000                                    2.000000                                 1.000000                0.003257                           0.004343                        0.002172      271.681416              0.884956                         1.179941                      0.589971    0.106477   -0.031264    -1.598890    -1.741543\n",
       "148            1                     299       42.06              9                         8                      3                   0.030100        0.140669                  1.000000      0               9.0                 4.673333                                    0.888889                                 0.333333                0.030100                           0.026756                        0.010033        7.108892              0.213980                         0.190204                      0.071327   -0.052695    0.501894    -1.488741     4.413533\n",
       "149            2                    1755        8.32              2                         0                      4                   0.005128        0.004741                  0.222222      0               9.0                 0.924444                                    0.000000                                 0.444444                0.001140                           0.000000                        0.002279      210.937500              0.240385                         0.000000                      0.480769    0.014812    0.458055     0.735757    10.523532\n",
       "150            5                     798       42.57             11                         6                      4                   0.035088        0.053346                  0.392857      0              28.0                 1.520357                                    0.214286                                 0.142857                0.013784                           0.007519                        0.005013       18.745595              0.258398                         0.140944                      0.093963    0.218758   -0.188690     5.473986    -4.980708\n",
       "151            1                     383       37.25              2                        10                      2                   0.070496        0.097258                  0.074074      1              27.0                 1.379630                                    0.370370                                 0.074074                0.005222                           0.026110                        0.005222       10.281879              0.053691                         0.268456                      0.053691   -0.378128    0.273612    -6.979367     4.646704\n",
       "152            2                     530       37.36              1                         3                      3                   0.049057        0.070491                  0.038462      0              26.0                 1.436923                                    0.115385                                 0.115385                0.001887                           0.005660                        0.005660       14.186296              0.026767                         0.080300                      0.080300   -0.242783    0.255831    -4.272055     8.582722\n",
       "153            5                    1300       22.86              3                         7                      3                   0.010000        0.017585                  0.230769      0              13.0                 1.758462                                    0.538462                                 0.230769                0.002308                           0.005385                        0.002308       56.867892              0.131234                         0.306212                      0.131234    0.242220   -0.227259     8.688376    -3.238228\n",
       "154            4                    1419       58.79              7                         9                      1                   0.006342        0.041431                  0.777778      0               9.0                 6.532222                                    1.000000                                 0.111111                0.004933                           0.006342                        0.000705       24.136758              0.119068                         0.153087                      0.017010   -0.055481   -0.233830    -3.448108    -2.288245\n",
       "155            3                    1741       11.94              7                         3                      5                   0.016657        0.006858                  0.241379      0              29.0                 0.411724                                    0.103448                                 0.172414                0.004021                           0.001723                        0.002872      145.812395              0.586265                         0.251256                      0.418760    0.089835    0.250874     0.781295     0.670698\n",
       "156            1                    1035       61.75              8                         0                      0                   0.002899        0.059662                  2.666667      0               3.0                20.583333                                    0.000000                                 0.000000                0.007729                           0.000000                        0.000000       16.761134              0.129555                         0.000000                      0.000000   -0.570798    0.311459    -4.103974     3.622528\n",
       "157            1                     818       88.58              7                         8                      3                   0.022005        0.108289                  0.388889      0              18.0                 4.921111                                    0.444444                                 0.166667                0.008557                           0.009780                        0.003667        9.234590              0.079025                         0.090314                      0.033868   -0.136569    0.430927    -1.925032     4.237090\n",
       "158            5                     756        8.12              1                         1                      1                   0.001323        0.010741                  1.000000      0               1.0                 8.120000                                    1.000000                                 1.000000                0.001323                           0.001323                        0.001323       93.103448              0.123153                         0.123153                      0.123153    0.008581   -0.268841    -1.596551    -2.891938\n",
       "159            2                     735       89.47              8                         9                      3                   0.035374        0.121728                  0.307692      0              26.0                 3.441154                                    0.346154                                 0.115385                0.010884                           0.012245                        0.004082        8.215044              0.089415                         0.100592                      0.033531   -0.112171    0.209136    -5.801327     4.619169\n",
       "160            5                    1262       81.87              4                         1                      0                   0.020602        0.064873                  0.153846      0              26.0                 3.148846                                    0.038462                                 0.000000                0.003170                           0.000792                        0.000000       15.414682              0.048858                         0.012214                      0.000000   -0.430301   -0.533354    -4.721782    -8.500515\n",
       "161            1                    1096       97.39              1                         4                      1                   0.011861        0.088859                  0.076923      0              13.0                 7.491538                                    0.307692                                 0.076923                0.000912                           0.003650                        0.000912       11.253722              0.010268                         0.041072                      0.010268   -0.449778    0.288271    -3.617204     3.726972\n",
       "162            4                     767        9.18              8                         8                      3                   0.024772        0.011969                  0.421053      0              19.0                 0.483158                                    0.421053                                 0.157895                0.010430                           0.010430                        0.003911       83.551198              0.871460                         0.871460                      0.326797    0.086161   -0.079241     1.167066     0.728088\n",
       "163            6                    1668       73.58              1                         5                      3                   0.012590        0.044113                  0.047619      0              21.0                 3.503810                                    0.238095                                 0.142857                0.000600                           0.002998                        0.001799       22.669204              0.013591                         0.067953                      0.040772    0.244189   -0.441749     3.539133    -8.199971\n",
       "164            6                     488       38.44              8                         1                      2                   0.047131        0.078770                  0.347826      0              23.0                 1.671304                                    0.043478                                 0.086957                0.016393                           0.002049                        0.004098       12.695109              0.208117                         0.026015                      0.052029   -0.021262   -0.478686    -0.370039    -5.817025\n",
       "165            3                    1424       39.11              3                        10                      5                   0.008427        0.027465                  0.250000      0              12.0                 3.259167                                    0.833333                                 0.416667                0.002107                           0.007022                        0.003511       36.410125              0.076707                         0.255689                      0.127845    0.436242    0.282948     5.289671     6.500751\n",
       "166            3                    1518       81.03              8                         4                      2                   0.001976        0.053379                  2.666667      0               3.0                27.010000                                    1.333333                                 0.666667                0.005270                           0.002635                        0.001318       18.733802              0.098729                         0.049364                      0.024682    0.048182    0.129987    -1.545491     2.647589\n",
       "167            2                     569       32.98              4                         4                      0                   0.049209        0.057961                  0.142857      0              28.0                 1.177857                                    0.142857                                 0.000000                0.007030                           0.007030                        0.000000       17.252881              0.121286                         0.121286                      0.000000   -0.711949   -0.038300   -10.367793    -0.047320\n",
       "168            3                    1504       98.66              7                         4                      0                   0.015293        0.065598                  0.304348      0              23.0                 4.289565                                    0.173913                                 0.000000                0.004654                           0.002660                        0.000000       15.244273              0.070951                         0.040543                      0.000000   -0.531961   -0.198836    -7.749126    -1.247620\n",
       "169            3                    1059       36.28              0                         6                      4                   0.001889        0.034259                  0.000000      0               2.0                18.140000                                    3.000000                                 2.000000                0.000000                           0.005666                        0.003777       29.189636              0.000000                         0.165380                      0.110254    0.426205    0.322331     5.788334     7.497890\n",
       "170            4                      81       51.58              9                         3                      5                   0.185185        0.636790                  0.600000      0              15.0                 3.438667                                    0.200000                                 0.333333                0.111111                           0.037037                        0.061728        1.570376              0.174486                         0.058162                      0.096937    0.385382    0.181069     3.881656     1.277513\n",
       "171            4                    1235       40.55              9                         2                      5                   0.000810        0.032834                  9.000000      0               1.0                40.550000                                    2.000000                                 5.000000                0.007287                           0.001619                        0.004049       30.456227              0.221948                         0.049322                      0.123305    0.803163    0.398675     9.504715     5.486778\n",
       "172            2                     297       91.67              5                         6                      4                   0.084175        0.308653                  0.200000      0              25.0                 3.666800                                    0.240000                                 0.160000                0.016835                           0.020202                        0.013468        3.239882              0.054543                         0.065452                      0.043635    0.008181    0.334092     0.579984     4.064927\n",
       "173            6                       2       75.74              6                         1                      1                   4.000000       37.870000                  0.750000      0               8.0                 9.467500                                    0.125000                                 0.125000                3.000000                           0.500000                        0.500000        0.026406              0.079218                         0.013203                      0.013203    0.031807   -0.490288    -0.092458    -2.715019\n",
       "174            2                     576       91.74              3                         4                      3                   0.019097        0.159271                  0.272727      0              11.0                 8.340000                                    0.363636                                 0.272727                0.005208                           0.006944                        0.005208        6.278613              0.032701                         0.043601                      0.032701   -0.020109    0.329277    -2.429409     3.973566\n",
       "175            5                    1145       85.10              2                         9                      0                   0.018341        0.074323                  0.095238      0              21.0                 4.052381                                    0.428571                                 0.000000                0.001747                           0.007860                        0.000000       13.454759              0.023502                         0.105758                      0.000000   -0.228264   -0.576476    -0.325787    -8.784315\n",
       "176            5                    1138       78.70              3                         5                      0                   0.018453        0.069156                  0.142857      0              21.0                 3.747619                                    0.238095                                 0.000000                0.002636                           0.004394                        0.000000       14.459975              0.038119                         0.063532                      0.000000   -0.305047   -0.540129    -1.390865    -8.533010\n",
       "177            1                    1075       31.95              3                         8                      0                   0.021395        0.029721                  0.130435      1              23.0                 1.389130                                    0.347826                                 0.000000                0.002791                           0.007442                        0.000000       33.646322              0.093897                         0.250391                      0.000000   -0.688529    0.117228    -7.424583     1.882678\n",
       "178            1                    1382       36.76              5                         7                      1                   0.016643        0.026599                  0.217391      1              23.0                 1.598261                                    0.304348                                 0.043478                0.003618                           0.005065                        0.000724       37.595212              0.136017                         0.190424                      0.027203   -0.555546    0.217975    -7.575817     1.317277\n",
       "179            3                     876       42.68              9                         0                      2                   0.012557        0.048721                  0.818182      0              11.0                 3.880000                                    0.000000                                 0.181818                0.010274                           0.000000                        0.002283       20.524836              0.210872                         0.000000                      0.046860   -0.195174    0.108309    -5.592241    -0.922888\n",
       "180            1                     219       89.69              3                         5                      5                   0.114155        0.409543                  0.120000      0              25.0                 3.587600                                    0.200000                                 0.200000                0.013699                           0.022831                        0.022831        2.441744              0.033449                         0.055748                      0.055748    0.049084    0.605592     0.597274     4.273287\n",
       "181            5                    1439       36.09              3                         5                      5                   0.006254        0.025080                  0.333333      0               9.0                 4.010000                                    0.555556                                 0.555556                0.002085                           0.003475                        0.003475       39.872541              0.083126                         0.138543                      0.138543    0.575134    0.000733     8.829349    -2.880936\n",
       "182            2                    1818       79.15              6                         4                      0                   0.001100        0.043537                  3.000000      0               2.0                39.575000                                    2.000000                                 0.000000                0.003300                           0.002200                        0.000000       22.969046              0.075805                         0.050537                      0.000000   -0.345497    0.107747    -3.646421     2.085031\n",
       "183            1                     218       41.93              4                         7                      2                   0.096330        0.192339                  0.190476      0              21.0                 1.996667                                    0.333333                                 0.095238                0.018349                           0.032110                        0.009174        5.199141              0.095397                         0.166945                      0.047699   -0.363598    0.336916    -6.570127     5.012038\n",
       "184            5                     793       10.30              8                         5                      1                   0.020177        0.012989                  0.500000      0              16.0                 0.643750                                    0.312500                                 0.062500                0.010088                           0.006305                        0.001261       76.990291              0.776699                         0.485437                      0.097087   -0.144783   -0.397530    -2.512090    -6.279280\n",
       "185            4                    1437       92.55             11                         6                      5                   0.014614        0.064405                  0.523810      0              21.0                 4.407143                                    0.285714                                 0.238095                0.007655                           0.004175                        0.003479       15.526742              0.118855                         0.064830                      0.054025    0.380279    0.100788     4.715898     0.877072\n",
       "186            2                     542       22.40              0                         1                      5                   0.003690        0.041328                  0.000000      0               2.0                11.200000                                    0.500000                                 2.500000                0.000000                           0.001845                        0.009225       24.196429              0.000000                         0.044643                      0.223214    0.376476    0.639838     4.240830     9.109758\n",
       "187            6                    1559       68.32             11                         8                      5                   0.015394        0.043823                  0.458333      0              24.0                 2.846667                                    0.333333                                 0.208333                0.007056                           0.005131                        0.003207       22.819087              0.161007                         0.117096                      0.073185    0.556722   -0.275797     6.351814    -5.126266\n",
       "188            6                     671        0.70              4                         5                      3                   0.029806        0.001043                  0.200000      0              20.0                 0.035000                                    0.250000                                 0.150000                0.005961                           0.007452                        0.004471      958.571429              5.714286                         7.142857                      4.285714    0.213352   -0.408419     4.726093    -4.863047\n",
       "189            5                     641       79.14              1                         6                      1                   0.043682        0.123463                  0.035714      0              28.0                 2.826429                                    0.214286                                 0.035714                0.001560                           0.009360                        0.001560        8.099570              0.012636                         0.075815                      0.012636   -0.201755   -0.488956    -0.871901    -9.763773\n",
       "190            2                     277       76.34              5                        10                      0                   0.025271        0.275596                  0.714286      0               7.0                10.905714                                    1.428571                                 0.000000                0.018051                           0.036101                        0.000000        3.628504              0.065496                         0.130993                      0.000000   -0.330713    0.030319    -3.310713     2.021359\n",
       "191            5                    1719       94.59              1                         6                      3                   0.008144        0.055026                  0.071429      0              14.0                 6.756429                                    0.428571                                 0.214286                0.000582                           0.003490                        0.001745       18.173168              0.010572                         0.063432                      0.031716    0.259618   -0.241790     4.107404    -8.055572\n",
       "192            2                     249       77.28              9                         3                      4                   0.044177        0.310361                  0.818182      0              11.0                 7.025455                                    0.272727                                 0.363636                0.036145                           0.012048                        0.016064        3.222050              0.116460                         0.038820                      0.051760    0.105041    0.450405     2.992060     4.516937\n",
       "193            2                    1803        7.51              6                         2                      0                   0.006101        0.004165                  0.545455      0              11.0                 0.682727                                    0.181818                                 0.000000                0.003328                           0.001109                        0.000000      240.079893              0.798935                         0.266312                      0.000000   -0.597277    0.058014    -8.218086     0.839357\n",
       "194            5                     165       79.75              2                         7                      4                   0.036364        0.483333                  0.333333      0               6.0                13.291667                                    1.166667                                 0.666667                0.012121                           0.042424                        0.024242        2.068966              0.025078                         0.087774                      0.050157    0.552467   -0.074452     8.332582    -0.209721\n",
       "195            5                    1726        7.75              2                         5                      3                   0.004056        0.004490                  0.285714      0               7.0                 1.107143                                    0.714286                                 0.428571                0.001159                           0.002897                        0.001738      222.709677              0.258065                         0.645161                      0.387097    0.267547   -0.179935     8.991406    -3.064890\n",
       "196            2                    1767       25.97              7                         5                      1                   0.009055        0.014697                  0.437500      0              16.0                 1.623125                                    0.312500                                 0.062500                0.003962                           0.002830                        0.000566       68.040046              0.269542                         0.192530                      0.038506   -0.431857    0.100341    -7.490434    -0.109199\n",
       "197            1                     310       65.47              5                         5                      2                   0.051613        0.211194                  0.312500      0              16.0                 4.091875                                    0.312500                                 0.125000                0.016129                           0.016129                        0.006452        4.734993              0.076371                         0.076371                      0.030548   -0.329633    0.379453    -4.114715     4.655803\n",
       "198            4                    1320       77.93              4                         6                      1                   0.017424        0.059038                  0.173913      0              23.0                 3.388261                                    0.260870                                 0.043478                0.003030                           0.004545                        0.000758       16.938278              0.051328                         0.076992                      0.012832   -0.255489   -0.294544    -5.115529    -3.438505\n",
       "199            2                     796        3.76              1                         2                      0                   0.031407        0.004724                  0.040000      0              25.0                 0.150400                                    0.080000                                 0.000000                0.001256                           0.002513                        0.000000      211.702128              0.265957                         0.531915                      0.000000   -0.733890   -0.011076   -10.176246    -0.092242\n",
       "200            5                    1559       61.66              7                         5                      2                   0.003849        0.039551                  1.166667      0               6.0                10.276667                                    0.833333                                 0.333333                0.004490                           0.003207                        0.001283       25.283814              0.113526                         0.081090                      0.032436    0.168236   -0.258277     1.364899    -4.625308\n",
       "201            2                     373       28.95              5                         2                      4                   0.067024        0.077614                  0.200000      0              25.0                 1.158000                                    0.080000                                 0.160000                0.013405                           0.005362                        0.010724       12.884283              0.172712                         0.069085                      0.138169   -0.105431    0.373711    -3.324956     9.007625\n",
       "202            4                    1221       93.06              2                         2                      0                   0.010647        0.076216                  0.153846      0              13.0                 7.158462                                    0.153846                                 0.000000                0.001638                           0.001638                        0.000000       13.120567              0.021492                         0.021492                      0.000000   -0.357284   -0.304311    -4.969786    -1.734718\n",
       "203            3                     460       50.97              9                         9                      4                   0.004348        0.110804                  4.500000      0               2.0                25.485000                                    4.500000                                 2.000000                0.019565                           0.019565                        0.008696        9.024917              0.176574                         0.176574                      0.078478    0.540127    0.342768     7.439904     3.267590\n",
       "204            5                    1024       66.64              1                         3                      0                   0.008789        0.065078                  0.111111      0               9.0                 7.404444                                    0.333333                                 0.000000                0.000977                           0.002930                        0.000000       15.366146              0.015006                         0.045018                      0.000000   -0.212900   -0.458819    -1.237503    -3.121529\n",
       "205            1                    1054       75.58             11                         5                      4                   0.020873        0.071708                  0.500000      1              22.0                 3.435455                                    0.227273                                 0.181818                0.010436                           0.004744                        0.003795       13.945488              0.145541                         0.066155                      0.052924   -0.098072    0.532812    -0.760610     5.651563\n",
       "206            1                     198       49.24              1                         1                      4                   0.030303        0.248687                  0.166667      0               6.0                 8.206667                                    0.166667                                 0.666667                0.005051                           0.005051                        0.020202        4.021121              0.020309                         0.020309                      0.081235    0.028293    0.660552     0.623692     9.496644\n",
       "207            1                     524       38.78             11                         3                      3                   0.040076        0.074008                  0.523810      0              21.0                 1.846667                                    0.142857                                 0.142857                0.020992                           0.005725                        0.005725       13.512120              0.283651                         0.077359                      0.077359   -0.294928    0.473226    -5.830924     7.397348\n",
       "208            6                     172       58.21              8                         7                      5                   0.069767        0.338430                  0.666667      0              12.0                 4.850833                                    0.583333                                 0.416667                0.046512                           0.040698                        0.029070        2.954819              0.137433                         0.120254                      0.085896    0.692629   -0.181283     7.142001    -2.879942\n",
       "209            5                    1049       77.81              2                         7                      0                   0.005720        0.074175                  0.333333      0               6.0                12.968333                                    1.166667                                 0.000000                0.001907                           0.006673                        0.000000       13.481558              0.025704                         0.089963                      0.000000   -0.090362   -0.472130    -0.026553    -6.059668\n",
       "210            6                    1603       47.86              9                         9                      3                   0.000624        0.029857                  9.000000      0               1.0                47.860000                                    9.000000                                 3.000000                0.005614                           0.005614                        0.001871       33.493523              0.188048                         0.188048                      0.062683    0.821403   -0.216518     9.506143     4.860652\n",
       "211            4                    1718       43.52              3                         6                      0                   0.011641        0.025332                  0.150000      0              20.0                 2.176000                                    0.300000                                 0.000000                0.001746                           0.003492                        0.000000       39.476103              0.068934                         0.137868                      0.000000   -0.402355   -0.375994    -6.078195    -3.374632\n",
       "212            4                     813       59.43              8                         9                      2                   0.018450        0.073100                  0.533333      0              15.0                 3.962000                                    0.600000                                 0.133333                0.009840                           0.011070                        0.002460       13.679960              0.134612                         0.151439                      0.033653    0.030289   -0.164770    -2.542218    -3.789164\n",
       "213            5                    1399       61.58              5                        10                      5                   0.011437        0.044017                  0.312500      0              16.0                 3.848750                                    0.625000                                 0.312500                0.003574                           0.007148                        0.003574       22.718415              0.081195                         0.162390                      0.081195    0.592663   -0.083170     8.219877    -4.659767\n",
       "214            5                    1151       97.79              6                         8                      1                   0.014770        0.084961                  0.352941      0              17.0                 5.752353                                    0.470588                                 0.058824                0.005213                           0.006950                        0.000869       11.770120              0.061356                         0.081808                      0.010226   -0.043865   -0.446258    -0.713012    -7.624638\n",
       "215            1                     909       64.11              8                         0                      3                   0.005501        0.070528                  1.600000      0               5.0                12.822000                                    0.000000                                 0.600000                0.008801                           0.000000                        0.003300       14.178755              0.124786                         0.000000                      0.046795   -0.127199    0.586495    -2.583321     5.090178\n",
       "216            1                     704       23.16              2                         8                      3                   0.042614        0.032898                  0.066667      1              30.0                 0.772000                                    0.266667                                 0.100000                0.002841                           0.011364                        0.004261       30.397237              0.086356                         0.345423                      0.129534   -0.305809    0.364799    -4.298893     6.498619\n",
       "217            2                    1530        8.91              4                         3                      3                   0.013072        0.005824                  0.200000      0              20.0                 0.445500                                    0.150000                                 0.150000                0.002614                           0.001961                        0.001961      171.717172              0.448934                         0.336700                      0.336700   -0.210702    0.282453    -3.112764     7.916149\n",
       "218            3                      13       25.19             10                         5                      1                   1.461538        1.937692                  0.526316      0              19.0                 1.325789                                    0.263158                                 0.052632                0.769231                           0.384615                        0.076923        0.516078              0.396983                         0.198491                      0.039698   -0.353866   -0.056935    -5.119524    -1.171766\n",
       "219            1                     636       38.87              8                         0                      4                   0.028302        0.061116                  0.444444      0              18.0                 2.159444                                    0.000000                                 0.222222                0.012579                           0.000000                        0.006289       16.362233              0.205814                         0.000000                      0.102907   -0.159497    0.601737    -3.708540     7.511072\n",
       "220            6                    1434       17.25              0                         8                      0                   0.016039        0.012029                  0.000000      0              23.0                 0.750000                                    0.347826                                 0.000000                0.000000                           0.005579                        0.000000       83.130435              0.000000                         0.463768                      0.000000   -0.217776   -0.751101    -2.835485    -9.537176\n",
       "221            2                    1459       77.21              4                         1                      2                   0.017820        0.052920                  0.153846      0              26.0                 2.969615                                    0.038462                                 0.076923                0.002742                           0.000685                        0.001371       18.896516              0.051807                         0.012952                      0.025903   -0.418173    0.166812    -9.945929     1.551949\n",
       "222            5                    1123       58.90              8                         9                      1                   0.021371        0.052449                  0.333333      0              24.0                 2.454167                                    0.375000                                 0.041667                0.007124                           0.008014                        0.000890       19.066214              0.135823                         0.152801                      0.016978   -0.132056   -0.484805    -1.851567    -7.518911\n",
       "223            6                    1100       26.82              8                         0                      2                   0.025455        0.024382                  0.285714      0              28.0                 0.957857                                    0.000000                                 0.071429                0.007273                           0.000000                        0.001818       41.014169              0.298285                         0.000000                      0.074571   -0.107010   -0.504705     1.657752    -5.830951\n",
       "224            4                     352       21.69             10                         7                      0                   0.019886        0.061619                  1.428571      0               7.0                 3.098571                                    1.000000                                 0.000000                0.028409                           0.019886                        0.000000       16.228677              0.461042                         0.322729                      0.000000   -0.239579   -0.274911    -3.141572    -3.382677\n",
       "225            1                     473       15.14             11                         1                      0                   0.054968        0.032008                  0.423077      1              26.0                 0.582308                                    0.038462                                 0.000000                0.023256                           0.002114                        0.000000       31.241744              0.726552                         0.066050                      0.000000   -0.859299    0.185621    -9.536509     2.686756\n",
       "226            2                    1597       11.14              2                         5                      5                   0.013776        0.006976                  0.090909      0              22.0                 0.506364                                    0.227273                                 0.227273                0.001252                           0.003131                        0.003131      143.357271              0.179533                         0.448833                      0.448833    0.112596    0.437069     1.333900     4.482952\n",
       "227            1                      91        0.26              8                         6                      4                   0.307692        0.002857                  0.285714      1              28.0                 0.009286                                    0.214286                                 0.142857                0.087912                           0.065934                        0.043956      350.000000             30.769231                        23.076923                     15.384615   -0.182738    0.508154    -2.868293     8.314009\n",
       "228            4                    1821       91.48              7                        10                      4                   0.008786        0.050236                  0.437500      0              16.0                 5.717500                                    0.625000                                 0.250000                0.003844                           0.005491                        0.002197       19.905990              0.076519                         0.109314                      0.043725    0.356692   -0.010687     5.215620    -0.310604\n",
       "229            5                     709       22.50              9                         8                      0                   0.028209        0.031735                  0.450000      0              20.0                 1.125000                                    0.400000                                 0.000000                0.012694                           0.011283                        0.000000       31.511111              0.400000                         0.355556                      0.000000   -0.280513   -0.536580    -3.334269    -5.846305\n",
       "230            1                    1537       38.44              5                         6                      1                   0.017567        0.025010                  0.185185      1              27.0                 1.423704                                    0.222222                                 0.037037                0.003253                           0.003904                        0.000651       39.984391              0.130073                         0.156087                      0.026015   -0.616972    0.202555    -7.781018     1.246108\n",
       "231            3                     691       33.87              9                         5                      1                   0.030391        0.049016                  0.428571      0              21.0                 1.612857                                    0.238095                                 0.047619                0.013025                           0.007236                        0.001447       20.401535              0.265722                         0.147623                      0.029525   -0.376250   -0.080296    -5.004246    -3.841211\n",
       "232            2                    1698        7.59              6                         7                      5                   0.011190        0.004470                  0.315789      0              19.0                 0.399474                                    0.368421                                 0.263158                0.003534                           0.004122                        0.002945      223.715415              0.790514                         0.922266                      0.658762    0.174091    0.443350     0.478423     7.394534\n",
       "233            6                    1698       32.22              4                         3                      3                   0.000589        0.018975                  4.000000      0               1.0                32.220000                                    3.000000                                 3.000000                0.002356                           0.001767                        0.001767       52.700186              0.124146                         0.093110                      0.093110    0.591725   -0.215112    10.255687    -0.400055\n",
       "234            3                     171       21.51              1                         3                      5                   0.099415        0.125789                  0.058824      0              17.0                 1.265294                                    0.176471                                 0.294118                0.005848                           0.017544                        0.029240        7.949791              0.046490                         0.139470                      0.232450    0.252141    0.327714     1.821976     2.098419\n",
       "235            4                     216       77.45              3                         6                      3                   0.083333        0.358565                  0.166667      0              18.0                 4.302778                                    0.333333                                 0.166667                0.013889                           0.027778                        0.013889        2.788896              0.038735                         0.077469                      0.038735    0.119111   -0.065458     1.690947    -0.484340\n",
       "236            5                    1026       24.44              3                         3                      0                   0.022417        0.023821                  0.130435      0              23.0                 1.062609                                    0.130435                                 0.000000                0.002924                           0.002924                        0.000000       41.980360              0.122750                         0.122750                      0.000000   -0.397359   -0.526416    -5.632982    -8.024721\n",
       "237            2                    1660       13.69              1                         3                      2                   0.012651        0.008247                  0.047619      0              21.0                 0.651905                                    0.142857                                 0.095238                0.000602                           0.001807                        0.001205      121.256392              0.073046                         0.219138                      0.146092   -0.369733    0.175326    -6.692914     6.302953\n",
       "238            4                     123        6.72              4                         9                      4                   0.235772        0.054634                  0.137931      0              29.0                 0.231724                                    0.310345                                 0.137931                0.032520                           0.073171                        0.032520       18.303571              0.595238                         1.339286                      0.595238    0.156864   -0.046521     0.858162     0.297015\n",
       "239            5                     635       52.23              9                         0                      5                   0.045669        0.082252                  0.310345      0              29.0                 1.801034                                    0.000000                                 0.172414                0.014173                           0.000000                        0.007874       12.157764              0.172315                         0.000000                      0.095730    0.264877   -0.052284     3.227093    -3.775783\n",
       "240            4                     942       90.29              7                         1                      5                   0.018047        0.095849                  0.411765      0              17.0                 5.311176                                    0.058824                                 0.294118                0.007431                           0.001062                        0.005308       10.433049              0.077528                         0.011075                      0.055377    0.345028    0.165763     3.332519    -0.751171\n",
       "241            4                     581       87.17              1                         3                      1                   0.032702        0.150034                  0.052632      0              19.0                 4.587895                                    0.157895                                 0.052632                0.001721                           0.005164                        0.001721        6.665137              0.011472                         0.034416                      0.011472   -0.248055   -0.243492    -7.507785    -4.939148\n",
       "242            1                     439       63.23             10                         3                      2                   0.018223        0.144032                  1.250000      0               8.0                 7.903750                                    0.375000                                 0.250000                0.022779                           0.006834                        0.004556        6.942907              0.158153                         0.047446                      0.031631   -0.273864    0.453134    -3.315823     5.038301\n",
       "243            5                    1469       91.79              1                         8                      3                   0.014295        0.062485                  0.047619      0              21.0                 4.370952                                    0.380952                                 0.142857                0.000681                           0.005446                        0.002042       16.003922              0.010894                         0.087155                      0.032683    0.215929   -0.294256     4.382703    -8.236549\n",
       "244            1                     511       28.39             10                         5                      2                   0.023483        0.055558                  0.833333      0              12.0                 2.365833                                    0.416667                                 0.166667                0.019569                           0.009785                        0.003914       17.999296              0.352237                         0.176118                      0.070447   -0.315268    0.413079    -4.469857     4.931880\n",
       "245            6                    1796       10.77              1                         2                      4                   0.005011        0.005997                  0.111111      0               9.0                 1.196667                                    0.222222                                 0.444444                0.000557                           0.001114                        0.002227      166.759517              0.092851                         0.185701                      0.371402    0.438665   -0.248685     4.155362    -4.729152\n",
       "246            3                     440       49.34              3                         5                      5                   0.011364        0.112136                  0.600000      0               5.0                 9.868000                                    1.000000                                 1.000000                0.006818                           0.011364                        0.011364        8.917714              0.060803                         0.101338                      0.101338    0.473912    0.392202     4.476445     8.122116\n",
       "247            4                     467       94.13              3                         9                      4                   0.040685        0.201563                  0.157895      0              19.0                 4.954211                                    0.473684                                 0.210526                0.006424                           0.019272                        0.008565        4.961224              0.031871                         0.095612                      0.042494    0.323660   -0.007882     3.609606     1.583378\n",
       "248            2                     365       20.05              8                        10                      2                   0.035616        0.054932                  0.615385      0              13.0                 1.542308                                    0.769231                                 0.153846                0.021918                           0.027397                        0.005479       18.204489              0.399002                         0.498753                      0.099751   -0.142716    0.192607    -1.526207     4.352262\n",
       "249            5                    1720       86.84              4                         1                      3                   0.009884        0.050488                  0.235294      0              17.0                 5.108235                                    0.058824                                 0.176471                0.002326                           0.000581                        0.001744       19.806541              0.046062                         0.011515                      0.034546    0.126261   -0.210574     2.332018    -7.445746\n",
       "...          ...                     ...         ...            ...                       ...                    ...                        ...             ...                       ...    ...               ...                      ...                                         ...                                      ...                     ...                                ...                             ...             ...                   ...                              ...                           ...         ...         ...          ...          ...\n",
       "1629           1                     612       31.64              0                         7                      4                   0.013072        0.051699                  0.000000      0               8.0                 3.955000                                    0.875000                                 0.500000                0.000000                           0.011438                        0.006536       19.342604              0.000000                         0.221239                      0.126422    0.093240    0.589500     2.694578     7.484076\n",
       "1630           3                     790       84.05              4                         6                      0                   0.024051        0.106392                  0.210526      0              19.0                 4.423684                                    0.315789                                 0.000000                0.005063                           0.007595                        0.000000        9.399167              0.047591                         0.071386                      0.000000   -0.451531   -0.187747    -5.593681    -4.102057\n",
       "1631           5                      33       65.62              5                         1                      5                   0.030303        1.988485                  5.000000      0               1.0                65.620000                                    1.000000                                 5.000000                0.151515                           0.030303                        0.151515        0.502895              0.076196                         0.015239                      0.076196    0.898172    0.234001    10.107505     4.188853\n",
       "1632           3                    1740       46.09              3                         8                      1                   0.009770        0.026489                  0.176471      0              17.0                 2.711176                                    0.470588                                 0.058824                0.001724                           0.004598                        0.000575       37.752224              0.065090                         0.173573                      0.021697   -0.274702   -0.111477    -5.332667    -2.619901\n",
       "1633           2                    1023       73.78              2                         3                      4                   0.002933        0.072121                  0.666667      0               3.0                24.593333                                    1.000000                                 1.333333                0.001955                           0.002933                        0.003910       13.865546              0.027108                         0.040661                      0.054215    0.251395    0.498596     3.721334     7.331653\n",
       "1634           4                    1826       79.52              9                         8                      2                   0.010953        0.043549                  0.450000      0              20.0                 3.976000                                    0.400000                                 0.100000                0.004929                           0.004381                        0.001095       22.962777              0.113179                         0.100604                      0.025151   -0.043263   -0.199545     2.167970    -4.469305\n",
       "1635           3                    1422        6.21              8                         7                      3                   0.001406        0.004367                  4.000000      0               2.0                 3.105000                                    3.500000                                 1.500000                0.005626                           0.004923                        0.002110      228.985507              1.288245                         1.127214                      0.483092    0.260491    0.233444     6.937700     4.085793\n",
       "1636           6                    1200       19.99              7                         9                      4                   0.007500        0.016658                  0.777778      0               9.0                 2.221111                                    1.000000                                 0.444444                0.005833                           0.007500                        0.003333       60.030015              0.350175                         0.450225                      0.200100    0.578059   -0.285894     8.988087    -1.957669\n",
       "1637           1                     808       11.71             10                         4                      2                   0.014851        0.014493                  0.833333      0              12.0                 0.975833                                    0.333333                                 0.166667                0.012376                           0.004950                        0.002475       69.000854              0.853971                         0.341588                      0.170794   -0.348468    0.418668    -4.554185     5.093735\n",
       "1638           2                     410       62.06              9                         4                      5                   0.024390        0.151366                  0.900000      0              10.0                 6.206000                                    0.400000                                 0.500000                0.021951                           0.009756                        0.012195        6.606510              0.145021                         0.064454                      0.080567    0.279669    0.542635     3.313810     4.692804\n",
       "1639           5                    1413       28.11              0                         4                      2                   0.008493        0.019894                  0.000000      0              12.0                 2.342500                                    0.333333                                 0.166667                0.000000                           0.002831                        0.001415       50.266809              0.000000                         0.142298                      0.071149    0.049803   -0.298965    -0.488760    -3.202621\n",
       "1640           6                     421       21.09              8                         7                      4                   0.047506        0.050095                  0.400000      0              20.0                 1.054500                                    0.350000                                 0.200000                0.019002                           0.016627                        0.009501       19.962067              0.379327                         0.331911                      0.189663    0.414502   -0.322570     6.540448    -4.044611\n",
       "1641           6                    1060       99.75              8                         2                      1                   0.014151        0.094104                  0.533333      0              15.0                 6.650000                                    0.133333                                 0.066667                0.007547                           0.001887                        0.000943       10.626566              0.080201                         0.020050                      0.010025   -0.032633   -0.551605    -0.728704    -4.917994\n",
       "1642           5                      11       79.66              1                         5                      4                   2.181818        7.241818                  0.041667      0              24.0                 3.319167                                    0.208333                                 0.166667                0.090909                           0.454545                        0.363636        0.138087              0.012553                         0.062767                      0.050213    0.290346   -0.169694     2.683262    -3.263415\n",
       "1643           3                     448       65.18              2                         4                      5                   0.037946        0.145491                  0.117647      0              17.0                 3.834118                                    0.235294                                 0.294118                0.004464                           0.008929                        0.011161        6.873274              0.030684                         0.061369                      0.076711    0.296002    0.312681     2.349315     0.667151\n",
       "1644           5                    1814        8.37              8                         6                      0                   0.002205        0.004614                  2.000000      0               4.0                 2.092500                                    1.500000                                 0.000000                0.004410                           0.003308                        0.000000      216.726404              0.955795                         0.716846                      0.000000   -0.140908   -0.442109    -0.201772    -5.778431\n",
       "1645           5                    1184       88.05              6                         8                      5                   0.014358        0.074367                  0.352941      0              17.0                 5.179412                                    0.470588                                 0.294118                0.005068                           0.006757                        0.004223       13.446905              0.068143                         0.090857                      0.056786    0.564043   -0.070000     7.835642    -1.934593\n",
       "1646           6                    1704       94.06              6                         6                      2                   0.004695        0.055200                  0.750000      0               8.0                11.757500                                    0.750000                                 0.250000                0.003521                           0.003521                        0.001174       18.116096              0.063789                         0.063789                      0.021263    0.274938   -0.460068     2.973524    -5.713658\n",
       "1647           6                    1488       41.73              3                         9                      1                   0.008065        0.028044                  0.250000      0              12.0                 3.477500                                    0.750000                                 0.083333                0.002016                           0.006048                        0.000672       35.657800              0.071891                         0.215672                      0.023964    0.088933   -0.603257    -0.054480    -7.985208\n",
       "1648           3                     527       80.08             11                         5                      5                   0.030361        0.151954                  0.687500      0              16.0                 5.005000                                    0.312500                                 0.312500                0.020873                           0.009488                        0.009488        6.580919              0.137363                         0.062438                      0.062438    0.326105    0.324666     3.591532     2.032002\n",
       "1649           3                    1116       24.18              6                         7                      0                   0.013441        0.021667                  0.400000      0              15.0                 1.612000                                    0.466667                                 0.000000                0.005376                           0.006272                        0.000000       46.153846              0.248139                         0.289495                      0.000000   -0.435748   -0.169103    -4.761547    -1.645827\n",
       "1650           3                     245       21.93              5                         5                      4                   0.016327        0.089510                  1.250000      0               4.0                 5.482500                                    1.250000                                 1.000000                0.020408                           0.020408                        0.016327       11.171911              0.227998                         0.227998                      0.182399    0.318574    0.315980     2.291291     7.499232\n",
       "1651           1                    1814       91.08              4                         5                      0                   0.000551        0.050209                  4.000000      0               1.0                91.080000                                    5.000000                                 0.000000                0.002205                           0.002756                        0.000000       19.916557              0.043917                         0.054897                      0.000000   -0.311164    0.302855     7.852192     4.638669\n",
       "1652           4                    1480       65.67              2                         7                      5                   0.020270        0.044372                  0.066667      0              30.0                 2.189000                                    0.233333                                 0.166667                0.001351                           0.004730                        0.003378       22.536927              0.030455                         0.106594                      0.076138    0.290276    0.028462     3.937660     0.784167\n",
       "1653           5                    1273       19.48              1                         2                      3                   0.019639        0.015302                  0.040000      0              25.0                 0.779200                                    0.080000                                 0.120000                0.000786                           0.001571                        0.002357       65.349076              0.051335                         0.102669                      0.154004    0.019036   -0.254663     2.987555    -5.197160\n",
       "1654           5                    1232       47.15              0                         1                      4                   0.001623        0.038271                  0.000000      0               2.0                23.575000                                    0.500000                                 2.000000                0.000000                           0.000812                        0.003247       26.129374              0.000000                         0.021209                      0.084836    0.514267    0.012343     5.162522    -2.809939\n",
       "1655           3                      19       20.01              7                         8                      4                   0.052632        1.053158                  7.000000      0               1.0                20.010000                                    8.000000                                 4.000000                0.368421                           0.421053                        0.210526        0.949525              0.349825                         0.399800                      0.199900    0.654406    0.424095     9.175161     5.486211\n",
       "1656           4                     919       58.56              7                         4                      0                   0.013058        0.063721                  0.583333      0              12.0                 4.880000                                    0.333333                                 0.000000                0.007617                           0.004353                        0.000000       15.693306              0.119536                         0.068306                      0.000000   -0.334835   -0.297790    -3.726753    -3.410507\n",
       "1657           5                    1523       18.77              6                         2                      4                   0.002626        0.012324                  1.500000      0               4.0                 4.692500                                    0.500000                                 1.000000                0.003940                           0.001313                        0.002626       81.140117              0.319659                         0.106553                      0.213106    0.434795   -0.019990     4.513860    -2.833282\n",
       "1658           6                    1307       75.25              7                         6                      5                   0.012242        0.057575                  0.437500      0              16.0                 4.703125                                    0.375000                                 0.312500                0.005356                           0.004591                        0.003826       17.368771              0.093023                         0.079734                      0.066445    0.625110   -0.217714     7.113457    -1.908023\n",
       "1659           6                     428        4.57             10                         9                      1                   0.044393        0.010678                  0.526316      0              19.0                 0.240526                                    0.473684                                 0.052632                0.023364                           0.021028                        0.002336       93.654267              2.188184                         1.969365                      0.218818   -0.012221   -0.609770    -3.060755    -5.844836\n",
       "1660           4                    1082       79.13             11                         3                      3                   0.024954        0.073133                  0.407407      0              27.0                 2.930741                                    0.111111                                 0.111111                0.010166                           0.002773                        0.002773       13.673702              0.139012                         0.037912                      0.037912   -0.051370   -0.087693     1.838761    -3.320831\n",
       "1661           4                     438       90.43              2                        10                      5                   0.009132        0.206461                  0.500000      0               4.0                22.607500                                    2.500000                                 1.250000                0.004566                           0.022831                        0.011416        4.843525              0.022117                         0.110583                      0.055291    0.732811    0.190003     9.023623     0.444452\n",
       "1662           5                    1014       50.31              7                         6                      0                   0.020710        0.049615                  0.333333      0              21.0                 2.395714                                    0.285714                                 0.000000                0.006903                           0.005917                        0.000000       20.155039              0.139137                         0.119261                      0.000000   -0.309435   -0.536263    -3.373116    -6.928945\n",
       "1663           2                    1117       80.84              5                         1                      3                   0.013429        0.072372                  0.333333      0              15.0                 5.389333                                    0.066667                                 0.200000                0.004476                           0.000895                        0.002686       13.817417              0.061851                         0.012370                      0.037110   -0.138141    0.327604    -2.331820     4.710353\n",
       "1664           4                    1075       69.73              8                         6                      2                   0.003721        0.064865                  2.000000      0               4.0                17.432500                                    1.500000                                 0.500000                0.007442                           0.005581                        0.001860       15.416607              0.114728                         0.086046                      0.028682    0.146714   -0.065524     6.437269     1.858359\n",
       "1665           5                      90       87.40              7                         2                      4                   0.088889        0.971111                  0.875000      0               8.0                10.925000                                    0.250000                                 0.500000                0.077778                           0.022222                        0.044444        1.029748              0.080092                         0.022883                      0.045767    0.428170   -0.038662     5.483471    -0.062813\n",
       "1666           3                    1219       11.24             11                         6                      0                   0.002461        0.009221                  3.666667      0               3.0                 3.746667                                    2.000000                                 0.000000                0.009024                           0.004922                        0.000000      108.451957              0.978648                         0.533808                      0.000000   -0.298697   -0.071482    -3.835855    -1.408294\n",
       "1667           4                     944       28.13              8                        10                      4                   0.011653        0.029799                  0.727273      0              11.0                 2.557273                                    0.909091                                 0.363636                0.008475                           0.010593                        0.004237       33.558478              0.284394                         0.355492                      0.142197    0.384086    0.041047     5.938570     1.502447\n",
       "1668           2                     522        6.78              4                         3                      4                   0.032567        0.012989                  0.235294      0              17.0                 0.398824                                    0.176471                                 0.235294                0.007663                           0.005747                        0.007663       76.991150              0.589971                         0.442478                      0.589971   -0.014646    0.407759    -2.567194     9.260552\n",
       "1669           4                    1365       37.49              5                         3                      4                   0.002930        0.027465                  1.250000      0               4.0                 9.372500                                    0.750000                                 1.000000                0.003663                           0.002198                        0.002930       36.409709              0.133369                         0.080021                      0.106695    0.376222    0.143048     6.113767     4.355253\n",
       "1670           5                     678       69.69             10                         1                      3                   0.044248        0.102788                  0.333333      0              30.0                 2.323000                                    0.033333                                 0.100000                0.014749                           0.001475                        0.004425        9.728799              0.143493                         0.014349                      0.043048   -0.023908   -0.253735     2.347776    -2.813657\n",
       "1671           3                      92       94.87              6                         5                      5                   0.043478        1.031196                  1.500000      0               4.0                23.717500                                    1.250000                                 1.250000                0.065217                           0.054348                        0.054348        0.969748              0.063244                         0.052704                      0.052704    0.545591    0.416393     3.399644     5.830930\n",
       "1672           6                     985       39.84              3                         7                      5                   0.013198        0.040447                  0.230769      0              13.0                 3.064615                                    0.538462                                 0.384615                0.003046                           0.007107                        0.005076       24.723896              0.075301                         0.175703                      0.125502    0.662522   -0.207532     8.540980    -4.596549\n",
       "1673           3                     140       96.15              7                         4                      0                   0.064286        0.686786                  0.777778      0               9.0                10.683333                                    0.444444                                 0.000000                0.050000                           0.028571                        0.000000        1.456058              0.072803                         0.041602                      0.000000   -0.359305   -0.100475    -2.731541     0.224744\n",
       "1674           5                     282       98.15              1                         6                      3                   0.099291        0.348050                  0.035714      0              28.0                 3.505357                                    0.214286                                 0.107143                0.003546                           0.021277                        0.010638        2.873153              0.010188                         0.061131                      0.030565    0.120248   -0.299016    -0.334932    -9.737473\n",
       "1675           4                     551       32.02              0                         4                      0                   0.014519        0.058113                  0.000000      0               8.0                 4.002500                                    0.500000                                 0.000000                0.000000                           0.007260                        0.000000       17.207995              0.000000                         0.124922                      0.000000   -0.298808   -0.281976    -2.094450    -2.468750\n",
       "1676           1                    1265       14.80              5                         4                      2                   0.006324        0.011700                  0.625000      0               8.0                 1.850000                                    0.500000                                 0.250000                0.003953                           0.003162                        0.001581       85.472973              0.337838                         0.270270                      0.135135   -0.297617    0.426025    -5.340984     3.976819\n",
       "1677           3                    1396       41.60              0                        10                      0                   0.005014        0.029799                  0.000000      0               7.0                 5.942857                                    1.428571                                 0.000000                0.000000                           0.007163                        0.000000       33.557692              0.000000                         0.240385                      0.000000   -0.271186   -0.166324    -3.440316    -0.056333\n",
       "1678           3                    1229       58.32              6                        10                      5                   0.022783        0.047453                  0.214286      0              28.0                 2.082857                                    0.357143                                 0.178571                0.004882                           0.008137                        0.004068       21.073388              0.102881                         0.171468                      0.085734    0.262022    0.197504     0.666392     5.269806\n",
       "1679           4                    1484       92.75             11                         2                      5                   0.011456        0.062500                  0.647059      0              17.0                 5.455882                                    0.117647                                 0.294118                0.007412                           0.001348                        0.003369       16.000000              0.118598                         0.021563                      0.053908    0.354856    0.156861     3.885722    -1.148442\n",
       "1680           5                     599       24.54              2                         6                      2                   0.025042        0.040968                  0.133333      0              15.0                 1.636000                                    0.400000                                 0.133333                0.003339                           0.010017                        0.003339       24.409128              0.081500                         0.244499                      0.081500    0.056194   -0.316474     1.360068    -9.491315\n",
       "1681           3                     375       91.15              6                         4                      2                   0.064000        0.243067                  0.250000      0              24.0                 3.797917                                    0.166667                                 0.083333                0.016000                           0.010667                        0.005333        4.114098              0.065826                         0.043884                      0.021942   -0.228598   -0.001727    -1.285422     2.696755\n",
       "1682           4                     405       97.38              7                         4                      4                   0.049383        0.240444                  0.350000      0              20.0                 4.869000                                    0.200000                                 0.200000                0.017284                           0.009877                        0.009877        4.158965              0.071883                         0.041076                      0.041076    0.221224    0.036573     3.218581     0.541695\n",
       "1683           3                    1774       49.31              4                        10                      4                   0.010147        0.027796                  0.222222      0              18.0                 2.739444                                    0.555556                                 0.222222                0.002255                           0.005637                        0.002255       35.976475              0.081119                         0.202799                      0.081119    0.211643    0.148886     5.147760     6.256430\n",
       "1684           1                    1054       35.18              1                         3                      3                   0.000949        0.033378                  1.000000      0               1.0                35.180000                                    3.000000                                 3.000000                0.000949                           0.002846                        0.002846       29.960205              0.028425                         0.085276                      0.085276    0.102948    0.637685     7.813169     6.737518\n",
       "1685           3                     176       88.98              5                        10                      2                   0.034091        0.505568                  0.833333      0               6.0                14.830000                                    1.666667                                 0.333333                0.028409                           0.056818                        0.011364        1.977973              0.056192                         0.112385                      0.022477    0.108378    0.058673    -0.012084     1.149347\n",
       "1686           3                    1123       16.11              3                         2                      3                   0.017809        0.014346                  0.150000      0              20.0                 0.805500                                    0.100000                                 0.150000                0.002671                           0.001781                        0.002671       69.708256              0.186220                         0.124146                      0.186220   -0.122149    0.122300     0.126139    -1.472461\n",
       "1687           2                    1793        2.33             10                         5                      1                   0.011154        0.001299                  0.500000      0              20.0                 0.116500                                    0.250000                                 0.050000                0.005577                           0.002789                        0.000558      769.527897              4.291845                         2.145923                      0.429185   -0.495498    0.086217    -9.103867    -1.658163\n",
       "1688           4                    1683       74.66              8                         7                      3                   0.005348        0.044361                  0.888889      0               9.0                 8.295556                                    0.777778                                 0.333333                0.004753                           0.004159                        0.001783       22.542191              0.107152                         0.093758                      0.040182    0.227220   -0.030307     5.779971     0.279971\n",
       "1689           2                    1649       55.81              1                        10                      0                   0.005458        0.033845                  0.111111      0               9.0                 6.201111                                    1.111111                                 0.000000                0.000606                           0.006064                        0.000000       29.546676              0.017918                         0.179179                      0.000000   -0.386021   -0.009137    -3.585081     0.133017\n",
       "1690           3                    1315       81.66              8                         0                      3                   0.001521        0.062099                  4.000000      0               2.0                40.830000                                    0.000000                                 1.500000                0.006084                           0.000000                        0.002281       16.103355              0.097967                         0.000000                      0.036738    0.185445    0.289187     4.488277     4.959719\n",
       "1691           2                     681        0.61              3                         8                      2                   0.026432        0.000896                  0.166667      0              18.0                 0.033889                                    0.444444                                 0.111111                0.004405                           0.011747                        0.002937     1116.393443              4.918033                        13.114754                      3.278689   -0.248151    0.168841    -5.767237     2.133558\n",
       "1692           2                    1210       25.72              4                         3                      3                   0.000826        0.021256                  4.000000      0               1.0                25.720000                                    3.000000                                 3.000000                0.003306                           0.002479                        0.002479       47.045101              0.155521                         0.116641                      0.116641    0.201686    0.477755     8.090147     6.503971\n",
       "1693           5                     713       50.15              4                         8                      3                   0.035063        0.070337                  0.160000      0              25.0                 2.006000                                    0.320000                                 0.120000                0.005610                           0.011220                        0.004208       14.217348              0.079761                         0.159521                      0.059821    0.148454   -0.295116     6.105335    -6.789245\n",
       "1694           3                     763       62.93             11                         4                      0                   0.039318        0.082477                  0.366667      0              30.0                 2.097667                                    0.133333                                 0.000000                0.014417                           0.005242                        0.000000       12.124583              0.174797                         0.063563                      0.000000   -0.627929   -0.214274    -7.089641    -2.950620\n",
       "1695           1                    1709       34.83              8                         0                      0                   0.002926        0.020380                  1.600000      0               5.0                 6.966000                                    0.000000                                 0.000000                0.004681                           0.000000                        0.000000       49.066896              0.229687                         0.000000                      0.000000   -0.637606    0.285515    -8.141423     1.247737\n",
       "1696           5                    1631       82.26              1                         7                      1                   0.009197        0.050435                  0.066667      0              15.0                 5.484000                                    0.466667                                 0.066667                0.000613                           0.004292                        0.000613       19.827377              0.012157                         0.085096                      0.012157   -0.049818   -0.441655     0.105124    -8.400446\n",
       "1697           1                     673       77.29              9                         8                      1                   0.037147        0.114844                  0.360000      1              25.0                 3.091600                                    0.320000                                 0.040000                0.013373                           0.011887                        0.001486        8.707465              0.116445                         0.103506                      0.012938   -0.529674    0.211917    -6.095780     4.164765\n",
       "1698           3                     404       44.62              4                         5                      3                   0.029703        0.110446                  0.333333      0              12.0                 3.718333                                    0.416667                                 0.250000                0.009901                           0.012376                        0.007426        9.054236              0.089646                         0.112057                      0.067234    0.049405    0.151905     1.999092     2.113326\n",
       "1699           3                     141       84.92              5                         0                      3                   0.078014        0.602270                  0.454545      0              11.0                 7.720000                                    0.000000                                 0.272727                0.035461                           0.000000                        0.021277        1.660386              0.058879                         0.000000                      0.035327    0.000909    0.201598     0.977812     2.225179\n",
       "1700           1                     298       14.91              5                         8                      5                   0.067114        0.050034                  0.250000      0              20.0                 0.745500                                    0.400000                                 0.250000                0.016779                           0.026846                        0.016779       19.986586              0.335345                         0.536553                      0.335345    0.105279    0.618791     0.094667     7.841442\n",
       "1701           3                     533       32.81              2                         0                      1                   0.015009        0.061557                  0.250000      0               8.0                 4.101250                                    0.000000                                 0.125000                0.003752                           0.000000                        0.001876       16.245047              0.060957                         0.000000                      0.030479   -0.313776    0.022524    -2.265918    -1.902734\n",
       "1702           4                     823       90.65              1                         5                      3                   0.006075        0.110146                  0.200000      0               5.0                18.130000                                    1.000000                                 0.600000                0.001215                           0.006075                        0.003645        9.078875              0.011031                         0.055157                      0.033094    0.281227    0.013861     1.309526    -0.504359\n",
       "1703           3                     933       30.73              1                         9                      5                   0.008574        0.032937                  0.125000      0               8.0                 3.841250                                    1.125000                                 0.625000                0.001072                           0.009646                        0.005359       30.361211              0.032541                         0.292873                      0.162707    0.474822    0.322344     5.168962     7.255159\n",
       "1704           4                    1220       93.10              7                         0                      0                   0.001639        0.076311                  3.500000      0               2.0                46.550000                                    0.000000                                 0.000000                0.005738                           0.000000                        0.000000       13.104189              0.075188                         0.000000                      0.000000   -0.220437   -0.194409    -1.635763    -0.554316\n",
       "1705           1                    1315       89.78              5                         3                      1                   0.002281        0.068274                  1.666667      0               3.0                29.926667                                    1.000000                                 0.333333                0.003802                           0.002281                        0.000760       14.646915              0.055692                         0.033415                      0.011138   -0.322789    0.375512    -3.618550     3.436115\n",
       "1706           1                    1236       67.97              7                         4                      2                   0.011327        0.054992                  0.500000      0              14.0                 4.855000                                    0.285714                                 0.142857                0.005663                           0.003236                        0.001618       18.184493              0.102987                         0.058849                      0.029425   -0.334576    0.389413    -5.198931     1.490263\n",
       "1707           4                     482       93.10              3                         1                      1                   0.014523        0.193154                  0.428571      0               7.0                13.300000                                    0.142857                                 0.142857                0.006224                           0.002075                        0.002075        5.177229              0.032223                         0.010741                      0.010741   -0.140254   -0.152917    -0.749149    -1.919194\n",
       "1708           3                     558       65.51              2                         7                      2                   0.007168        0.117401                  0.500000      0               4.0                16.377500                                    1.750000                                 0.500000                0.003584                           0.012545                        0.003584        8.517784              0.030530                         0.106854                      0.030530    0.069466    0.090338    -0.280058    -0.181070\n",
       "1709           4                     179       30.19              3                         5                      2                   0.061453        0.168659                  0.272727      0              11.0                 2.744545                                    0.454545                                 0.181818                0.016760                           0.027933                        0.011173        5.929116              0.099371                         0.165618                      0.066247   -0.004192   -0.105917     2.004466    -2.600361\n",
       "1710           5                    1692       73.74              1                         2                      2                   0.005319        0.043582                  0.111111      0               9.0                 8.193333                                    0.222222                                 0.222222                0.000591                           0.001182                        0.001182       22.945484              0.013561                         0.027122                      0.027122    0.078270   -0.270758     1.406152    -6.989536\n",
       "1711           3                     474       32.30              9                         7                      3                   0.037975        0.068143                  0.500000      0              18.0                 1.794444                                    0.388889                                 0.166667                0.018987                           0.014768                        0.006329       14.674923              0.278638                         0.216718                      0.092879    0.001098    0.110314     1.911248     2.116036\n",
       "1712           2                     456       88.51             10                         6                      0                   0.002193        0.194101                 10.000000      0               1.0                88.510000                                    6.000000                                 0.000000                0.021930                           0.013158                        0.000000        5.151960              0.112982                         0.067789                      0.000000   -0.137395    0.177337     8.413266     4.778818\n",
       "1713           4                     474       86.63              9                         8                      1                   0.056962        0.182764                  0.333333      0              27.0                 3.208519                                    0.296296                                 0.037037                0.018987                           0.016878                        0.002110        5.471546              0.103890                         0.092347                      0.011543   -0.254610   -0.312557    -3.640046    -5.364482\n",
       "1714           3                    1478       68.55              5                         6                      0                   0.016238        0.046380                  0.208333      0              24.0                 2.856250                                    0.250000                                 0.000000                0.003383                           0.004060                        0.000000       21.560904              0.072939                         0.087527                      0.000000   -0.524678   -0.221083    -5.931244    -2.463631\n",
       "1715           1                       2       34.07              5                         9                      4                   0.500000       17.035000                  5.000000      0               1.0                34.070000                                    9.000000                                 4.000000                2.500000                           4.500000                        2.000000        0.058703              0.146757                         0.264162                      0.117405    0.503238    0.754483     9.038996     5.709252\n",
       "1716           4                    1210       16.35              9                        10                      3                   0.012397        0.013512                  0.600000      0              15.0                 1.090000                                    0.666667                                 0.200000                0.007438                           0.008264                        0.002479       74.006116              0.550459                         0.611621                      0.183486    0.167466   -0.078530    -0.076543     0.346947\n",
       "1717           3                     559       52.69              3                         9                      0                   0.023256        0.094258                  0.230769      0              13.0                 4.053077                                    0.692308                                 0.000000                0.005367                           0.016100                        0.000000       10.609224              0.056937                         0.170810                      0.000000   -0.348352   -0.175365    -3.775267     1.614201\n",
       "1718           1                     667       26.44             10                         7                      4                   0.001499        0.039640                 10.000000      0               1.0                26.440000                                    7.000000                                 4.000000                0.014993                           0.010495                        0.005997       25.226929              0.378215                         0.264750                      0.151286    0.456170    0.782043     9.148281     5.458436\n",
       "1719           2                     303       88.23             11                         5                      1                   0.029703        0.291188                  1.222222      0               9.0                 9.803333                                    0.555556                                 0.111111                0.036304                           0.016502                        0.003300        3.434206              0.124674                         0.056670                      0.011334   -0.291136    0.164908    -2.465115     2.159211\n",
       "1720           6                    1450       61.94              3                         7                      2                   0.016552        0.042717                  0.125000      0              24.0                 2.580833                                    0.291667                                 0.083333                0.002069                           0.004828                        0.001379       23.409751              0.048434                         0.113013                      0.032289    0.085989   -0.560456    -0.801982    -8.715660\n",
       "1721           1                    1309       27.63              2                         5                      4                   0.006875        0.021108                  0.222222      0               9.0                 3.070000                                    0.555556                                 0.444444                0.001528                           0.003820                        0.003056       47.376041              0.072385                         0.180963                      0.144770    0.030377    0.593534     4.362004     8.267942\n",
       "1722           3                     562       73.28              1                        10                      3                   0.044484        0.130391                  0.040000      0              25.0                 2.931200                                    0.400000                                 0.120000                0.001779                           0.017794                        0.005338        7.669214              0.013646                         0.136463                      0.040939    0.012145    0.025813     0.269875     3.446269\n",
       "1723           6                     407       62.09              7                         3                      3                   0.039312        0.152555                  0.437500      0              16.0                 3.880625                                    0.187500                                 0.187500                0.017199                           0.007371                        0.007371        6.555001              0.112740                         0.048317                      0.048317    0.263760   -0.366196     3.309290    -2.596354\n",
       "1724           3                     836       97.99              5                         9                      4                   0.017943        0.117213                  0.333333      0              15.0                 6.532667                                    0.600000                                 0.266667                0.005981                           0.010766                        0.004785        8.531483              0.051026                         0.091846                      0.040820    0.271483    0.185260     3.744615     2.699343\n",
       "1725           1                     385       44.73              4                         8                      2                   0.028571        0.116182                  0.363636      0              11.0                 4.066364                                    0.727273                                 0.181818                0.010390                           0.020779                        0.005195        8.607199              0.089425                         0.178851                      0.044713   -0.230273    0.382407    -4.041372     2.549493\n",
       "1726           1                    1538       60.68              8                         6                      5                   0.012354        0.039454                  0.421053      1              19.0                 3.193684                                    0.315789                                 0.263158                0.005202                           0.003901                        0.003251       25.346078              0.131839                         0.098879                      0.082399    0.095483    0.624063    -0.589579     6.392539\n",
       "1727           4                     839       82.62              8                         0                      3                   0.017878        0.098474                  0.533333      0              15.0                 5.508000                                    0.000000                                 0.200000                0.009535                           0.000000                        0.003576       10.154926              0.096829                         0.000000                      0.036311    0.037427    0.001942     2.981706    -1.124331\n",
       "1728           1                     532       93.35              0                         4                      4                   0.011278        0.175470                  0.000000      0               6.0                15.558333                                    0.666667                                 0.666667                0.000000                           0.007519                        0.007519        5.698982              0.000000                         0.042849                      0.042849    0.117318    0.626335     3.359876     6.962106\n",
       "1729           3                     421       79.04              4                         2                      0                   0.007126        0.187743                  1.333333      0               3.0                26.346667                                    0.666667                                 0.000000                0.009501                           0.004751                        0.000000        5.326417              0.050607                         0.025304                      0.000000   -0.317981   -0.050349    -3.070290     0.163052\n",
       "1730           4                      13       73.98             10                         9                      5                   1.461538        5.690769                  0.526316      0              19.0                 3.893684                                    0.473684                                 0.263158                0.769231                           0.692308                        0.384615        0.175723              0.135172                         0.121655                      0.067586    0.461423    0.107540     7.610621    -1.873757\n",
       "1731           1                    1367       65.92              5                         1                      0                   0.019751        0.048222                  0.185185      1              27.0                 2.441481                                    0.037037                                 0.000000                0.003658                           0.000732                        0.000000       20.737257              0.075850                         0.015170                      0.000000   -0.838558    0.150768   -10.055054     0.769138\n",
       "1732           2                    1265       10.51              6                         7                      5                   0.012648        0.008308                  0.375000      0              16.0                 0.656875                                    0.437500                                 0.312500                0.004743                           0.005534                        0.003953      120.361560              0.570885                         0.666032                      0.475737    0.215368    0.466568     0.627473     7.477462\n",
       "1733           2                     922       26.50              9                        10                      2                   0.003254        0.028742                  3.000000      0               3.0                 8.833333                                    3.333333                                 0.666667                0.009761                           0.010846                        0.002169       34.792453              0.339623                         0.377358                      0.075472    0.033818    0.267997    -2.465698     2.136254\n",
       "1734           2                    1553       63.32              7                         8                      1                   0.001932        0.040773                  2.333333      0               3.0                21.106667                                    2.666667                                 0.333333                0.004507                           0.005151                        0.000644       24.526216              0.110550                         0.126342                      0.015793   -0.146733    0.168209    -3.011511     1.141794\n",
       "1735           1                      93       48.98              5                         8                      0                   0.118280        0.526667                  0.454545      0              11.0                 4.452727                                    0.727273                                 0.000000                0.053763                           0.086022                        0.000000        1.898734              0.102082                         0.163332                      0.000000   -0.534878    0.199007    -4.341489     2.310202\n",
       "1736           3                     429       88.55              1                         8                      0                   0.002331        0.206410                  1.000000      0               1.0                88.550000                                    8.000000                                 0.000000                0.002331                           0.018648                        0.000000        4.844720              0.011293                         0.090344                      0.000000   -0.042084   -0.054800     9.708371     2.976890\n",
       "1737           1                     679       90.50              7                         4                      5                   0.026510        0.133284                  0.388889      0              18.0                 5.027778                                    0.222222                                 0.277778                0.010309                           0.005891                        0.007364        7.502762              0.077348                         0.044199                      0.055249    0.101614    0.654072     1.590423     5.373973\n",
       "1738           1                     350       14.49              9                         8                      2                   0.045714        0.041400                  0.562500      0              16.0                 0.905625                                    0.500000                                 0.125000                0.025714                           0.022857                        0.005714       24.154589              0.621118                         0.552105                      0.138026   -0.315002    0.366606    -1.591089     4.976254\n",
       "1739           5                    1600       43.51              4                         0                      0                   0.017500        0.027194                  0.142857      0              28.0                 1.553929                                    0.000000                                 0.000000                0.002500                           0.000000                        0.000000       36.773156              0.091933                         0.000000                      0.000000   -0.498235   -0.536114    -5.106455    -8.633089\n",
       "1740           2                    1576       60.52              5                         7                      2                   0.006980        0.038401                  0.454545      0              11.0                 5.501818                                    0.636364                                 0.181818                0.003173                           0.004442                        0.001269       26.040978              0.082617                         0.115664                      0.033047   -0.154503    0.202168    -2.365052     2.754789\n",
       "1741           1                    1772       39.42              3                         9                      3                   0.002257        0.022246                  0.750000      0               4.0                 9.855000                                    2.250000                                 0.750000                0.001693                           0.005079                        0.001693       44.951801              0.076104                         0.228311                      0.076104    0.043548    0.502271     5.815296     7.292999\n",
       "1742           5                    1442       92.56             10                         0                      2                   0.018724        0.064189                  0.370370      0              27.0                 3.428148                                    0.000000                                 0.074074                0.006935                           0.000000                        0.001387       15.579084              0.108038                         0.000000                      0.021608   -0.154990   -0.336170     0.164986    -6.050881\n",
       "1743           6                     583       71.90              9                         8                      0                   0.048027        0.123328                  0.321429      0              28.0                 2.567857                                    0.285714                                 0.000000                0.015437                           0.013722                        0.000000        8.108484              0.125174                         0.111266                      0.000000   -0.236803   -0.754987    -3.284574    -6.488367\n",
       "1744           5                     570       24.44              1                         9                      3                   0.022807        0.042877                  0.076923      0              13.0                 1.880000                                    0.692308                                 0.230769                0.001754                           0.015789                        0.005263       23.322422              0.040917                         0.368249                      0.122750    0.289183   -0.237442     7.880153    -4.071717\n",
       "1745           3                    1308       90.30              2                         7                      1                   0.008410        0.069037                  0.181818      0              11.0                 8.209091                                    0.636364                                 0.090909                0.001529                           0.005352                        0.000765       14.485050              0.022148                         0.077519                      0.011074   -0.186875   -0.069209    -2.256251     0.078734\n",
       "1746           3                     929        5.14              1                         5                      1                   0.011841        0.005533                  0.090909      0              11.0                 0.467273                                    0.454545                                 0.090909                0.001076                           0.005382                        0.001076      180.739300              0.194553                         0.972763                      0.194553   -0.279672   -0.041324    -6.589663     1.588630\n",
       "1747           3                       4        8.62              5                        10                      1                   1.500000        2.155000                  0.833333      0               6.0                 1.436667                                    1.666667                                 0.166667                1.250000                           2.500000                        0.250000        0.464037              0.580046                         1.160093                      0.116009   -0.110546   -0.030078    -3.984585     0.781309\n",
       "1748           3                    1371       10.90              2                         7                      4                   0.007294        0.007950                  0.200000      0              10.0                 1.090000                                    0.700000                                 0.400000                0.001459                           0.005106                        0.002918      125.779817              0.183486                         0.642202                      0.366972    0.233540    0.227336     5.181474     6.929360\n",
       "1749           4                     502       75.97              5                         3                      0                   0.027888        0.151335                  0.357143      0              14.0                 5.426429                                    0.214286                                 0.000000                0.009960                           0.005976                        0.000000        6.607872              0.065815                         0.039489                      0.000000   -0.357424   -0.300202    -6.527399    -4.733041\n",
       "1750           2                     987       26.32              6                         5                      0                   0.026342        0.026667                  0.230769      0              26.0                 1.012308                                    0.192308                                 0.000000                0.006079                           0.005066                        0.000000       37.500000              0.227964                         0.189970                      0.000000   -0.684151   -0.037838    -8.546973     0.015983\n",
       "1751           3                     703       47.17              8                         8                      4                   0.005690        0.067098                  2.000000      0               4.0                11.792500                                    2.000000                                 1.000000                0.011380                           0.011380                        0.005690       14.903540              0.169599                         0.169599                      0.084800    0.397583    0.292865     6.506152     3.067188\n",
       "1752           6                    1504       89.37              8                         5                      3                   0.018617        0.059422                  0.285714      0              28.0                 3.191786                                    0.178571                                 0.107143                0.005319                           0.003324                        0.001995       16.828914              0.089515                         0.055947                      0.033568    0.171494   -0.466429     3.227532    -7.113527\n",
       "1753           4                    1738       70.03             10                         9                      2                   0.005754        0.040293                  1.000000      0              10.0                 7.003000                                    0.900000                                 0.200000                0.005754                           0.005178                        0.001151       24.817935              0.142796                         0.128516                      0.028559    0.089241   -0.144764     6.064500     1.157601\n",
       "1754           1                     467       87.58              0                         8                      2                   0.057816        0.187537                  0.000000      1              27.0                 3.243704                                    0.296296                                 0.074074                0.000000                           0.017131                        0.004283        5.332268              0.000000                         0.091345                      0.022836   -0.378776    0.280051    -7.844985     4.068583\n",
       "1755           1                    1308       74.42              6                         5                      3                   0.005352        0.056896                  0.857143      0               7.0                10.631429                                    0.714286                                 0.428571                0.004587                           0.003823                        0.002294       17.575920              0.080623                         0.067186                      0.040312   -0.063134    0.517527     4.714210     5.322341\n",
       "1756           2                     453       36.03              2                         4                      0                   0.002208        0.079536                  2.000000      0               1.0                36.030000                                    4.000000                                 0.000000                0.004415                           0.008830                        0.000000       12.572856              0.055509                         0.111019                      0.000000   -0.330649    0.132157    -3.711656     0.418196\n",
       "1757           4                     745       21.46              0                         0                      1                   0.026846        0.028805                  0.000000      0              20.0                 1.073000                                    0.000000                                 0.050000                0.000000                           0.000000                        0.001342       34.715750              0.000000                         0.000000                      0.046598   -0.357602   -0.220881    -7.236362    -7.298626\n",
       "1758           1                     511       60.59              3                         3                      2                   0.050881        0.118571                  0.115385      0              26.0                 2.330385                                    0.115385                                 0.076923                0.005871                           0.005871                        0.003914        8.433735              0.049513                         0.049513                      0.033009   -0.478661    0.335519    -8.472413     4.532022\n",
       "1759           3                    1421       10.78              5                         8                      4                   0.009148        0.007586                  0.384615      0              13.0                 0.829231                                    0.615385                                 0.307692                0.003519                           0.005630                        0.002815      131.818182              0.463822                         0.742115                      0.371058    0.210968    0.205756     5.092225     6.681635\n",
       "1760           2                     160       92.21              6                         0                      4                   0.081250        0.576313                  0.461538      0              13.0                 7.093077                                    0.000000                                 0.307692                0.037500                           0.000000                        0.025000        1.735170              0.065069                         0.000000                      0.043379    0.038859    0.456665     0.597581     3.242662\n",
       "1761           2                      55       12.86             11                         9                      2                   0.254545        0.233818                  0.785714      0              14.0                 0.918571                                    0.642857                                 0.142857                0.200000                           0.163636                        0.036364        4.276827              0.855365                         0.699844                      0.155521   -0.177282    0.206160    -1.485528     4.478005\n",
       "1762           2                    1637       70.76              1                         4                      0                   0.001833        0.043225                  0.333333      0               3.0                23.586667                                    1.333333                                 0.000000                0.000611                           0.002443                        0.000000       23.134539              0.014132                         0.056529                      0.000000   -0.396273    0.079846    -4.876172     0.557323\n",
       "1763           4                    1791       84.09              2                         6                      2                   0.015075        0.046951                  0.074074      0              27.0                 3.114444                                    0.222222                                 0.074074                0.001117                           0.003350                        0.001117       21.298609              0.023784                         0.071352                      0.023784   -0.144412   -0.233730     0.278748    -9.041852\n",
       "1764           2                      28       54.84              7                         3                      1                   1.000000        1.958571                  0.250000      0              28.0                 1.958571                                    0.107143                                 0.035714                0.250000                           0.107143                        0.035714        0.510576              0.127644                         0.054705                      0.018235   -0.560200    0.074300    -6.846248     7.009752\n",
       "1765           1                     500        5.88              4                         1                      0                   0.002000        0.011760                  4.000000      0               1.0                 5.880000                                    1.000000                                 0.000000                0.008000                           0.002000                        0.000000       85.034014              0.680272                         0.170068                      0.000000   -0.548464    0.324000    -5.115762     0.328213\n",
       "1766           5                     119       29.69              4                         5                      2                   0.100840        0.249496                  0.333333      0              12.0                 2.474167                                    0.416667                                 0.166667                0.033613                           0.042017                        0.016807        4.008084              0.134725                         0.168407                      0.067363    0.079544   -0.280694     2.040120    -2.845488\n",
       "1767           2                     741       51.85              4                        10                      4                   0.002699        0.069973                  2.000000      0               2.0                25.925000                                    5.000000                                 2.000000                0.005398                           0.013495                        0.005398       14.291225              0.077146                         0.192864                      0.077146    0.452433    0.485561     6.288129     7.161877\n",
       "1768           2                    1560       33.53              3                         1                      4                   0.001282        0.021494                  1.500000      0               2.0                16.765000                                    0.500000                                 2.000000                0.001923                           0.000641                        0.002564       46.525500              0.089472                         0.029824                      0.119296    0.214501    0.533055     1.860765    10.056735\n",
       "1769           1                     321       43.28             11                         7                      5                   0.090343        0.134829                  0.379310      1              29.0                 1.492414                                    0.241379                                 0.172414                0.034268                           0.021807                        0.015576        7.416821              0.254159                         0.161738                      0.115527   -0.000892    0.585012    -2.453825     8.194140\n",
       "1770           4                    1413       33.23              6                         5                      0                   0.017693        0.023517                  0.240000      0              25.0                 1.329200                                    0.200000                                 0.000000                0.004246                           0.003539                        0.000000       42.521818              0.180560                         0.150466                      0.000000   -0.481011   -0.383146    -6.319633    -3.314936\n",
       "1771           4                     113       58.90              9                         4                      0                   0.256637        0.521239                  0.310345      0              29.0                 2.031034                                    0.137931                                 0.000000                0.079646                           0.035398                        0.000000        1.918506              0.152801                         0.067912                      0.000000   -0.514366   -0.374555    -4.955513    -5.252791\n",
       "1772           2                    1178       26.85              2                         0                      0                   0.007640        0.022793                  0.222222      0               9.0                 2.983333                                    0.000000                                 0.000000                0.001698                           0.000000                        0.000000       43.873371              0.074488                         0.000000                      0.000000   -0.588638    0.084644    -7.477822     1.844912\n",
       "1773           2                      50        4.10              2                         5                      3                   0.540000        0.082000                  0.074074      0              27.0                 0.151852                                    0.185185                                 0.111111                0.040000                           0.100000                        0.060000       12.195122              0.487805                         1.219512                      0.731707   -0.236160    0.246033    -0.895336     2.639490\n",
       "1774           3                    1085       53.76              8                         7                      0                   0.004608        0.049548                  1.600000      0               5.0                10.752000                                    1.400000                                 0.000000                0.007373                           0.006452                        0.000000       20.182292              0.148810                         0.130208                      0.000000   -0.286126   -0.105971    -3.396359    -0.535480\n",
       "1775           2                    1493       12.28             11                         7                      2                   0.007368        0.008225                  1.000000      0              11.0                 1.116364                                    0.636364                                 0.181818                0.007368                           0.004689                        0.001340      121.579805              0.895765                         0.570033                      0.162866   -0.192747    0.219940    -4.512022     4.607533\n",
       "1776           1                     242       39.24              8                         5                      4                   0.033058        0.162149                  1.000000      0               8.0                 4.905000                                    0.625000                                 0.500000                0.033058                           0.020661                        0.016529        6.167176              0.203874                         0.127421                      0.101937    0.061398    0.627893     0.955770     8.386696\n",
       "1777           3                     596       10.74              2                         1                      2                   0.013423        0.018020                  0.250000      0               8.0                 1.342500                                    0.125000                                 0.250000                0.003356                           0.001678                        0.003356       55.493482              0.186220                         0.093110                      0.186220   -0.155897    0.110514    -2.081894    -1.955158\n",
       "1778           5                     302       39.38              2                         3                      3                   0.056291        0.130397                  0.117647      0              17.0                 2.316471                                    0.176471                                 0.176471                0.006623                           0.009934                        0.009934        7.668867              0.050787                         0.076181                      0.076181    0.146839   -0.205681     2.675555    -2.991265\n",
       "1779           1                    1625       89.93             11                         3                      0                   0.011692        0.055342                  0.578947      1              19.0                 4.733158                                    0.157895                                 0.000000                0.006769                           0.001846                        0.000000       18.069610              0.122317                         0.033359                      0.000000   -0.710022    0.181576    -7.833744    -0.558582\n",
       "1780           5                    1073       93.97              6                         1                      2                   0.003728        0.087577                  1.500000      0               4.0                23.492500                                    0.250000                                 0.500000                0.005592                           0.000932                        0.001864       11.418538              0.063850                         0.010642                      0.021283    0.162423   -0.204214     1.005684    -3.866466\n",
       "1781           2                     941       90.78              9                         2                      3                   0.015940        0.096472                  0.600000      0              15.0                 6.052000                                    0.133333                                 0.200000                0.009564                           0.002125                        0.003188       10.365719              0.099141                         0.022031                      0.033047   -0.115199    0.328513    -2.107337     4.943964\n",
       "1782           3                     667       14.56              3                         7                      2                   0.035982        0.021829                  0.125000      0              24.0                 0.606667                                    0.291667                                 0.083333                0.004498                           0.010495                        0.002999       45.810440              0.206044                         0.480769                      0.137363   -0.225870   -0.028378    -0.755084     1.027171\n",
       "1783           3                     557       65.74             11                         2                      3                   0.035907        0.118025                  0.550000      0              20.0                 3.287000                                    0.100000                                 0.150000                0.019749                           0.003591                        0.005386        8.472772              0.167326                         0.030423                      0.045634   -0.091465    0.140155     1.274046     2.258114\n",
       "1784           5                     589       25.03              2                         7                      5                   0.018676        0.042496                  0.181818      0              11.0                 2.275455                                    0.636364                                 0.454545                0.003396                           0.011885                        0.008489       23.531762              0.079904                         0.279664                      0.199760    0.586399   -0.017983     8.363355    -3.987318\n",
       "1785           1                    1262       65.81              9                         3                      5                   0.011094        0.052147                  0.642857      0              14.0                 4.700714                                    0.214286                                 0.357143                0.007132                           0.002377                        0.003962       19.176417              0.136757                         0.045586                      0.075976    0.106342    0.684112    -0.419446     7.710482\n",
       "1786           1                    1007       76.01              1                         6                      1                   0.001986        0.075482                  0.500000      0               2.0                38.005000                                    3.000000                                 0.500000                0.000993                           0.005958                        0.000993       13.248257              0.013156                         0.078937                      0.013156   -0.232097    0.362438    -3.140653     3.021931\n",
       "1787           2                     826       34.47              1                         1                      2                   0.002421        0.041731                  0.500000      0               2.0                17.235000                                    0.500000                                 1.000000                0.001211                           0.001211                        0.002421       23.962866              0.029011                         0.029011                      0.058021   -0.123915    0.329782    -4.551945     4.246637\n",
       "1788           2                     467       92.95              6                         3                      4                   0.057816        0.199036                  0.222222      0              27.0                 3.442593                                    0.111111                                 0.148148                0.012848                           0.006424                        0.008565        5.024207              0.064551                         0.032275                      0.043034   -0.069208    0.347730    -0.471632     3.691104\n",
       "1789           1                    1681       60.33             10                         0                      0                   0.013682        0.035889                  0.434783      1              23.0                 2.623043                                    0.000000                                 0.000000                0.005949                           0.000000                        0.000000       27.863418              0.165755                         0.000000                      0.000000   -0.826515    0.185734    -9.189062    -0.643166\n",
       "1790           2                     166       23.92             11                         2                      5                   0.072289        0.144096                  0.916667      0              12.0                 1.993333                                    0.166667                                 0.416667                0.066265                           0.012048                        0.030120        6.939799              0.459866                         0.083612                      0.209030    0.189893    0.557001     3.653892     3.974497\n",
       "1791           6                    1019       35.72              8                         8                      5                   0.008832        0.035054                  0.888889      0               9.0                 3.968889                                    0.888889                                 0.555556                0.007851                           0.007851                        0.004907       28.527436              0.223964                         0.223964                      0.139978    0.728138   -0.179199     7.935737    -2.873689\n",
       "1792           2                     772       73.41              7                         7                      1                   0.024611        0.095091                  0.368421      0              19.0                 3.863684                                    0.368421                                 0.052632                0.009067                           0.009067                        0.001295       10.516278              0.095355                         0.095355                      0.013622   -0.386563    0.076503    -5.999290     3.552078\n",
       "1793           2                    1767       63.45             11                         1                      1                   0.013016        0.035908                  0.478261      0              23.0                 2.758696                                    0.043478                                 0.043478                0.006225                           0.000566                        0.000566       27.848700              0.173365                         0.015760                      0.015760   -0.559368    0.099316    -8.929683    -1.015705\n",
       "1794           1                     498       61.62              2                         0                      2                   0.038153        0.123735                  0.105263      0              19.0                 3.243158                                    0.000000                                 0.105263                0.004016                           0.000000                        0.004016        8.081792              0.032457                         0.000000                      0.032457   -0.454373    0.396840    -8.721907     4.732460\n",
       "1795           3                    1451       11.90              9                         1                      4                   0.008959        0.008201                  0.692308      0              13.0                 0.915385                                    0.076923                                 0.307692                0.006203                           0.000689                        0.002757      121.932773              0.756303                         0.084034                      0.336134    0.080592    0.271472     0.228548     1.558208\n",
       "1796           6                     575        8.55              5                         1                      0                   0.050435        0.014870                  0.172414      0              29.0                 0.294828                                    0.034483                                 0.000000                0.008696                           0.001739                        0.000000       67.251462              0.584795                         0.116959                      0.000000   -0.408360   -0.701087    -6.720244    -6.820616\n",
       "1797           6                     865       31.84             10                         7                      3                   0.017341        0.036809                  0.666667      0              15.0                 2.122667                                    0.466667                                 0.200000                0.011561                           0.008092                        0.003468       27.167085              0.314070                         0.219849                      0.094221    0.319001   -0.391723     6.539560    -3.156917\n",
       "1798           2                    1571       12.01              8                         8                      5                   0.006365        0.007645                  0.800000      0              10.0                 1.201000                                    0.800000                                 0.500000                0.005092                           0.005092                        0.003183      130.807660              0.666112                         0.666112                      0.416320    0.305648    0.495070     1.032434     7.445225\n",
       "1799           6                    1807       65.04              9                         5                      0                   0.014388        0.035993                  0.346154      0              26.0                 2.501538                                    0.192308                                 0.000000                0.004981                           0.002767                        0.000000       27.782903              0.138376                         0.076876                      0.000000   -0.285962   -0.735913    -1.650151    -7.612187\n",
       "1800           1                    1381       69.57              1                         9                      4                   0.016655        0.050377                  0.043478      1              23.0                 3.024783                                    0.391304                                 0.173913                0.000724                           0.006517                        0.002896       19.850510              0.014374                         0.129366                      0.057496   -0.034013    0.470970     0.441294     5.547047\n",
       "1801           3                     956        2.36              0                         6                      5                   0.009414        0.002469                  0.000000      0               9.0                 0.262222                                    0.666667                                 0.555556                0.000000                           0.006276                        0.005230      405.084746              0.000000                         2.542373                      2.118644    0.383494    0.339717     4.961590     7.381038\n",
       "1802           1                     796       28.96              5                         3                      2                   0.020101        0.036382                  0.312500      0              16.0                 1.810000                                    0.187500                                 0.125000                0.006281                           0.003769                        0.002513       27.486188              0.172652                         0.103591                      0.069061   -0.395912    0.392903    -4.619734     7.339599\n",
       "1803           1                     338       36.45             10                        10                      5                   0.071006        0.107840                  0.416667      1              24.0                 1.518750                                    0.416667                                 0.208333                0.029586                           0.029586                        0.014793        9.272977              0.274348                         0.274348                      0.137174    0.104222    0.585888    -0.437698     6.872810\n",
       "1804           4                    1175       74.52              4                         4                      3                   0.012766        0.063421                  0.266667      0              15.0                 4.968000                                    0.266667                                 0.200000                0.003404                           0.003404                        0.002553       15.767579              0.053677                         0.053677                      0.040258    0.104429   -0.043319     1.649832    -0.523160\n",
       "1805           2                    1027       39.90              0                         4                      2                   0.011685        0.038851                  0.000000      0              12.0                 3.325000                                    0.333333                                 0.166667                0.000000                           0.003895                        0.001947       25.739348              0.000000                         0.100251                      0.050125   -0.226330    0.221037    -5.331325     5.990990\n",
       "1806           6                    1507       23.96              1                         0                      4                   0.015926        0.015899                  0.041667      0              24.0                 0.998333                                    0.000000                                 0.166667                0.000664                           0.000000                        0.002654       62.896494              0.041736                         0.000000                      0.166945    0.243958   -0.314566     3.223017    -5.546333\n",
       "1807           3                     130       42.82              6                         0                      5                   0.200000        0.329385                  0.230769      0              26.0                 1.646923                                    0.000000                                 0.192308                0.046154                           0.000000                        0.038462        3.035965              0.140121                         0.000000                      0.116768    0.107911    0.310642     1.174698     2.373464\n",
       "1808           1                    1380       54.08              8                         4                      1                   0.010145        0.039188                  0.571429      0              14.0                 3.862857                                    0.285714                                 0.071429                0.005797                           0.002899                        0.000725       25.517751              0.147929                         0.073964                      0.018491   -0.500914    0.296445    -5.283191     1.486939\n",
       "1809           2                     755       56.06             11                         5                      3                   0.019868        0.074252                  0.733333      0              15.0                 3.737333                                    0.333333                                 0.200000                0.014570                           0.006623                        0.003974       13.467713              0.196218                         0.089190                      0.053514   -0.084942    0.313461    -1.702273     4.643777\n",
       "1810           1                     383        3.35              3                         8                      1                   0.023499        0.008747                  0.333333      0               9.0                 0.372222                                    0.888889                                 0.111111                0.007833                           0.020888                        0.002611      114.328358              0.895522                         2.388060                      0.298507   -0.389951    0.301226    -4.521966     1.756332\n",
       "1811           2                    1461       39.82              6                         9                      1                   0.017112        0.027255                  0.240000      1              25.0                 1.592800                                    0.360000                                 0.040000                0.004107                           0.006160                        0.000684       36.690105              0.150678                         0.226017                      0.025113   -0.445423    0.018850    -7.407547     1.006333\n",
       "1812           3                     916       21.73              4                         0                      2                   0.013100        0.023723                  0.333333      0              12.0                 1.810833                                    0.000000                                 0.166667                0.004367                           0.000000                        0.002183       42.153705              0.184077                         0.000000                      0.092039   -0.218194    0.093791    -1.991095    -1.965868\n",
       "1813           3                     557       69.06             10                         0                      5                   0.025135        0.123986                  0.714286      0              14.0                 4.932857                                    0.000000                                 0.357143                0.017953                           0.000000                        0.008977        8.065450              0.144802                         0.000000                      0.072401    0.253119    0.377354     3.561305     4.125284\n",
       "1814           2                     770        9.17             11                        10                      5                   0.029870        0.011909                  0.478261      0              23.0                 0.398696                                    0.434783                                 0.217391                0.014286                           0.012987                        0.006494       83.969466              1.199564                         1.090513                      0.545256    0.187698    0.418184    -0.213774     6.881392\n",
       "1815           1                     866       44.22              3                         9                      5                   0.018476        0.051062                  0.187500      0              16.0                 2.763750                                    0.562500                                 0.312500                0.003464                           0.010393                        0.005774       19.583899              0.067843                         0.203528                      0.113071    0.185605    0.618242     1.175430     6.936861\n",
       "1816           3                    1563       87.86              4                         1                      0                   0.005758        0.056212                  0.444444      0               9.0                 9.762222                                    0.111111                                 0.000000                0.002559                           0.000640                        0.000000       17.789665              0.045527                         0.011382                      0.000000   -0.434341   -0.101966    -5.957708    -0.603845\n",
       "1817           2                    1775        5.79             11                         8                      4                   0.014085        0.003262                  0.440000      1              25.0                 0.231600                                    0.320000                                 0.160000                0.006197                           0.004507                        0.002254      306.563040              1.899827                         1.381693                      0.690846   -0.036067    0.316228    -2.124451     7.101188\n",
       "1818           5                     224       28.55              5                         7                      4                   0.075893        0.127455                  0.294118      0              17.0                 1.679412                                    0.411765                                 0.235294                0.022321                           0.031250                        0.017857        7.845884              0.175131                         0.245184                      0.140105    0.362854   -0.137358     6.660828    -3.836380\n",
       "1819           3                     774       41.22              4                         1                      5                   0.012920        0.053256                  0.400000      0              10.0                 4.122000                                    0.100000                                 0.500000                0.005168                           0.001292                        0.006460       18.777293              0.097040                         0.024260                      0.121300    0.305074    0.381886     2.764474     2.239516\n",
       "1820           4                     930       40.27              8                         5                      3                   0.002151        0.043301                  4.000000      0               2.0                20.135000                                    2.500000                                 1.500000                0.008602                           0.005376                        0.003226       23.094115              0.198659                         0.124162                      0.074497    0.354076    0.084956     7.416952     3.067899\n",
       "1821           4                    1501       51.16              7                         4                      5                   0.011326        0.034084                  0.411765      0              17.0                 3.009412                                    0.235294                                 0.294118                0.004664                           0.002665                        0.003331       29.339328              0.136826                         0.078186                      0.097733    0.366335    0.136529     3.983505     1.238935\n",
       "1822           2                    1689       13.70              8                         1                      1                   0.017762        0.008111                  0.266667      1              30.0                 0.456667                                    0.033333                                 0.033333                0.004737                           0.000592                        0.000592      123.284672              0.583942                         0.072993                      0.072993   -0.662985    0.063058    -9.473579    -1.388091\n",
       "1823           4                    1178       74.02             11                         6                      3                   0.013582        0.062835                  0.687500      0              16.0                 4.626250                                    0.375000                                 0.187500                0.009338                           0.005093                        0.002547       15.914618              0.148608                         0.081059                      0.040530    0.121521   -0.052398     5.149657     1.203134\n",
       "1824           2                     837        8.07              2                         6                      1                   0.035842        0.009642                  0.066667      0              30.0                 0.269000                                    0.200000                                 0.033333                0.002389                           0.007168                        0.001195      103.717472              0.247831                         0.743494                      0.123916   -0.561812    0.022895    -7.129368     5.270863\n",
       "1825           1                      36       35.02              8                        10                      1                   0.250000        0.972778                  0.888889      0               9.0                 3.891111                                    1.111111                                 0.111111                0.222222                           0.277778                        0.027778        1.027984              0.228441                         0.285551                      0.028555   -0.328814    0.297557    -4.359249     2.572219\n",
       "1826           5                    1455       90.53             10                         1                      4                   0.019931        0.062220                  0.344828      0              29.0                 3.121724                                    0.034483                                 0.137931                0.006873                           0.000687                        0.002749       16.072020              0.110461                         0.011046                      0.044184    0.145190   -0.168548     2.970952    -6.837061\n",
       "1827           1                    1133       24.49              3                         3                      1                   0.011474        0.021615                  0.230769      0              13.0                 1.883846                                    0.230769                                 0.076923                0.002648                           0.002648                        0.000883       46.263781              0.122499                         0.122499                      0.040833   -0.521240    0.307079    -6.778986     2.526335\n",
       "1828           3                    1421        2.42              7                         8                      0                   0.019704        0.001703                  0.250000      0              28.0                 0.086429                                    0.285714                                 0.000000                0.004926                           0.005630                        0.000000      587.190083              2.892562                         3.305785                      0.000000   -0.577690   -0.247480    -6.443964    -2.567855\n",
       "1829           2                      77       66.01              5                         3                      5                   0.363636        0.857273                  0.178571      0              28.0                 2.357500                                    0.107143                                 0.178571                0.064935                           0.038961                        0.064935        1.166490              0.075746                         0.045448                      0.075746    0.060303    0.442556     0.222823     3.865767\n",
       "1830           6                    1701        8.09              9                         8                      4                   0.014109        0.004756                  0.375000      0              24.0                 0.337083                                    0.333333                                 0.166667                0.005291                           0.004703                        0.002352      210.259580              1.112485                         0.988875                      0.494438    0.364356   -0.368483     6.764425    -4.953679\n",
       "1831           4                      30       52.22              9                         6                      2                   0.900000        1.740667                  0.333333      0              27.0                 1.934074                                    0.222222                                 0.074074                0.300000                           0.200000                        0.066667        0.574493              0.172348                         0.114899                      0.038300   -0.155154   -0.192013    -4.027856    -4.661971\n",
       "1832           6                     680       92.40              7                        10                      3                   0.026471        0.135882                  0.388889      0              18.0                 5.133333                                    0.555556                                 0.166667                0.010294                           0.014706                        0.004412        7.359307              0.075758                         0.108225                      0.032468    0.384303   -0.443470     6.310797    -7.676450\n",
       "1833           3                    1536       33.57             11                         2                      2                   0.015625        0.021855                  0.458333      0              24.0                 1.398750                                    0.083333                                 0.083333                0.007161                           0.001302                        0.001302       45.755139              0.327674                         0.059577                      0.059577   -0.320658    0.013829    -9.086072    -2.415003\n",
       "1834           2                     303       46.79              3                         2                      3                   0.023102        0.154422                  0.428571      0               7.0                 6.684286                                    0.285714                                 0.428571                0.009901                           0.006601                        0.009901        6.475743              0.064116                         0.042744                      0.064116   -0.033193    0.380053    -3.573747     5.524268\n",
       "1835           3                       3       64.94              3                         4                      3                   4.666667       21.646667                  0.214286      0              14.0                 4.638571                                    0.285714                                 0.214286                1.000000                           1.333333                        1.000000        0.046196              0.046196                         0.061595                      0.046196    0.028692    0.149325     0.098078    -2.371513\n",
       "1836           3                    1736        4.66              0                         8                      5                   0.001728        0.002684                  0.000000      0               3.0                 1.553333                                    2.666667                                 1.666667                0.000000                           0.004608                        0.002880      372.532189              0.000000                         1.716738                      1.072961    0.541676    0.372560     5.761696     7.081137\n",
       "1837           1                     756       15.41             10                         4                      2                   0.015873        0.020384                  0.833333      0              12.0                 1.284167                                    0.333333                                 0.166667                0.013228                           0.005291                        0.002646       49.059053              0.648929                         0.259572                      0.129786   -0.345301    0.419073    -4.543165     5.082536\n",
       "1838           1                    1465       58.95             10                         0                      2                   0.017065        0.040239                  0.400000      1              25.0                 2.358000                                    0.000000                                 0.080000                0.006826                           0.000000                        0.001365       24.851569              0.169635                         0.000000                      0.033927   -0.540618    0.365386    -9.943054     0.251460\n",
       "1839           1                     358       34.74              7                         6                      4                   0.005587        0.097039                  3.500000      0               2.0                17.370000                                    3.000000                                 2.000000                0.019553                           0.016760                        0.011173       10.305124              0.201497                         0.172712                      0.115141    0.256953    0.701160     3.189190     7.629879\n",
       "1840           5                    1555       33.38              8                         2                      2                   0.001286        0.021466                  4.000000      0               2.0                16.690000                                    1.000000                                 1.000000                0.005145                           0.001286                        0.001286       46.584781              0.239664                         0.059916                      0.059916    0.196065   -0.178417     0.483268    -4.208192\n",
       "1841           2                    1539       11.13              9                         1                      5                   0.004548        0.007232                  1.285714      0               7.0                 1.590000                                    0.142857                                 0.714286                0.005848                           0.000650                        0.003249      138.274933              0.808625                         0.089847                      0.449236    0.219435    0.577670     1.293981     9.526946\n",
       "1842           1                     724       14.52              9                         5                      5                   0.006906        0.020055                  1.800000      0               5.0                 2.904000                                    1.000000                                 1.000000                0.012431                           0.006906                        0.006906       49.862259              0.619835                         0.344353                      0.344353    0.250494    0.748200     1.660101     8.853664\n",
       "1843           5                    1248       16.29             10                         6                      5                   0.021635        0.013053                  0.370370      0              27.0                 0.603333                                    0.222222                                 0.185185                0.008013                           0.004808                        0.004006       76.611418              0.613874                         0.368324                      0.306937    0.361625   -0.095189     6.456516    -4.907660\n",
       "1844           2                    1259       20.78              3                         5                      4                   0.007149        0.016505                  0.333333      0               9.0                 2.308889                                    0.555556                                 0.444444                0.002383                           0.003971                        0.003177       60.587103              0.144370                         0.240616                      0.192493    0.121445    0.425099     4.521530     7.961914\n",
       "1845           5                    1238       45.82              6                         0                      4                   0.005654        0.037011                  0.857143      0               7.0                 6.545714                                    0.000000                                 0.571429                0.004847                           0.000000                        0.003231       27.018769              0.130947                         0.000000                      0.087298    0.362845   -0.030255     4.337762    -2.487364\n",
       "1846           4                      44       66.72             10                         4                      5                   0.090909        1.516364                  2.500000      0               4.0                16.680000                                    1.000000                                 1.250000                0.227273                           0.090909                        0.113636        0.659472              0.149880                         0.059952                      0.074940    0.599689    0.264537     6.046237     1.797339\n",
       "1847           3                    1171       25.56             11                         1                      3                   0.020495        0.021827                  0.458333      0              24.0                 1.065000                                    0.041667                                 0.125000                0.009394                           0.000854                        0.002562       45.813772              0.430360                         0.039124                      0.117371   -0.186881    0.122008    -9.181171    -2.838308\n",
       "1848           2                    1211       88.88              8                         1                      5                   0.003303        0.073394                  2.000000      0               4.0                22.220000                                    0.250000                                 1.250000                0.006606                           0.000826                        0.004129       13.625113              0.090009                         0.011251                      0.056256    0.352766    0.608844     4.357925     4.961932\n",
       "1849           3                     703        8.20              8                         7                      0                   0.005690        0.011664                  2.000000      0               4.0                 2.050000                                    1.750000                                 0.000000                0.011380                           0.009957                        0.000000       85.731707              0.975610                         0.853659                      0.000000   -0.301564   -0.090145    -3.622889    -1.654950\n",
       "1850           6                     680       51.89              8                         5                      2                   0.033824        0.076309                  0.347826      0              23.0                 2.256087                                    0.217391                                 0.086957                0.011765                           0.007353                        0.002941       13.104644              0.154172                         0.096358                      0.038543    0.056948   -0.516685    -3.043913    -7.160035\n",
       "1851           4                     981       36.26              6                         4                      2                   0.014271        0.036962                  0.428571      0              14.0                 2.590000                                    0.285714                                 0.142857                0.006116                           0.004077                        0.002039       27.054606              0.165472                         0.110314                      0.055157   -0.064467   -0.121219    -2.041299    -2.894363\n",
       "1852           1                     801       73.63              6                         1                      4                   0.034956        0.091923                  0.214286      1              28.0                 2.629643                                    0.035714                                 0.142857                0.007491                           0.001248                        0.004994       10.878718              0.081489                         0.013581                      0.054326   -0.228058    0.528369    -1.736382     5.927167\n",
       "1853           2                    1397        8.48              1                         5                      3                   0.017180        0.006070                  0.041667      0              24.0                 0.353333                                    0.208333                                 0.125000                0.000716                           0.003579                        0.002147      164.740566              0.117925                         0.589623                      0.353774   -0.214021    0.240313    -5.343004     6.472922\n",
       "1854           6                     656       95.58              5                         6                      3                   0.001524        0.145701                  5.000000      0               1.0                95.580000                                    6.000000                                 3.000000                0.007622                           0.009146                        0.004573        6.863361              0.052312                         0.062775                      0.031387    0.796724   -0.196206     9.937723     4.108630\n",
       "1855           3                    1636        8.60              6                         3                      1                   0.007335        0.005257                  0.500000      0              12.0                 0.716667                                    0.250000                                 0.083333                0.003667                           0.001834                        0.000611      190.232558              0.697674                         0.348837                      0.116279   -0.336671   -0.030846    -7.261403    -0.302938\n",
       "1856           5                    1764       79.93              8                         0                      3                   0.005669        0.045312                  0.800000      0              10.0                 7.993000                                    0.000000                                 0.300000                0.004535                           0.000000                        0.001701       22.069311              0.100088                         0.000000                      0.037533    0.183057   -0.152703     1.266842    -4.495432\n",
       "1857           1                    1400       59.43              3                         6                      2                   0.016429        0.042450                  0.130435      1              23.0                 2.583913                                    0.260870                                 0.086957                0.002143                           0.004286                        0.001429       23.557126              0.050480                         0.100959                      0.033653   -0.402975    0.313592    -7.690426     2.947644\n",
       "1858           4                    1830       23.73              6                         4                      0                   0.015301        0.012967                  0.214286      0              28.0                 0.847500                                    0.142857                                 0.000000                0.003279                           0.002186                        0.000000       77.117573              0.252845                         0.168563                      0.000000   -0.541436   -0.395605    -5.110292    -8.551067\n",
       "1859           6                     451       54.85              1                         5                      1                   0.048780        0.121619                  0.045455      0              22.0                 2.493182                                    0.227273                                 0.045455                0.002217                           0.011086                        0.002217        8.222425              0.018232                         0.091158                      0.018232   -0.072937   -0.614835    -6.318127    -6.666389\n",
       "1860           2                     431       12.24             10                         5                      0                   0.053364        0.028399                  0.434783      0              23.0                 0.532174                                    0.217391                                 0.000000                0.023202                           0.011601                        0.000000       35.212418              0.816993                         0.408497                      0.000000   -0.660203   -0.004908    -6.314555     3.436418\n",
       "1861           6                     370       56.26             11                        10                      0                   0.072973        0.152054                  0.407407      0              27.0                 2.083704                                    0.370370                                 0.000000                0.029730                           0.027027                        0.000000        6.576609              0.195521                         0.177746                      0.000000   -0.201039   -0.758078    -3.395929    -6.123923\n",
       "1862           4                     212       88.01              3                         6                      5                   0.014151        0.415142                  1.000000      0               3.0                29.336667                                    2.000000                                 1.666667                0.014151                           0.028302                        0.023585        2.408817              0.034087                         0.068174                      0.056812    0.694814    0.246615     8.221653     0.542709\n",
       "1863           1                    1134       14.51              7                         2                      4                   0.002646        0.012795                  2.333333      0               3.0                 4.836667                                    0.666667                                 1.333333                0.006173                           0.001764                        0.003527       78.152998              0.482426                         0.137836                      0.275672    0.082278    0.691328     1.694020     9.509952\n",
       "1864           4                    1005       78.16              1                         0                      3                   0.007960        0.077771                  0.125000      0               8.0                 9.770000                                    0.000000                                 0.375000                0.000995                           0.000000                        0.002985       12.858240              0.012794                         0.000000                      0.038383    0.124540    0.028796     1.806451    -1.250343\n",
       "1865           2                    1827       68.94              6                         5                      1                   0.008210        0.037734                  0.400000      0              15.0                 4.596000                                    0.333333                                 0.066667                0.003284                           0.002737                        0.000547       26.501305              0.087032                         0.072527                      0.014505   -0.390615    0.098756    -5.775617     0.531482\n",
       "1866           6                     660       90.53             10                         1                      1                   0.003030        0.137167                  5.000000      0               2.0                45.265000                                    0.500000                                 0.500000                0.015152                           0.001515                        0.001515        7.290401              0.110461                         0.011046                      0.011046    0.176489   -0.423078     8.293224     2.701620\n",
       "1867           2                     206       71.30              4                         0                      4                   0.106796        0.346117                  0.181818      0              22.0                 3.240909                                    0.000000                                 0.181818                0.019417                           0.000000                        0.019417        2.889201              0.056101                         0.000000                      0.056101   -0.077012    0.402924    -0.024459     3.007612\n",
       "1868           5                     794       29.91              5                         3                      2                   0.013854        0.037670                  0.454545      0              11.0                 2.719091                                    0.272727                                 0.181818                0.006297                           0.003778                        0.002519       26.546306              0.167168                         0.100301                      0.066867    0.047049   -0.266000    -1.026168    -2.987634\n",
       "1869           4                     452       44.59              7                         9                      3                   0.050885        0.098650                  0.304348      0              23.0                 1.938696                                    0.391304                                 0.130435                0.015487                           0.019912                        0.006637       10.136802              0.156986                         0.201839                      0.067280    0.087640   -0.110890     0.296960    -0.639632\n",
       "1870           2                     195        2.10              1                         3                      1                   0.112821        0.010769                  0.045455      0              22.0                 0.095455                                    0.136364                                 0.045455                0.005128                           0.015385                        0.005128       92.857143              0.476190                         1.428571                      0.476190   -0.525993    0.098815    -7.403222     0.422384\n",
       "1871           3                    1434       69.97              8                         1                      4                   0.010460        0.048794                  0.533333      0              15.0                 4.664667                                    0.066667                                 0.266667                0.005579                           0.000697                        0.002789       20.494498              0.114335                         0.014292                      0.057167    0.098324    0.252156     1.952418     1.719391\n",
       "1872           3                     338       88.93              1                         3                      5                   0.073964        0.263107                  0.040000      0              25.0                 3.557200                                    0.120000                                 0.200000                0.002959                           0.008876                        0.014793        3.800742              0.011245                         0.033734                      0.056224    0.206482    0.273511     2.256691     0.565354\n",
       "1873           2                     767       50.95              7                         2                      0                   0.022164        0.066428                  0.411765      0              17.0                 2.997059                                    0.117647                                 0.000000                0.009126                           0.002608                        0.000000       15.053974              0.137390                         0.039254                      0.000000   -0.623033    0.038000    -9.540482     0.919365\n",
       "1874           1                     321       76.03              8                         7                      2                   0.071651        0.236854                  0.347826      0              23.0                 3.305652                                    0.304348                                 0.086957                0.024922                           0.021807                        0.006231        4.222018              0.105222                         0.092069                      0.026305   -0.368408    0.328203    -5.891068     4.447347\n",
       "1875           1                     397       41.89              5                         5                      0                   0.065491        0.105516                  0.192308      1              26.0                 1.611154                                    0.192308                                 0.000000                0.012594                           0.012594                        0.000000        9.477202              0.119360                         0.119360                      0.000000   -0.762581    0.139003   -10.497591     0.265843\n",
       "1876           4                     316       41.83              5                         8                      1                   0.094937        0.132373                  0.166667      0              30.0                 1.394333                                    0.266667                                 0.033333                0.015823                           0.025316                        0.003165        7.554387              0.119531                         0.191250                      0.023906   -0.310003   -0.328558    -4.616800    -4.810662\n",
       "1877           2                     685       62.68              1                         6                      2                   0.035036        0.091504                  0.041667      0              24.0                 2.611667                                    0.250000                                 0.083333                0.001460                           0.008759                        0.002920       10.928526              0.015954                         0.095724                      0.031908   -0.305633    0.142684    -8.220529     4.169440\n",
       "1878           4                    1140       38.03              2                         2                      3                   0.016667        0.033360                  0.105263      0              19.0                 2.001579                                    0.105263                                 0.157895                0.001754                           0.001754                        0.002632       29.976334              0.052590                         0.052590                      0.078885    0.000731   -0.048512     0.969935    -2.455174\n",
       "\n",
       "[1879 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trustLevel</th>\n",
       "      <td>0.140559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scannedLineItems</th>\n",
       "      <td>0.140535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_cluster_center_1</th>\n",
       "      <td>0.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsne_axis_2</th>\n",
       "      <td>0.068266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_cluster_center_3</th>\n",
       "      <td>0.052418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsne_axis_1</th>\n",
       "      <td>0.051469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_cluster_center_2</th>\n",
       "      <td>0.050080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_axis_2</th>\n",
       "      <td>0.046946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <td>0.039232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_axis_1</th>\n",
       "      <td>0.033114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantityModifications</th>\n",
       "      <td>0.029725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantityModificationsPerScannedLineItem</th>\n",
       "      <td>0.028974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <td>0.024746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <td>0.023510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineItemVoids</th>\n",
       "      <td>0.021347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scansWithoutRegistrationPerScannedLineItem</th>\n",
       "      <td>0.019014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricePerScannedLineItem</th>\n",
       "      <td>0.017869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <td>0.016745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scansWithoutRegistrationPerEuro</th>\n",
       "      <td>0.015736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantityModificationsPerSecond</th>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grandTotal</th>\n",
       "      <td>0.015296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondsPerEuro</th>\n",
       "      <td>0.014301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scansWithoutRegistrationPerSecond</th>\n",
       "      <td>0.012887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valuePerSecond</th>\n",
       "      <td>0.012819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineItemVoidsPerSecond</th>\n",
       "      <td>0.011599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantityModificationsPerEuro</th>\n",
       "      <td>0.008113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineItemVoidsPerEuro</th>\n",
       "      <td>0.007829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Importance\n",
       "trustLevel                                    0.140559\n",
       "scannedLineItems                              0.140535\n",
       "distance_cluster_center_1                     0.081400\n",
       "tsne_axis_2                                   0.068266\n",
       "distance_cluster_center_3                     0.052418\n",
       "tsne_axis_1                                   0.051469\n",
       "distance_cluster_center_2                     0.050080\n",
       "pca_axis_2                                    0.046946\n",
       "scansWithoutRegistration                      0.039232\n",
       "pca_axis_1                                    0.033114\n",
       "quantityModifications                         0.029725\n",
       "quantityModificationsPerScannedLineItem       0.028974\n",
       "totalScanTimeInSeconds                        0.024746\n",
       "scannedLineItemsPerSecond                     0.023510\n",
       "lineItemVoids                                 0.021347\n",
       "scansWithoutRegistrationPerScannedLineItem    0.019014\n",
       "pricePerScannedLineItem                       0.017869\n",
       "lineItemVoidsPerPosition                      0.016745\n",
       "scansWithoutRegistrationPerEuro               0.015736\n",
       "quantityModificationsPerSecond                0.015469\n",
       "grandTotal                                    0.015296\n",
       "secondsPerEuro                                0.014301\n",
       "scansWithoutRegistrationPerSecond             0.012887\n",
       "valuePerSecond                                0.012819\n",
       "lineItemVoidsPerSecond                        0.011599\n",
       "quantityModificationsPerEuro                  0.008113\n",
       "lineItemVoidsPerEuro                          0.007829"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load data\n",
    "\n",
    "y = train['fraud']\n",
    "x = train.drop('fraud',axis=1)\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier(criterion = 'entropy')\n",
    "model.fit(x, y)\n",
    "\n",
    "pd.DataFrame(model.feature_importances_, list(x), columns =['Importance']).sort_values(by='Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying oversampling to dataset\n",
    "- Classical Oversampling\n",
    "- SMOTE Technique\n",
    "- ADASYN Technique\n",
    "\n",
    "Each one has a slightly different approach for generating synthetic instances\n",
    "- Simply duplicated fraud instances\n",
    "- ADASYN focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier\n",
    "- SMOTE will not make any distinction between easy and hard samples to be classified using the nearest neighbors rule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three cells only define the functions, actually appliing oversampling for subsequent steps can be down after the definitions\n",
    "\n",
    "\n",
    "Old comment of Jan:\n",
    "\n",
    "Only run one of the following three cells to apply a specific oversampling method!\n",
    "Attention!! If we use oversampling we have problems using k-fold cross validation. Since we have a faked test set. It would be better to oversample in every k-fold iteration. ALternatively we need to switch back to a fixed training, test split.  \n",
    "This is not implemented yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     887\n",
      "Name: fraud, dtype: int64\n",
      "0    0.500000\n",
      "1    0.249859\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# !pip install imblearn  # might be necessary for installation\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def randomOverSampling(train):\n",
    "    ros = RandomOverSampler(random_state=42, ratio = 0.5)\n",
    "    X_train_extended, Y_train_extended = ros.fit_resample(train.drop('fraud',axis=1), train['fraud'])\n",
    "\n",
    "    new_train = pd.DataFrame(X_train_extended, columns=train.drop('fraud',axis=1).columns) \n",
    "    new_train[\"fraud\"] = Y_train_extended\n",
    "    return new_train\n",
    "    \n",
    "randomOverSampling(train)\n",
    "\n",
    "print(randomOverSampling(train).fraud.value_counts())\n",
    "print(randomOverSampling(train).fraud.value_counts() / len(smoteOverSamling(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     887\n",
      "Name: fraud, dtype: int64\n",
      "0    0.666792\n",
      "1    0.333208\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def smoteOverSamling(train):\n",
    "    sm = SMOTE(random_state=42, k_neighbors = 3, ratio = 0.5)\n",
    "    X_train_extended, Y_train_extended = sm.fit_sample(train.drop('fraud',axis=1), train['fraud'])\n",
    "\n",
    "    new_train = pd.DataFrame(X_train_extended, columns=train.drop('fraud',axis=1).columns) \n",
    "    new_train [\"fraud\"] = Y_train_extended\n",
    "    return new_train\n",
    "    \n",
    "print(smoteOverSamling(train).fraud.value_counts())\n",
    "print(smoteOverSamling(train).fraud.value_counts() / len(smoteOverSamling(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1775\n",
      "1     861\n",
      "Name: fraud, dtype: int64\n",
      "0    0.944651\n",
      "1    0.458222\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "def adasynOverSamling(train):\n",
    "    ada = ADASYN(random_state=42, n_neighbors = 3, ratio = 0.5)\n",
    "    X_train_extended, Y_train_extended = ada.fit_resample(train.drop('fraud',axis=1), train['fraud'])\n",
    "\n",
    "    new_train = pd.DataFrame(X_train_extended, columns=train.drop('fraud',axis=1).columns) \n",
    "    new_train[\"fraud\"] = Y_train_extended\n",
    "    return new_train\n",
    "    \n",
    "print(adasynOverSamling(train).fraud.value_counts())\n",
    "print(adasynOverSamling(train).fraud.value_counts() / len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually apply one of these techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = smoteOverSamling(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm.classes import OneClassSVM\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.linear_model.ridge import RidgeClassifierCV\n",
    "from sklearn.linear_model.ridge import RidgeClassifier\n",
    "from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier\n",
    "from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
    "from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.mixture import DPGMM\n",
    "#from sklearn.mixture import GMM\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "#from sklearn.mixture import VBGMM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "model_tuning_factory = [\n",
    "    GridSearchCV(LogisticRegression(max_iter = 10000), \n",
    "             dict(# penalty = ['l1','l2'],  # automatic regularization  -> option 'l1' doesnt work with all solvers and leads to errors\n",
    "                 solver = ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "                 fit_intercept = [True, False]),\n",
    "                #  solver = ['lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "             cv = skf,\n",
    "             scoring = my_custom_score),\n",
    "    GridSearchCV(KNeighborsClassifier(), \n",
    "                 dict(n_neighbors = range(1,4),\n",
    "                      weights = ['uniform', 'distance']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(NearestCentroid(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(DecisionTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(ExtraTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(ExtraTreesClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                      # n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    GridSearchCV(RandomForestClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    GridSearchCV(BernoulliNB(),\n",
    "                 dict(binarize  = np.arange(0.0, 2.0, 0.1)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(GaussianNB(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(AdaBoostClassifier(),\n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(GradientBoostingClassifier(),\n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 #     learning_rate = np.arange(0.01, 1.0, 0.01)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),                     \n",
    "    GridSearchCV(BaggingClassifier(), \n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(Perceptron(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(LinearDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(QuadraticDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(SVC(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score)\n",
    "]       \n",
    "\n",
    "\n",
    "\n",
    "model_tuning_factory_subset = [\n",
    "    GridSearchCV(LogisticRegression(max_iter = 10000), \n",
    "                 dict(# penalty = ['l1','l2'],  # automatic regularization  -> option 'l1' doesnt work with all solvers and leads to errors\n",
    "                     solver = ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "                     fit_intercept = [True, False]),\n",
    "                    #  solver = ['lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(DecisionTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(ExtraTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),\n",
    "    GridSearchCV(ExtraTreesClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                      # n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    GridSearchCV(RandomForestClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    GridSearchCV(BernoulliNB(),\n",
    "                 dict(binarize  = np.arange(0.0, 2.0, 0.1)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(AdaBoostClassifier(),\n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(GradientBoostingClassifier(),\n",
    "                 dict(),\n",
    "                 #dict(n_estimators = range(1,150)),\n",
    "                 #     learning_rate = np.arange(0.01, 1.0, 0.01)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),                     \n",
    "    GridSearchCV(Perceptron(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    GridSearchCV(LinearDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score)\n",
    "]        \n",
    "                 \n",
    "                 \n",
    "iterations = 10                 \n",
    "               \n",
    "model_tuning_factory_randomized = [\n",
    "    RandomizedSearchCV(LogisticRegression(max_iter = 10000), \n",
    "                 dict(# penalty = ['l1','l2'],  # automatic regularization  -> option 'l1' doesnt work with all solvers and leads to errors\n",
    "                       solver = ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                       fit_intercept = [True, False]),\n",
    "                    #  solver = ['lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(KNeighborsClassifier(), \n",
    "                 dict(n_neighbors = range(1,4),\n",
    "                      weights = ['uniform', 'distance']),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(NearestCentroid(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    RandomizedSearchCV(DecisionTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(ExtraTreeClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini']),\n",
    "                     # max_depth = range(1,100)),\n",
    "                 #     max_leaf_nodes = range(2,100)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(ExtraTreesClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini'],\n",
    "                      n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score),    \n",
    "    RandomizedSearchCV(RandomForestClassifier(),\n",
    "                 dict(criterion = ['entropy', 'gini'],\n",
    "                      n_estimators  = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),    \n",
    "    RandomizedSearchCV(BernoulliNB(),\n",
    "                 dict(binarize  = np.arange(0.0, 1.0, 0.1)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations), \n",
    "    RandomizedSearchCV(GaussianNB(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score), \n",
    "    RandomizedSearchCV(AdaBoostClassifier(),\n",
    "                 dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                 dict(n_estimators = range(1,150),\n",
    "                      learning_rate = np.arange(0.01, 1.0, 0.01)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),                    \n",
    "    RandomizedSearchCV(BaggingClassifier(), \n",
    "                 dict(n_estimators = range(1,150)),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(Perceptron(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(LinearDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    RandomizedSearchCV(QuadraticDiscriminantAnalysis(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score,\n",
    "                 n_iter = iterations),\n",
    "    GridSearchCV(SVC(),\n",
    "                 dict(),\n",
    "                 cv = skf,\n",
    "                 scoring = my_custom_score)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    score = ((-25)*fp + (-5)*fn + 5*tp) / len(y_true)\n",
    "    return (score)\n",
    "\n",
    "my_custom_score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished LogisticRegression with No Oversampling and No Scaling and 1 features after 0.7 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 2 features after 1.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahuem\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished LogisticRegression with No Oversampling and No Scaling and 3 features after 2.44 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 4 features after 2.65 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 5 features after 3.15 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 6 features after 3.59 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 7 features after 3.35 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 8 features after 4.32 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 9 features after 4.34 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 10 features after 4.52 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 11 features after 4.58 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 12 features after 4.47 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 13 features after 4.92 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 14 features after 6.17 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 15 features after 6.98 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 16 features after 8.81 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 17 features after 10.36 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 18 features after 11.45 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 19 features after 18.97 seconds\n",
      "Finished LogisticRegression with No Oversampling and No Scaling and 20 features after 23.72 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 1 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 2 features after 1.15 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 3 features after 1.18 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 4 features after 1.19 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 5 features after 1.21 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 6 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 7 features after 1.23 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 8 features after 1.27 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 9 features after 1.28 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 10 features after 1.3 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 11 features after 1.3 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 12 features after 1.33 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 13 features after 1.35 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 14 features after 1.36 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 15 features after 1.38 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 16 features after 1.51 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 17 features after 1.54 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 18 features after 1.56 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 19 features after 1.6 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and No Scaling and 20 features after 1.61 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 1 features after 0.08 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 2 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 3 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 4 features after 0.06 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 5 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 6 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 7 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 8 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 9 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 10 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 11 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 12 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 13 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 14 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 15 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 16 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 17 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 18 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 19 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and No Scaling and 20 features after 0.05 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 1 features after 0.24 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 2 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 3 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 4 features after 0.24 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 5 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 6 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 7 features after 0.27 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 8 features after 0.27 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 9 features after 0.28 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 10 features after 0.29 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 11 features after 0.3 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 12 features after 0.31 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 13 features after 0.31 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 14 features after 0.32 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 15 features after 0.33 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 16 features after 0.35 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 17 features after 0.35 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 18 features after 0.37 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 19 features after 0.38 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and No Scaling and 20 features after 0.38 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 1 features after 0.16 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 2 features after 0.17 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 3 features after 0.17 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 4 features after 0.17 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 5 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 6 features after 0.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 7 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 8 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 9 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 10 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 11 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 12 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 13 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 14 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 15 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 16 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 17 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 18 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 19 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and No Scaling and 20 features after 0.18 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 1 features after 0.53 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 2 features after 0.56 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 3 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 4 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 5 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 6 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 7 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 8 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 9 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 10 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 11 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 12 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 13 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 14 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 15 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 16 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 17 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 18 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 19 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and No Scaling and 20 features after 0.57 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 1 features after 0.65 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 2 features after 0.71 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 3 features after 0.71 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 4 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 5 features after 0.79 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 6 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 7 features after 0.79 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 8 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 9 features after 0.82 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 10 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 11 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 12 features after 0.82 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 13 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 14 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 15 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 16 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 17 features after 0.88 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 18 features after 0.88 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 19 features after 0.87 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and No Scaling and 20 features after 0.86 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 1 features after 1.56 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 2 features after 1.58 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 3 features after 1.62 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 4 features after 1.66 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 5 features after 1.65 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 6 features after 1.66 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 7 features after 1.67 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 8 features after 1.68 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 9 features after 1.71 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 10 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 11 features after 1.76 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 12 features after 1.72 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 13 features after 1.76 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 14 features after 1.81 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 15 features after 1.76 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 16 features after 1.83 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 17 features after 1.8 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 18 features after 1.81 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 19 features after 1.84 seconds\n",
      "Finished BernoulliNB with No Oversampling and No Scaling and 20 features after 1.93 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 1 features after 0.04 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 2 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 3 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 4 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 5 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 6 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 7 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 8 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 9 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 10 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 11 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 12 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 13 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 14 features after 0.05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished GaussianNB with No Oversampling and No Scaling and 15 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 16 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 17 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 18 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 19 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and No Scaling and 20 features after 0.05 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 1 features after 2.82 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 2 features after 2.83 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 3 features after 2.87 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 4 features after 2.9 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 5 features after 2.87 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 6 features after 2.93 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 7 features after 2.92 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 8 features after 2.93 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 9 features after 2.93 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 10 features after 2.98 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 11 features after 2.99 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 12 features after 3.01 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 13 features after 3.04 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 14 features after 3.06 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 15 features after 3.08 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 16 features after 3.06 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 17 features after 3.04 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 18 features after 3.02 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 19 features after 3.02 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and No Scaling and 20 features after 2.98 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 1 features after 2.94 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 2 features after 3.12 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 3 features after 3.26 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 4 features after 3.39 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 5 features after 3.52 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 6 features after 3.58 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 7 features after 3.67 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 8 features after 3.63 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 9 features after 3.65 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 10 features after 3.7 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 11 features after 3.7 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 12 features after 3.78 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 13 features after 3.79 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 14 features after 3.85 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 15 features after 3.9 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 16 features after 3.84 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 17 features after 3.84 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 18 features after 3.8 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 19 features after 3.77 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and No Scaling and 20 features after 3.71 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 1 features after 0.11 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 2 features after 0.13 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 3 features after 0.15 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 4 features after 0.17 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 5 features after 0.19 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 6 features after 0.2 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 7 features after 0.22 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 8 features after 0.23 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 9 features after 0.23 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 10 features after 0.26 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 11 features after 0.27 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 12 features after 0.3 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 13 features after 0.32 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 14 features after 0.34 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 15 features after 0.36 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 16 features after 0.38 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 17 features after 0.39 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 18 features after 0.42 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 19 features after 0.47 seconds\n",
      "Finished BaggingClassifier with No Oversampling and No Scaling and 20 features after 0.48 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 1 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 2 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 3 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 4 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 5 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 6 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 7 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 8 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 9 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 10 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 11 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 12 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 13 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 14 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 15 features after 0.17 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 16 features after 0.12 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 17 features after 0.13 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 18 features after 0.14 seconds\n",
      "Finished Perceptron with No Oversampling and No Scaling and 19 features after 0.14 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Perceptron with No Oversampling and No Scaling and 20 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 1 features after 0.19 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 2 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 3 features after 0.18 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 4 features after 0.19 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 5 features after 0.26 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 6 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 7 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 8 features after 0.18 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 9 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 10 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 11 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 12 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 13 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 14 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 15 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 16 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 17 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 18 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 19 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and No Scaling and 20 features after 0.15 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 1 features after 0.04 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 2 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 3 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 4 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 5 features after 0.07 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 6 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 7 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 8 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 9 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 10 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 11 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 12 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 13 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 14 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 15 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 16 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 17 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 18 features after 0.1 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 19 features after 0.07 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and No Scaling and 20 features after 0.06 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 1 features after 0.14 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 2 features after 0.19 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 3 features after 2.49 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 4 features after 2.52 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 5 features after 2.57 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 6 features after 2.62 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 7 features after 2.64 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 8 features after 2.69 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 9 features after 2.77 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 10 features after 2.85 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 11 features after 2.87 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 12 features after 2.9 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 13 features after 2.94 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 14 features after 2.98 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 15 features after 3.02 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 16 features after 3.13 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 17 features after 3.2 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 18 features after 3.24 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 19 features after 3.31 seconds\n",
      "Finished SVC with No Oversampling and No Scaling and 20 features after 3.36 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 1 features after 0.7 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 2 features after 1.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahuem\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 3 features after 3.11 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 4 features after 2.73 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 5 features after 3.13 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 6 features after 3.81 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 7 features after 3.79 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 8 features after 3.91 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 9 features after 4.39 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 10 features after 4.86 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 11 features after 4.6 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 12 features after 4.87 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 13 features after 4.98 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 14 features after 5.41 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 15 features after 6.09 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 16 features after 9.41 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 17 features after 11.03 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 18 features after 11.8 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 19 features after 18.92 seconds\n",
      "Finished LogisticRegression with No Oversampling and MinMaxScaler and 20 features after 20.87 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 1 features after 1.23 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 2 features after 1.15 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 3 features after 1.18 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 4 features after 1.2 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 5 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 6 features after 1.23 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 7 features after 1.25 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 8 features after 1.25 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 9 features after 1.28 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 10 features after 1.3 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 11 features after 1.3 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 12 features after 1.31 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 13 features after 1.34 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 14 features after 1.37 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 15 features after 1.38 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 16 features after 1.52 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 17 features after 1.55 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 18 features after 1.57 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 19 features after 1.59 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and MinMaxScaler and 20 features after 1.61 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 1 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 2 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 3 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 4 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 5 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 6 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 7 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 8 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 9 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 10 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 11 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 12 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 13 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 14 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 15 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 16 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 17 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 18 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 19 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and MinMaxScaler and 20 features after 0.05 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 1 features after 0.24 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 2 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 3 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 4 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 5 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 6 features after 0.26 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 7 features after 0.26 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 8 features after 0.26 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 9 features after 0.29 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 10 features after 0.29 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 11 features after 0.29 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 12 features after 0.31 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 13 features after 0.32 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 14 features after 0.32 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 15 features after 0.33 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 16 features after 0.34 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 17 features after 0.35 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 18 features after 0.36 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 19 features after 0.38 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and MinMaxScaler and 20 features after 0.38 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 1 features after 0.16 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 2 features after 0.17 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 3 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 4 features after 0.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 5 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 6 features after 0.17 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 7 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 8 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 9 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 10 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 11 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 12 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 13 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 14 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 15 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 16 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 17 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 18 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 19 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and MinMaxScaler and 20 features after 0.18 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 1 features after 0.61 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 2 features after 0.56 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 3 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 4 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 5 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 6 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 7 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 8 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 9 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 10 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 11 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 12 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 13 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 14 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 15 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 16 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 17 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 18 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 19 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and MinMaxScaler and 20 features after 0.57 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 1 features after 0.79 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 2 features after 0.7 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 3 features after 0.71 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 4 features after 0.76 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 5 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 6 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 7 features after 0.78 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 8 features after 0.78 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 9 features after 0.81 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 10 features after 0.82 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 11 features after 0.85 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 12 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 13 features after 0.84 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 14 features after 0.84 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 15 features after 0.82 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 16 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 17 features after 0.87 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 18 features after 0.88 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 19 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and MinMaxScaler and 20 features after 0.86 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 1 features after 1.59 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 2 features after 1.56 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 3 features after 1.67 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 4 features after 1.69 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 5 features after 1.66 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 6 features after 1.74 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 7 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 8 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 9 features after 1.84 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 10 features after 1.71 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 11 features after 1.85 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 12 features after 1.75 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 13 features after 1.76 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 14 features after 1.77 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 15 features after 1.79 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 16 features after 1.79 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 17 features after 1.79 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 18 features after 1.89 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 19 features after 1.88 seconds\n",
      "Finished BernoulliNB with No Oversampling and MinMaxScaler and 20 features after 2.11 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 1 features after 0.04 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 2 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 3 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 4 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 5 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 6 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 7 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 8 features after 0.05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 9 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 10 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 11 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 12 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 13 features after 0.06 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 14 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 15 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 16 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 17 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 18 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 19 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and MinMaxScaler and 20 features after 0.06 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 1 features after 2.88 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 2 features after 2.85 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 3 features after 2.87 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 4 features after 2.93 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 5 features after 2.93 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 6 features after 2.95 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 7 features after 2.97 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 8 features after 2.96 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 9 features after 2.99 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 10 features after 3.03 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 11 features after 3.02 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 12 features after 3.06 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 13 features after 3.11 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 14 features after 3.12 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 15 features after 3.11 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 16 features after 3.1 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 17 features after 3.09 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 18 features after 3.05 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 19 features after 3.14 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and MinMaxScaler and 20 features after 3.03 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 1 features after 2.91 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 2 features after 3.14 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 3 features after 3.3 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 4 features after 3.38 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 5 features after 3.44 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 6 features after 3.51 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 7 features after 3.57 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 8 features after 3.59 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 9 features after 3.62 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 10 features after 3.71 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 11 features after 3.75 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 12 features after 3.72 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 13 features after 3.76 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 14 features after 3.75 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 15 features after 3.77 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 16 features after 3.79 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 17 features after 3.79 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 18 features after 3.8 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 19 features after 3.75 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and MinMaxScaler and 20 features after 3.67 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 1 features after 0.11 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 2 features after 0.13 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 3 features after 0.15 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 4 features after 0.17 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 5 features after 0.19 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 6 features after 0.2 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 7 features after 0.22 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 8 features after 0.23 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 9 features after 0.23 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 10 features after 0.25 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 11 features after 0.27 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 12 features after 0.3 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 13 features after 0.31 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 14 features after 0.34 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 15 features after 0.35 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 16 features after 0.38 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 17 features after 0.4 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 18 features after 0.42 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 19 features after 0.48 seconds\n",
      "Finished BaggingClassifier with No Oversampling and MinMaxScaler and 20 features after 0.48 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 1 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 2 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 3 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 4 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 5 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 6 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 7 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 8 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 9 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 10 features after 0.11 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Perceptron with No Oversampling and MinMaxScaler and 11 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 12 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 13 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 14 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 15 features after 0.12 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 16 features after 0.12 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 17 features after 0.15 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 18 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 19 features after 0.13 seconds\n",
      "Finished Perceptron with No Oversampling and MinMaxScaler and 20 features after 0.11 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 1 features after 0.14 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 2 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 3 features after 0.19 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 4 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 5 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 6 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 7 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 8 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 9 features after 0.18 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 10 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 11 features after 0.19 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 12 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 13 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 14 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 15 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 16 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 17 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 18 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 19 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and MinMaxScaler and 20 features after 0.17 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 1 features after 0.11 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 2 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 3 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 4 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 5 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 6 features after 0.08 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 7 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 8 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 9 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 10 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 11 features after 0.07 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 12 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 13 features after 0.11 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 14 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 15 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 16 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 17 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 18 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 19 features after 0.08 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and MinMaxScaler and 20 features after 0.07 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 1 features after 0.13 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 2 features after 0.19 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 3 features after 2.47 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 4 features after 2.5 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 5 features after 2.55 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 6 features after 2.62 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 7 features after 2.65 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 8 features after 2.69 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 9 features after 2.79 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 10 features after 2.84 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 11 features after 2.87 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 12 features after 2.9 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 13 features after 2.92 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 14 features after 2.96 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 15 features after 3.02 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 16 features after 3.16 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 17 features after 3.16 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 18 features after 3.22 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 19 features after 3.29 seconds\n",
      "Finished SVC with No Oversampling and MinMaxScaler and 20 features after 3.34 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 1 features after 0.7 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 2 features after 1.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahuem\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished LogisticRegression with No Oversampling and StandardScaler and 3 features after 2.55 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 4 features after 2.44 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 5 features after 2.98 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 6 features after 3.53 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 7 features after 3.42 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 8 features after 3.6 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 9 features after 4.25 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 10 features after 4.43 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 11 features after 4.9 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 12 features after 5.65 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 13 features after 4.89 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 14 features after 5.44 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 15 features after 6.24 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 16 features after 8.51 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 17 features after 10.65 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 18 features after 11.4 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 19 features after 19.43 seconds\n",
      "Finished LogisticRegression with No Oversampling and StandardScaler and 20 features after 21.6 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 1 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 2 features after 1.15 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 3 features after 1.18 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 4 features after 1.2 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 5 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 6 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 7 features after 1.24 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 8 features after 1.26 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 9 features after 1.27 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 10 features after 1.29 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 11 features after 1.32 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 12 features after 1.34 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 13 features after 1.34 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 14 features after 1.37 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 15 features after 1.39 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 16 features after 1.52 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 17 features after 1.55 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 18 features after 1.57 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 19 features after 1.59 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and StandardScaler and 20 features after 1.63 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 1 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 2 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 3 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 4 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 5 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 6 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 7 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 8 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 9 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 10 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 11 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 12 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 13 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 14 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 15 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 16 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 17 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 18 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 19 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and StandardScaler and 20 features after 0.05 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 1 features after 0.24 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 2 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 3 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 4 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 5 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 6 features after 0.26 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 7 features after 0.27 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 8 features after 0.27 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 9 features after 0.27 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 10 features after 0.29 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 11 features after 0.3 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 12 features after 0.3 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 13 features after 0.31 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 14 features after 0.32 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 15 features after 0.33 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 16 features after 0.34 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 17 features after 0.35 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 18 features after 0.36 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 19 features after 0.38 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and StandardScaler and 20 features after 0.39 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 1 features after 0.16 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 2 features after 0.17 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 3 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 4 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 5 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 6 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 7 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 8 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 9 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 10 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 11 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 12 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 13 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 14 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 15 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 16 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 17 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 18 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 19 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and StandardScaler and 20 features after 0.18 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 1 features after 0.54 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 2 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 3 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 4 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 5 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 6 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 7 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 8 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 9 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 10 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 11 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 12 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 13 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 14 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 15 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 16 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 17 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 18 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 19 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and StandardScaler and 20 features after 0.57 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 1 features after 0.79 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 2 features after 0.71 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 3 features after 0.71 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 4 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 5 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 6 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 7 features after 0.78 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 8 features after 0.78 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 9 features after 0.82 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 10 features after 0.82 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 11 features after 0.84 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 12 features after 0.85 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 13 features after 0.85 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 14 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 15 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 16 features after 0.87 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 17 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 18 features after 0.87 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 19 features after 0.88 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and StandardScaler and 20 features after 0.86 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 1 features after 1.63 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 2 features after 1.57 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 3 features after 1.65 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 4 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 5 features after 1.68 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 6 features after 1.68 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 7 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 8 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 9 features after 1.72 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 10 features after 1.73 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 11 features after 1.74 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 12 features after 1.89 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 13 features after 1.77 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 14 features after 1.79 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 15 features after 1.78 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 16 features after 1.8 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 17 features after 1.82 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 18 features after 1.82 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 19 features after 1.87 seconds\n",
      "Finished BernoulliNB with No Oversampling and StandardScaler and 20 features after 2.04 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 1 features after 0.04 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 2 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 3 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 4 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 5 features after 0.05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished GaussianNB with No Oversampling and StandardScaler and 6 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 7 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 8 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 9 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 10 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 11 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 12 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 13 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 14 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 15 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 16 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 17 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 18 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 19 features after 0.06 seconds\n",
      "Finished GaussianNB with No Oversampling and StandardScaler and 20 features after 0.05 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 1 features after 2.91 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 2 features after 2.88 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 3 features after 2.93 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 4 features after 2.94 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 5 features after 2.95 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 6 features after 3.03 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 7 features after 2.99 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 8 features after 3.0 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 9 features after 2.98 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 10 features after 3.03 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 11 features after 3.0 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 12 features after 3.05 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 13 features after 3.1 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 14 features after 3.12 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 15 features after 3.15 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 16 features after 3.1 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 17 features after 3.07 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 18 features after 3.07 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 19 features after 3.07 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and StandardScaler and 20 features after 3.03 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 1 features after 2.95 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 2 features after 3.15 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 3 features after 3.3 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 4 features after 3.4 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 5 features after 3.43 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 6 features after 3.5 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 7 features after 3.57 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 8 features after 3.58 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 9 features after 3.6 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 10 features after 3.6 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 11 features after 3.73 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 12 features after 3.73 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 13 features after 3.74 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 14 features after 3.74 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 15 features after 3.77 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 16 features after 3.8 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 17 features after 3.79 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 18 features after 3.79 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 19 features after 3.74 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and StandardScaler and 20 features after 3.67 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 1 features after 0.11 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 2 features after 0.13 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 3 features after 0.15 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 4 features after 0.18 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 5 features after 0.19 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 6 features after 0.2 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 7 features after 0.22 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 8 features after 0.22 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 9 features after 0.24 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 10 features after 0.25 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 11 features after 0.27 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 12 features after 0.29 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 13 features after 0.39 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 14 features after 0.34 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 15 features after 0.35 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 16 features after 0.38 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 17 features after 0.4 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 18 features after 0.42 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 19 features after 0.47 seconds\n",
      "Finished BaggingClassifier with No Oversampling and StandardScaler and 20 features after 0.47 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 1 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 2 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 3 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 4 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 5 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 6 features after 0.11 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Perceptron with No Oversampling and StandardScaler and 7 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 8 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 9 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 10 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 11 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 12 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 13 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 14 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 15 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 16 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 17 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 18 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 19 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and StandardScaler and 20 features after 0.11 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 1 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 2 features after 0.14 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 3 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 4 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 5 features after 0.24 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 6 features after 0.18 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 7 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 8 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 9 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 10 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 11 features after 0.25 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 12 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 13 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 14 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 15 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 16 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 17 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 18 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 19 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and StandardScaler and 20 features after 0.16 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 1 features after 0.04 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 2 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 3 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 4 features after 0.07 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 5 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 6 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 7 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 8 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 9 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 10 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 11 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 12 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 13 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 14 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 15 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 16 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 17 features after 0.07 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 18 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 19 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and StandardScaler and 20 features after 0.06 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 1 features after 0.14 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 2 features after 0.19 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 3 features after 2.46 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 4 features after 2.5 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 5 features after 2.54 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 6 features after 2.6 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 7 features after 2.63 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 8 features after 2.7 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 9 features after 2.79 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 10 features after 2.84 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 11 features after 2.87 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 12 features after 2.9 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 13 features after 2.94 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 14 features after 2.97 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 15 features after 3.01 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 16 features after 3.12 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 17 features after 3.16 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 18 features after 3.22 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 19 features after 3.31 seconds\n",
      "Finished SVC with No Oversampling and StandardScaler and 20 features after 3.35 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 1 features after 0.7 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 2 features after 1.68 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 3 features after 1.22 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 4 features after 1.51 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 5 features after 1.7 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 6 features after 1.65 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 7 features after 3.47 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished LogisticRegression with No Oversampling and LogScaler and 8 features after 3.96 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 9 features after 3.83 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 10 features after 5.48 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 11 features after 5.69 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 12 features after 8.53 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 13 features after 9.24 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 14 features after 9.09 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 15 features after 8.99 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 16 features after 9.7 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 17 features after 11.36 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 18 features after 11.95 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 19 features after 19.94 seconds\n",
      "Finished LogisticRegression with No Oversampling and LogScaler and 20 features after 22.4 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 1 features after 1.24 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 2 features after 1.16 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 3 features after 1.22 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 4 features after 1.23 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 5 features after 1.24 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 6 features after 1.26 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 7 features after 1.23 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 8 features after 1.32 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 9 features after 1.35 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 10 features after 1.38 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 11 features after 1.41 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 12 features after 1.43 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 13 features after 1.45 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 14 features after 1.49 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 15 features after 1.51 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 16 features after 1.53 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 17 features after 1.54 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 18 features after 1.59 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 19 features after 1.6 seconds\n",
      "Finished KNeighborsClassifier with No Oversampling and LogScaler and 20 features after 1.62 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 1 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 2 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 3 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 4 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 5 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 6 features after 0.04 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 7 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 8 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 9 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 10 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 11 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 12 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 13 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 14 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 15 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 16 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 17 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 18 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 19 features after 0.05 seconds\n",
      "Finished NearestCentroid with No Oversampling and LogScaler and 20 features after 0.09 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 1 features after 0.24 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 2 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 3 features after 0.23 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 4 features after 0.24 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 5 features after 0.25 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 6 features after 0.26 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 7 features after 0.28 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 8 features after 0.28 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 9 features after 0.28 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 10 features after 0.29 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 11 features after 0.3 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 12 features after 0.31 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 13 features after 0.32 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 14 features after 0.33 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 15 features after 0.33 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 16 features after 0.35 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 17 features after 0.35 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 18 features after 0.37 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 19 features after 0.38 seconds\n",
      "Finished DecisionTreeClassifier with No Oversampling and LogScaler and 20 features after 0.38 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 1 features after 0.17 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 2 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 3 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 4 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 5 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 6 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 7 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 8 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 9 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 10 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 11 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 12 features after 0.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 13 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 14 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 15 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 16 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 17 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 18 features after 0.18 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 19 features after 0.19 seconds\n",
      "Finished ExtraTreeClassifier with No Oversampling and LogScaler and 20 features after 0.18 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 1 features after 0.54 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 2 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 3 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 4 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 5 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 6 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 7 features after 0.61 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 8 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 9 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 10 features after 0.6 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 11 features after 0.61 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 12 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 13 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 14 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 15 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 16 features after 0.59 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 17 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 18 features after 0.57 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 19 features after 0.58 seconds\n",
      "Finished ExtraTreesClassifier with No Oversampling and LogScaler and 20 features after 0.58 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 1 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 2 features after 0.68 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 3 features after 0.73 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 4 features after 0.77 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 5 features after 0.78 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 6 features after 0.78 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 7 features after 0.79 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 8 features after 0.79 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 9 features after 0.85 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 10 features after 0.87 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 11 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 12 features after 0.84 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 13 features after 0.85 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 14 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 15 features after 0.83 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 16 features after 0.91 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 17 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 18 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 19 features after 0.89 seconds\n",
      "Finished RandomForestClassifier with No Oversampling and LogScaler and 20 features after 0.88 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 1 features after 2.02 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 2 features after 1.64 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 3 features after 1.62 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 4 features after 1.7 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 5 features after 1.78 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 6 features after 1.75 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 7 features after 1.73 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 8 features after 1.74 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 9 features after 1.73 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 10 features after 1.85 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 11 features after 1.76 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 12 features after 1.82 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 13 features after 1.8 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 14 features after 1.79 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 15 features after 1.8 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 16 features after 1.82 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 17 features after 1.83 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 18 features after 1.86 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 19 features after 1.93 seconds\n",
      "Finished BernoulliNB with No Oversampling and LogScaler and 20 features after 2.24 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 1 features after 0.04 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 2 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 3 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 4 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 5 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 6 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 7 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 8 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 9 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 10 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 11 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 12 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 13 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 14 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 15 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 16 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 17 features after 0.06 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 18 features after 0.05 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 19 features after 0.06 seconds\n",
      "Finished GaussianNB with No Oversampling and LogScaler and 20 features after 0.06 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 1 features after 2.98 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 2 features after 2.96 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 3 features after 2.98 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 4 features after 2.96 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 5 features after 2.98 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 6 features after 3.02 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 7 features after 3.02 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 8 features after 3.11 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 9 features after 3.18 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 10 features after 3.14 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 11 features after 3.11 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 12 features after 3.15 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 13 features after 3.14 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 14 features after 3.17 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 15 features after 3.17 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 16 features after 3.14 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 17 features after 3.12 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 18 features after 3.12 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 19 features after 3.11 seconds\n",
      "Finished AdaBoostClassifier with No Oversampling and LogScaler and 20 features after 3.06 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 1 features after 3.0 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 2 features after 3.17 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 3 features after 3.33 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 4 features after 3.46 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 5 features after 3.45 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 6 features after 3.54 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 7 features after 3.64 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 8 features after 3.69 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 9 features after 3.7 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 10 features after 3.71 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 11 features after 3.79 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 12 features after 3.74 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 13 features after 3.78 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 14 features after 3.8 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 15 features after 3.8 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 16 features after 3.83 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 17 features after 3.86 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 18 features after 3.86 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 19 features after 3.78 seconds\n",
      "Finished GradientBoostingClassifier with No Oversampling and LogScaler and 20 features after 3.68 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 1 features after 0.11 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 2 features after 0.13 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 3 features after 0.16 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 4 features after 0.17 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 5 features after 0.18 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 6 features after 0.19 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 7 features after 0.22 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 8 features after 0.24 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 9 features after 0.25 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 10 features after 0.27 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 11 features after 0.28 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 12 features after 0.3 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 13 features after 0.32 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 14 features after 0.34 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 15 features after 0.36 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 16 features after 0.37 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 17 features after 0.39 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 18 features after 0.42 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 19 features after 0.48 seconds\n",
      "Finished BaggingClassifier with No Oversampling and LogScaler and 20 features after 0.47 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 1 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 2 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 3 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 4 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 5 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 6 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 7 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 8 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 9 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 10 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 11 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 12 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 13 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 14 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 15 features after 0.13 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 16 features after 0.12 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 17 features after 0.11 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 18 features after 0.1 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 19 features after 0.13 seconds\n",
      "Finished Perceptron with No Oversampling and LogScaler and 20 features after 0.12 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 1 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 2 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 3 features after 0.18 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 4 features after 0.15 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 5 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 6 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 7 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 8 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 9 features after 0.22 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 10 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 11 features after 0.15 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 12 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 13 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 14 features after 0.2 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 15 features after 0.3 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 16 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 17 features after 0.17 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 18 features after 0.16 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 19 features after 0.18 seconds\n",
      "Finished LinearDiscriminantAnalysis with No Oversampling and LogScaler and 20 features after 0.18 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 1 features after 0.04 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 2 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 3 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 4 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 5 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 6 features after 0.1 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 7 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 8 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 9 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 10 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 11 features after 0.05 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 12 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 13 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 14 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 15 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 16 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 17 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 18 features after 0.07 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 19 features after 0.06 seconds\n",
      "Finished QuadraticDiscriminantAnalysis with No Oversampling and LogScaler and 20 features after 0.06 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 1 features after 0.13 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 2 features after 0.19 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 3 features after 0.45 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 4 features after 0.39 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 5 features after 0.38 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 6 features after 0.36 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 7 features after 2.63 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 8 features after 2.72 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 9 features after 2.76 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 10 features after 2.82 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 11 features after 2.88 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 12 features after 2.92 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 13 features after 2.97 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 14 features after 3.02 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 15 features after 3.07 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 16 features after 3.14 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 17 features after 3.2 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 18 features after 3.24 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 19 features after 3.32 seconds\n",
      "Finished SVC with No Oversampling and LogScaler and 20 features after 3.36 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling Strategy</th>\n",
       "      <th>Data Preparation</th>\n",
       "      <th>Feature Count</th>\n",
       "      <th>Feature Selection Technique</th>\n",
       "      <th>Features</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Monetary Value Per Instance - Mean</th>\n",
       "      <th>Monetary Value Per Instance - Standard Deviation</th>\n",
       "      <th>Raw Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120368</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120368</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120368</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.121215</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.138371</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.138371</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.138371</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>0.084027</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.117084</td>\n",
       "      <td>0.121028</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.117084</td>\n",
       "      <td>0.121028</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.111762</td>\n",
       "      <td>0.137173</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.125820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.100420</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.108791</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.180599</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.180599</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.162452</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.092775</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.105831</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.106390</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.082368</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.120123</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.106390</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.098423</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.154678</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.157366</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.073999</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.116777</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.160232</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.160232</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.119992</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.110248</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.160232</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.148369</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.093820</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153697</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153697</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153253</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153697</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.118830</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.147274</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.147274</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.147274</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.089208</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.116007</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.128960</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.149659</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.158264</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.088130</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.121912</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.123550</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.135525</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.126292</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.979244</td>\n",
       "      <td>1.219465</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.987227</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.987227</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.987227</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.021820</td>\n",
       "      <td>1.758131</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.027142</td>\n",
       "      <td>0.374191</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItemsPerSecond]</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>-1.043108</td>\n",
       "      <td>0.334697</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.056413</td>\n",
       "      <td>0.306418</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItemsPerSecond]</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>-1.189462</td>\n",
       "      <td>0.304893</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.287919</td>\n",
       "      <td>0.398643</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.303885</td>\n",
       "      <td>0.361401</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.303885</td>\n",
       "      <td>0.361401</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.303885</td>\n",
       "      <td>0.361401</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.327834</td>\n",
       "      <td>0.385513</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.327834</td>\n",
       "      <td>0.351853</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>-1.330495</td>\n",
       "      <td>0.382551</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.333156</td>\n",
       "      <td>0.359628</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.386376</td>\n",
       "      <td>0.335402</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.466205</td>\n",
       "      <td>2.617490</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.466205</td>\n",
       "      <td>2.617490</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.466205</td>\n",
       "      <td>2.617490</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.490154</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.490154</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.490154</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.548696</td>\n",
       "      <td>0.534504</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.564662</td>\n",
       "      <td>0.496072</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.591272</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.599255</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.628526</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.628526</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.628526</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.817456</td>\n",
       "      <td>0.475335</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.822778</td>\n",
       "      <td>0.398985</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.868015</td>\n",
       "      <td>0.432081</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.868015</td>\n",
       "      <td>0.435536</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.875998</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.875998</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.875998</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.969133</td>\n",
       "      <td>0.441033</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.998403</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.998403</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.998403</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.009047</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.009047</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.009047</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.048962</td>\n",
       "      <td>0.480463</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.086216</td>\n",
       "      <td>0.503074</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.195317</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.195317</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.195317</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.421205</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.277807</td>\n",
       "      <td>0.480363</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.280468</td>\n",
       "      <td>0.383766</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.280468</td>\n",
       "      <td>0.383766</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.280468</td>\n",
       "      <td>0.383766</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.339010</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.339010</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.339010</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.344332</td>\n",
       "      <td>0.574415</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.344332</td>\n",
       "      <td>0.574415</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.344332</td>\n",
       "      <td>0.574415</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.357637</td>\n",
       "      <td>0.452316</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.424162</td>\n",
       "      <td>0.366827</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.450772</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.450772</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.450772</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.496009</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.496009</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.496009</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.676956</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.676956</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.676956</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.788717</td>\n",
       "      <td>0.432177</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.249069</td>\n",
       "      <td>0.700153</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.249069</td>\n",
       "      <td>0.700153</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.249069</td>\n",
       "      <td>0.700153</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.400745</td>\n",
       "      <td>0.469608</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.400745</td>\n",
       "      <td>0.462822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.467270</td>\n",
       "      <td>0.531802</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.706759</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.706759</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.706759</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.111229</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.111229</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.111229</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.132517</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.132517</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.132517</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.177754</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.177754</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.177754</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.204364</td>\n",
       "      <td>0.487839</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.683342</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.683342</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.683342</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.709952</td>\n",
       "      <td>0.394694</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.749867</td>\n",
       "      <td>0.412888</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.843002</td>\n",
       "      <td>0.431181</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.962746</td>\n",
       "      <td>0.415310</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.109101</td>\n",
       "      <td>0.429031</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.394891</td>\n",
       "      <td>0.676389</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.394891</td>\n",
       "      <td>0.676389</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.421501</td>\n",
       "      <td>0.681185</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.421501</td>\n",
       "      <td>0.681185</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model Oversampling Strategy Data Preparation Feature Count Feature Selection Technique                                           Features                              Optimal Parameters  Monetary Value Per Instance - Mean  Monetary Value Per Instance - Standard Deviation                                          Raw Model\n",
       "1909             AdaBoostClassifier       No Oversampling        LogScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "319              AdaBoostClassifier       No Oversampling       No Scaling             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "849              AdaBoostClassifier       No Oversampling     MinMaxScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1379             AdaBoostClassifier       No Oversampling   StandardScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "317              AdaBoostClassifier       No Oversampling       No Scaling             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "847              AdaBoostClassifier       No Oversampling     MinMaxScaler             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1907             AdaBoostClassifier       No Oversampling        LogScaler             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1377             AdaBoostClassifier       No Oversampling   StandardScaler             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "24               LogisticRegression       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "28               LogisticRegression       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "554              LogisticRegression       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1088             LogisticRegression       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "558              LogisticRegression       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1084             LogisticRegression       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1612             LogisticRegression       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.162320                                          0.119850  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1090             LogisticRegression       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.156998                                          0.120305  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "548              LogisticRegression       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "550              LogisticRegression       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1078             LogisticRegression       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "552              LogisticRegression       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1080             LogisticRegression       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1082             LogisticRegression       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1086             LogisticRegression       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.120368  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "30               LogisticRegression       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.156998                                          0.120305  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1076             LogisticRegression       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "546              LogisticRegression       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "556              LogisticRegression       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.120368  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "26               LogisticRegression       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.120368  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "20               LogisticRegression       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "16               LogisticRegression       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "560              LogisticRegression       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.156998                                          0.120305  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "18               LogisticRegression       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "22               LogisticRegression       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "32               LogisticRegression       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.134489  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1092             LogisticRegression       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.134489  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "562              LogisticRegression       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.134489  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1610             LogisticRegression       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.121215  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "570              LogisticRegression       No Oversampling     MinMaxScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1630             LogisticRegression       No Oversampling        LogScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1629             LogisticRegression       No Oversampling        LogScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1628             LogisticRegression       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1614             LogisticRegression       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "569              LogisticRegression       No Oversampling     MinMaxScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "568              LogisticRegression       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1098             LogisticRegression       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1099             LogisticRegression       No Oversampling   StandardScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "39               LogisticRegression       No Oversampling       No Scaling            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "38               LogisticRegression       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "40               LogisticRegression       No Oversampling       No Scaling            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1100             LogisticRegression       No Oversampling   StandardScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1094             LogisticRegression       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "566              LogisticRegression       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1096             LogisticRegression       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1622             LogisticRegression       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1624             LogisticRegression       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1626             LogisticRegression       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "564              LogisticRegression       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "36               LogisticRegression       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "34               LogisticRegression       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1616             LogisticRegression       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.138371                                          0.118278  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1618             LogisticRegression       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.138371                                          0.118278  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1620             LogisticRegression       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.138371                                          0.118278  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1773           ExtraTreesClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.119745                                          0.084027  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1951     GradientBoostingClassifier       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.117084                                          0.121028  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1953     GradientBoostingClassifier       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                            0.117084                                          0.121028  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1961     GradientBoostingClassifier       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.111762                                          0.137173  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "365      GradientBoostingClassifier       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1425     GradientBoostingClassifier       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "863              AdaBoostClassifier       No Oversampling     MinMaxScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1920             AdaBoostClassifier       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.125820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1393             AdaBoostClassifier       No Oversampling   StandardScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1923             AdaBoostClassifier       No Oversampling        LogScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "333              AdaBoostClassifier       No Oversampling       No Scaling            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1957     GradientBoostingClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "895      GradientBoostingClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1962     GradientBoostingClassifier       No Oversampling        LogScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.103779                                          0.147455  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "713            ExtraTreesClassifier       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.103779                                          0.100420  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1432     GradientBoostingClassifier       No Oversampling   StandardScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.103779                                          0.147455  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1921             AdaBoostClassifier       No Oversampling        LogScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1391             AdaBoostClassifier       No Oversampling   StandardScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1385             AdaBoostClassifier       No Oversampling   StandardScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1915             AdaBoostClassifier       No Oversampling        LogScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "855              AdaBoostClassifier       No Oversampling     MinMaxScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "331              AdaBoostClassifier       No Oversampling       No Scaling            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "861              AdaBoostClassifier       No Oversampling     MinMaxScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "325              AdaBoostClassifier       No Oversampling       No Scaling            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1966     GradientBoostingClassifier       No Oversampling        LogScaler            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1240           ExtraTreesClassifier       No Oversampling   StandardScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.098457                                          0.108791  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "376      GradientBoostingClassifier       No Oversampling       No Scaling            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "906      GradientBoostingClassifier       No Oversampling     MinMaxScaler            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1436     GradientBoostingClassifier       No Oversampling   StandardScaler            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "912      GradientBoostingClassifier       No Oversampling     MinMaxScaler            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1426     GradientBoostingClassifier       No Oversampling   StandardScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.093135                                          0.180599  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "910      GradientBoostingClassifier       No Oversampling     MinMaxScaler            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1440     GradientBoostingClassifier       No Oversampling   StandardScaler            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1442     GradientBoostingClassifier       No Oversampling   StandardScaler            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1972     GradientBoostingClassifier       No Oversampling        LogScaler            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1970     GradientBoostingClassifier       No Oversampling        LogScaler            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1956     GradientBoostingClassifier       No Oversampling        LogScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.093135                                          0.180599  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "380      GradientBoostingClassifier       No Oversampling       No Scaling            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1959     GradientBoostingClassifier       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "857              AdaBoostClassifier       No Oversampling     MinMaxScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "372      GradientBoostingClassifier       No Oversampling       No Scaling            13                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.162452  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1963     GradientBoostingClassifier       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1608             LogisticRegression       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.090474                                          0.162155  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1964     GradientBoostingClassifier       No Oversampling        LogScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "320              AdaBoostClassifier       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.127099  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1387             AdaBoostClassifier       No Oversampling   StandardScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "904      GradientBoostingClassifier       No Oversampling     MinMaxScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1766           ExtraTreesClassifier       No Oversampling        LogScaler             7                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                           {'criterion': 'gini'}                            0.090474                                          0.092775  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1389             AdaBoostClassifier       No Oversampling   StandardScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "850              AdaBoostClassifier       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.127099  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1917             AdaBoostClassifier       No Oversampling        LogScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "374      GradientBoostingClassifier       No Oversampling       No Scaling            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1380             AdaBoostClassifier       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.127099  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1919             AdaBoostClassifier       No Oversampling        LogScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "327              AdaBoostClassifier       No Oversampling       No Scaling            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "329              AdaBoostClassifier       No Oversampling       No Scaling            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1914             AdaBoostClassifier       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.105831  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1434     GradientBoostingClassifier       No Oversampling   StandardScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "859              AdaBoostClassifier       No Oversampling     MinMaxScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "851              AdaBoostClassifier       No Oversampling     MinMaxScaler             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1912             AdaBoostClassifier       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                            0.087813                                          0.106390  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1911             AdaBoostClassifier       No Oversampling        LogScaler             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1381             AdaBoostClassifier       No Oversampling   StandardScaler             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "710            ExtraTreesClassifier       No Oversampling     MinMaxScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                           {'criterion': 'gini'}                            0.087813                                          0.082368  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "180            ExtraTreesClassifier       No Oversampling       No Scaling             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.087813                                          0.120123  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "321              AdaBoostClassifier       No Oversampling       No Scaling             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1910             AdaBoostClassifier       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.106390  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "711            ExtraTreesClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.085152                                          0.098423  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "379      GradientBoostingClassifier       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.152815  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "368      GradientBoostingClassifier       No Oversampling       No Scaling            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.154678  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1969     GradientBoostingClassifier       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.157366  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1439     GradientBoostingClassifier       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.152815  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1236           ExtraTreesClassifier       No Oversampling   StandardScaler             7                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                        {'criterion': 'entropy'}                            0.085152                                          0.073999  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "909      GradientBoostingClassifier       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.152815  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1423     GradientBoostingClassifier       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.152141  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1913             AdaBoostClassifier       No Oversampling        LogScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1383             AdaBoostClassifier       No Oversampling   StandardScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "853              AdaBoostClassifier       No Oversampling     MinMaxScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "363      GradientBoostingClassifier       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.152141  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "323              AdaBoostClassifier       No Oversampling       No Scaling             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "893      GradientBoostingClassifier       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.152141  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1918             AdaBoostClassifier       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.116777  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "385      GradientBoostingClassifier       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "384      GradientBoostingClassifier       No Oversampling       No Scaling            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1433     GradientBoostingClassifier       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "383      GradientBoostingClassifier       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "386      GradientBoostingClassifier       No Oversampling       No Scaling            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "382      GradientBoostingClassifier       No Oversampling       No Scaling            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1435     GradientBoostingClassifier       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1428     GradientBoostingClassifier       No Oversampling   StandardScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.160232  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1977     GradientBoostingClassifier       No Oversampling        LogScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "387      GradientBoostingClassifier       No Oversampling       No Scaling            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "370      GradientBoostingClassifier       No Oversampling       No Scaling            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.163647  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "378      GradientBoostingClassifier       No Oversampling       No Scaling            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "377      GradientBoostingClassifier       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1958     GradientBoostingClassifier       No Oversampling        LogScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.160232  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "315              AdaBoostClassifier       No Oversampling       No Scaling             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1968     GradientBoostingClassifier       No Oversampling        LogScaler            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1973     GradientBoostingClassifier       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1974     GradientBoostingClassifier       No Oversampling        LogScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1975     GradientBoostingClassifier       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1976     GradientBoostingClassifier       No Oversampling        LogScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1443     GradientBoostingClassifier       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1444     GradientBoostingClassifier       No Oversampling   StandardScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1445     GradientBoostingClassifier       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1446     GradientBoostingClassifier       No Oversampling   StandardScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1447     GradientBoostingClassifier       No Oversampling   StandardScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "373      GradientBoostingClassifier       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1438     GradientBoostingClassifier       No Oversampling   StandardScaler            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1960     GradientBoostingClassifier       No Oversampling        LogScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.163647  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1905             AdaBoostClassifier       No Oversampling        LogScaler             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "375      GradientBoostingClassifier       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1437     GradientBoostingClassifier       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "845              AdaBoostClassifier       No Oversampling     MinMaxScaler             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "712            ExtraTreesClassifier       No Oversampling     MinMaxScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.079830                                          0.119992  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "900      GradientBoostingClassifier       No Oversampling     MinMaxScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.163647  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "915      GradientBoostingClassifier       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "914      GradientBoostingClassifier       No Oversampling     MinMaxScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "913      GradientBoostingClassifier       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1770           ExtraTreesClassifier       No Oversampling        LogScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.079830                                          0.110248  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "908      GradientBoostingClassifier       No Oversampling     MinMaxScaler            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "898      GradientBoostingClassifier       No Oversampling     MinMaxScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.160232  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "917      GradientBoostingClassifier       No Oversampling     MinMaxScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "916      GradientBoostingClassifier       No Oversampling     MinMaxScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "903      GradientBoostingClassifier       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "905      GradientBoostingClassifier       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1375             AdaBoostClassifier       No Oversampling   StandardScaler             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "907      GradientBoostingClassifier       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "324              AdaBoostClassifier       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1384             AdaBoostClassifier       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1916             AdaBoostClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1967     GradientBoostingClassifier       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.148369  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1771           ExtraTreesClassifier       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                        {'criterion': 'entropy'}                            0.077169                                          0.093820  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "179            ExtraTreesClassifier       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.077169                                          0.128288  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1764           ExtraTreesClassifier       No Oversampling        LogScaler             6                         RFE  [trustLevel, totalScanTimeInSeconds, scannedLi...                        {'criterion': 'entropy'}                            0.077169                                          0.123318  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "854              AdaBoostClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "901      GradientBoostingClassifier       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.153697  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "371      GradientBoostingClassifier       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.153697  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "897      GradientBoostingClassifier       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.171039  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "367      GradientBoostingClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.171039  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "366      GradientBoostingClassifier       No Oversampling       No Scaling            10                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.074508                                          0.153253  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1427     GradientBoostingClassifier       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.171039  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1431     GradientBoostingClassifier       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.153697  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1242           ExtraTreesClassifier       No Oversampling   StandardScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.071847                                          0.105882  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1933             AdaBoostClassifier       No Oversampling        LogScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1386             AdaBoostClassifier       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.071847                                          0.124820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1403             AdaBoostClassifier       No Oversampling   StandardScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "326              AdaBoostClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.071847                                          0.124820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "183            ExtraTreesClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.071847                                          0.118830  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "856              AdaBoostClassifier       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.071847                                          0.124820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "343              AdaBoostClassifier       No Oversampling       No Scaling            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "873              AdaBoostClassifier       No Oversampling     MinMaxScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1424     GradientBoostingClassifier       No Oversampling   StandardScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.069186                                          0.147274  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1954     GradientBoostingClassifier       No Oversampling        LogScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.069186                                          0.147274  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "364      GradientBoostingClassifier       No Oversampling       No Scaling             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.069186                                          0.147274  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "224          RandomForestClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.069186                                          0.089208  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "872              AdaBoostClassifier       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "342              AdaBoostClassifier       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "346              AdaBoostClassifier       No Oversampling       No Scaling            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1971     GradientBoostingClassifier       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1935             AdaBoostClassifier       No Oversampling        LogScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1404             AdaBoostClassifier       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1406             AdaBoostClassifier       No Oversampling   StandardScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1405             AdaBoostClassifier       No Oversampling   StandardScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "874              AdaBoostClassifier       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "876              AdaBoostClassifier       No Oversampling     MinMaxScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "345              AdaBoostClassifier       No Oversampling       No Scaling            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "875              AdaBoostClassifier       No Oversampling     MinMaxScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1932             AdaBoostClassifier       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1934             AdaBoostClassifier       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1441     GradientBoostingClassifier       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1936             AdaBoostClassifier       No Oversampling        LogScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1402             AdaBoostClassifier       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "344              AdaBoostClassifier       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "911      GradientBoostingClassifier       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "381      GradientBoostingClassifier       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1814         RandomForestClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.066525                                          0.116007  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "194            ExtraTreesClassifier       No Oversampling       No Scaling            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                           {'criterion': 'gini'}                            0.063864                                          0.128960  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1430     GradientBoostingClassifier       No Oversampling   StandardScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.063864                                          0.149659  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "14               LogisticRegression       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.063864                                          0.187959  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1074             LogisticRegression       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.063864                                          0.187959  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1922             AdaBoostClassifier       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.063864                                          0.158264  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "544              LogisticRegression       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.063864                                          0.187959  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "755          RandomForestClassifier       No Oversampling     MinMaxScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                           {'criterion': 'gini'}                            0.061203                                          0.088130  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1774           ExtraTreesClassifier       No Oversampling        LogScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                        {'criterion': 'entropy'}                            0.061203                                          0.121912  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "227          RandomForestClassifier       No Oversampling       No Scaling            12                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                        {'criterion': 'entropy'}                            0.061203                                          0.123550  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "927               BaggingClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.061203                                          0.135525  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1280         RandomForestClassifier       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.061203                                          0.126292  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "...                             ...                   ...              ...           ...                         ...                                                ...                                             ...                                 ...                                               ...                                                ...\n",
       "944                      Perceptron       No Oversampling     MinMaxScaler             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.979244                                          1.219465  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "950                      Perceptron       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1480                     Perceptron       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2010                     Perceptron       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "420                      Perceptron       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "495   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.987227                                          0.319313  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1025  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.987227                                          0.319313  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1555  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.987227                                          0.319313  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2028                     Perceptron       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2026                     Perceptron       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2024                     Perceptron       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2020                     Perceptron       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2022                     Perceptron       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2018                     Perceptron       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.021820                                          1.758131  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1185            ExtraTreeClassifier       No Oversampling   StandardScaler             2                         RFE               [trustLevel, totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.027142                                          0.374191  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "612          DecisionTreeClassifier       No Oversampling     MinMaxScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1672         DecisionTreeClassifier       No Oversampling        LogScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "82           DecisionTreeClassifier       No Oversampling       No Scaling             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1142         DecisionTreeClassifier       No Oversampling   StandardScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "735          RandomForestClassifier       No Oversampling     MinMaxScaler             1                         RFE                        [scannedLineItemsPerSecond]                           {'criterion': 'gini'}                           -1.043108                                          0.334697  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1713            ExtraTreeClassifier       No Oversampling        LogScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.056413                                          0.306418  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "1026  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "496   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1556  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2086  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "694            ExtraTreesClassifier       No Oversampling     MinMaxScaler             1                         RFE                        [scannedLineItemsPerSecond]                           {'criterion': 'gini'}                           -1.189462                                          0.304893  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1027  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.232038                                          0.366117  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1557  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.232038                                          0.366117  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "497   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.232038                                          0.366117  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2083  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             4                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -1.287919                                          0.398643  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1028  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.303885                                          0.361401  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1558  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.303885                                          0.361401  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "498   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.303885                                          0.361401  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "84           DecisionTreeClassifier       No Oversampling       No Scaling             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.327834                                          0.385513  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1144         DecisionTreeClassifier       No Oversampling   StandardScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.327834                                          0.351853  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1715            ExtraTreeClassifier       No Oversampling        LogScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                           {'criterion': 'gini'}                           -1.330495                                          0.382551  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "1674         DecisionTreeClassifier       No Oversampling        LogScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.333156                                          0.359628  DecisionTreeClassifier(class_weight=None, crit...\n",
       "614          DecisionTreeClassifier       No Oversampling     MinMaxScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.386376                                          0.335402  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1482                     Perceptron       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.466205                                          2.617490  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "952                      Perceptron       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.466205                                          2.617490  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "422                      Perceptron       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.466205                                          2.617490  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1559  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.490154                                          0.406493  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1029  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.490154                                          0.406493  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "499   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.490154                                          0.406493  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "415                      Perceptron       No Oversampling       No Scaling             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "945                      Perceptron       No Oversampling     MinMaxScaler             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2005                     Perceptron       No Oversampling        LogScaler             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1475                     Perceptron       No Oversampling   StandardScaler             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1879                     GaussianNB       No Oversampling        LogScaler             4                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -1.548696                                          0.534504       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "2087  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.564662                                          0.496072  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2084  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             5                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -1.591272                                          0.383223  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2085  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -1.599255                                          0.338200  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "290                      GaussianNB       No Oversampling       No Scaling             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.628526                                          0.515212       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1350                     GaussianNB       No Oversampling   StandardScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.628526                                          0.515212       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "820                      GaussianNB       No Oversampling     MinMaxScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.628526                                          0.515212       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1477                     Perceptron       No Oversampling   StandardScaler             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "417                      Perceptron       No Oversampling       No Scaling             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "947                      Perceptron       No Oversampling     MinMaxScaler             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2007                     Perceptron       No Oversampling        LogScaler             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2089  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.817456                                          0.475335  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2090  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.822778                                          0.398985  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2092  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.868015                                          0.432081  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2091  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.868015                                          0.435536  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1030  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.875998                                          0.558251  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "500   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.875998                                          0.558251  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1560  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.875998                                          0.558251  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2088  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                           -1.969133                                          0.441033  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "291                      GaussianNB       No Oversampling       No Scaling             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.998403                                          0.470626       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "821                      GaussianNB       No Oversampling     MinMaxScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.998403                                          0.470626       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1351                     GaussianNB       No Oversampling   StandardScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.998403                                          0.470626       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "501   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.009047                                          0.518266  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1561  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.009047                                          0.518266  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1031  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.009047                                          0.518266  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1880                     GaussianNB       No Oversampling        LogScaler             5                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -2.048962                                          0.480463       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "2093  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.086216                                          0.503074  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1473                     Perceptron       No Oversampling   StandardScaler             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "413                      Perceptron       No Oversampling       No Scaling             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2003                     Perceptron       No Oversampling        LogScaler             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "943                      Perceptron       No Oversampling     MinMaxScaler             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "502   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.195317                                          0.546154  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1562  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.195317                                          0.546154  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1032  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.195317                                          0.546154  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2094  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.421205  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "824                      GaussianNB       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1353                     GaussianNB       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1354                     GaussianNB       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "294                      GaussianNB       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "293                      GaussianNB       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "823                      GaussianNB       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1881                     GaussianNB       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -2.277807                                          0.480363       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "503   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.280468                                          0.383766  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1033  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.280468                                          0.383766  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1563  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.280468                                          0.383766  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1352                     GaussianNB       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "822                      GaussianNB       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1882                     GaussianNB       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "292                      GaussianNB       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1564  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.339010                                          0.429265  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1034  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.339010                                          0.429265  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "504   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.339010                                          0.429265  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1355                     GaussianNB       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.344332                                          0.574415       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "295                      GaussianNB       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.344332                                          0.574415       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "825                      GaussianNB       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.344332                                          0.574415       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "2095  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.357637                                          0.452316  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "509   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1039  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1038  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1569  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2099  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2098  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1568  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "508   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2096  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.424162                                          0.366827  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1565  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.450772                                          0.453778  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "505   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.450772                                          0.453778  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1035  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.450772                                          0.453778  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1036  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.496009                                          0.395064  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1566  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.496009                                          0.395064  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "506   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.496009                                          0.395064  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1037  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1567  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2097  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "507   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "941                      Perceptron       No Oversampling     MinMaxScaler             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "411                      Perceptron       No Oversampling       No Scaling             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1471                     Perceptron       No Oversampling   StandardScaler             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2001                     Perceptron       No Oversampling        LogScaler             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "826                      GaussianNB       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.676956                                          0.667603       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "296                      GaussianNB       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.676956                                          0.667603       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1356                     GaussianNB       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.676956                                          0.667603       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1883                     GaussianNB       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.788717                                          0.432177       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1357                     GaussianNB       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.249069                                          0.700153       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "297                      GaussianNB       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.249069                                          0.700153       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "827                      GaussianNB       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.249069                                          0.700153       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1885                     GaussianNB       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -3.400745                                          0.469608       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1886                     GaussianNB       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.400745                                          0.462822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1884                     GaussianNB       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                           -3.467270                                          0.531802       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1358                     GaussianNB       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.706759                                          0.728619       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "298                      GaussianNB       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.706759                                          0.728619       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "828                      GaussianNB       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.706759                                          0.728619       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "829                      GaussianNB       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.111229                                          0.765794       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1359                     GaussianNB       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.111229                                          0.765794       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "299                      GaussianNB       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.111229                                          0.765794       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "830                      GaussianNB       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.132517                                          0.752621       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1360                     GaussianNB       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.132517                                          0.752621       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "300                      GaussianNB       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.132517                                          0.752621       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "831                      GaussianNB       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.177754                                          0.637230       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1361                     GaussianNB       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.177754                                          0.637230       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "301                      GaussianNB       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.177754                                          0.637230       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1887                     GaussianNB       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.204364                                          0.487839       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "832                      GaussianNB       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.683342                                          0.517235       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1362                     GaussianNB       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.683342                                          0.517235       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "302                      GaussianNB       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.683342                                          0.517235       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1888                     GaussianNB       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.709952                                          0.394694       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1889                     GaussianNB       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.749867                                          0.412888       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1890                     GaussianNB       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.843002                                          0.431181       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1891                     GaussianNB       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.962746                                          0.415310       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1892                     GaussianNB       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.109101                                          0.429031       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1895                     GaussianNB       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "834                      GaussianNB       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1365                     GaussianNB       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1893                     GaussianNB       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "305                      GaussianNB       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1894                     GaussianNB       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "304                      GaussianNB       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "835                      GaussianNB       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "303                      GaussianNB       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1364                     GaussianNB       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1363                     GaussianNB       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "833                      GaussianNB       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "592                 NearestCentroid       No Oversampling     MinMaxScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1122                NearestCentroid       No Oversampling   StandardScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1652                NearestCentroid       No Oversampling        LogScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "62                  NearestCentroid       No Oversampling       No Scaling             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "591                 NearestCentroid       No Oversampling     MinMaxScaler             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "61                  NearestCentroid       No Oversampling       No Scaling             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1121                NearestCentroid       No Oversampling   StandardScaler             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1651                NearestCentroid       No Oversampling        LogScaler             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1653                NearestCentroid       No Oversampling        LogScaler             3                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -7.394891                                          0.676389  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1654                NearestCentroid       No Oversampling        LogScaler             4                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -7.394891                                          0.676389  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1656                NearestCentroid       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -7.421501                                          0.681185  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1655                NearestCentroid       No Oversampling        LogScaler             5                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -7.421501                                          0.681185  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "70                  NearestCentroid       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "67                  NearestCentroid       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "66                  NearestCentroid       No Oversampling       No Scaling             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "65                  NearestCentroid       No Oversampling       No Scaling             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "64                  NearestCentroid       No Oversampling       No Scaling             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "605                 NearestCentroid       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "602                 NearestCentroid       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1130                NearestCentroid       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "603                 NearestCentroid       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "604                 NearestCentroid       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1126                NearestCentroid       No Oversampling   StandardScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1127                NearestCentroid       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1129                NearestCentroid       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "69                  NearestCentroid       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "599                 NearestCentroid       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "71                  NearestCentroid       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1133                NearestCentroid       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1131                NearestCentroid       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1135                NearestCentroid       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1132                NearestCentroid       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "72                  NearestCentroid       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1657                NearestCentroid       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "594                 NearestCentroid       No Oversampling     MinMaxScaler             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1124                NearestCentroid       No Oversampling   StandardScaler             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1125                NearestCentroid       No Oversampling   StandardScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "595                 NearestCentroid       No Oversampling     MinMaxScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "601                 NearestCentroid       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "596                 NearestCentroid       No Oversampling     MinMaxScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "597                 NearestCentroid       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "75                  NearestCentroid       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "74                  NearestCentroid       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "73                  NearestCentroid       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "600                 NearestCentroid       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1134                NearestCentroid       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "598                 NearestCentroid       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1128                NearestCentroid       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1123                NearestCentroid       No Oversampling   StandardScaler             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "63                  NearestCentroid       No Oversampling       No Scaling             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "68                  NearestCentroid       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "593                 NearestCentroid       No Oversampling     MinMaxScaler             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1136                NearestCentroid       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1137                NearestCentroid       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1138                NearestCentroid       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1139                NearestCentroid       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1140                NearestCentroid       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "610                 NearestCentroid       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "76                  NearestCentroid       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "77                  NearestCentroid       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "608                 NearestCentroid       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "607                 NearestCentroid       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "606                 NearestCentroid       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1670                NearestCentroid       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1669                NearestCentroid       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1668                NearestCentroid       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1667                NearestCentroid       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1666                NearestCentroid       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1664                NearestCentroid       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1663                NearestCentroid       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1662                NearestCentroid       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1661                NearestCentroid       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1660                NearestCentroid       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1659                NearestCentroid       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1658                NearestCentroid       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "609                 NearestCentroid       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "80                  NearestCentroid       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "79                  NearestCentroid       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "78                  NearestCentroid       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1665                NearestCentroid       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "\n",
       "[2120 rows x 10 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "result_table = pd.DataFrame(columns=[\"Model\", \"Oversampling Strategy\", \"Data Preparation\", \"Feature Count\", \"Feature Selection Technique\", \"Features\", \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \"Monetary Value Per Instance - Standard Deviation\", \"Raw Model\"])\n",
    "\n",
    "for oversampling_strategy in range(1,2):  # Oversamling strategies currtently not in the loop\n",
    "    if (oversampling_strategy == 1):  \n",
    "        Y = train['fraud']\n",
    "        X = train.drop('fraud',axis=1)\n",
    "        oversampling = \"No Oversampling\"\n",
    "    elif (oversampling_strategy == 2):\n",
    "        extended_train = randomOverSampling(train)\n",
    "        Y = extended_train['fraud']\n",
    "        X = extended_train.drop('fraud',axis=1)\n",
    "        oversampling = \"Random Oversampling\"\n",
    "    elif (oversampling_strategy == 3):\n",
    "        extended_train = smoteOverSamling(train)\n",
    "        Y = extended_train['fraud']\n",
    "        X = extended_train.drop('fraud',axis=1)\n",
    "        oversampling = \"SMOTE\"\n",
    "    elif (oversampling_strategy == 3):\n",
    "        extended_train = adasynOverSamling(train)\n",
    "        Y = extended_train['fraud']\n",
    "        X = extended_train.drop('fraud',axis=1)\n",
    "        oversampling = \"Adaysin\"\n",
    "            \n",
    "    # four types of data preparation: No preparation, MaxMinScaler, StandardScaler, LogScaling\n",
    "    for data_preparation_strategy in range(1,5):\n",
    "        if (data_preparation_strategy == 1):  \n",
    "            X_scaled = X\n",
    "            data_preparation = \"No Scaling\"\n",
    "        elif (data_preparation_strategy == 2):\n",
    "            feature_scaler = MinMaxScaler()  \n",
    "            X_scaled = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index) \n",
    "            data_preparation = \"MinMaxScaler\"\n",
    "        elif (data_preparation_strategy == 3):\n",
    "            feature_scaler = StandardScaler()  \n",
    "            X_scaled = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index)\n",
    "            data_preparation = \"StandardScaler\"\n",
    "        elif (data_preparation_strategy == 4):\n",
    "            transformer = FunctionTransformer(np.log1p, validate=True)  \n",
    "            X_scaled = pd.DataFrame(transformer.transform(X), columns=X.columns, index=X.index)\n",
    "            data_preparation = \"LogScaler\"    \n",
    "\n",
    "\n",
    "\n",
    "        for model in model_tuning_factory:   # replace with model_tuning_factory_randomized for faster results\n",
    "\n",
    "                \n",
    "            for feature_count in range(1,len(list(X))+1):\n",
    "   \n",
    "                model.seed = 42\n",
    "                start_time = time.time()              \n",
    "                \n",
    "                \n",
    "                # Solution with SelectKBest\n",
    "                best_features = SelectKBest(f_classif, k=feature_count).fit(X_scaled,Y)\n",
    "                best_feature_list = X.columns[best_features.get_support()]\n",
    "                X_selected_features = X[best_feature_list]\n",
    "                \n",
    "                model.fit(X_selected_features,Y)  \n",
    "                model_name = model.best_estimator_.__class__.__name__\n",
    "                score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "                score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "                \n",
    "                result_table = result_table.append({\n",
    "                 \"Model\": model_name,\n",
    "                 \"Oversampling Strategy\": oversampling,   \n",
    "                 \"Data Preparation\": data_preparation,   \n",
    "                 \"Feature Count\": feature_count,\n",
    "                 \"Feature Selection Technique\": \"SelectKBest\",   \n",
    "                 \"Features\": best_feature_list.values, \n",
    "                 \"Optimal Parameters\": model.best_params_,\n",
    "                 \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "                 \"Monetary Value Per Instance - Standard Deviation\": score_std,   \n",
    "                 \"Raw Model\": model.best_estimator_\n",
    "                  }, ignore_index=True)\n",
    "                \n",
    "\n",
    "                # Solution with Recursive Feature Elimination -> only works for some models\n",
    "                \n",
    "                if (model.estimator.__class__.__name__ == 'LogisticRegression'\n",
    "                 or model.estimator.__class__.__name__ == 'DecisionTreeClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'ExtraTreeClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'ExtraTreesClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'RandomForestClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'BernoulliNB'\n",
    "                 or model.estimator.__class__.__name__ == 'AdaBoostClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'GradientBoostingClassifier'\n",
    "                 or model.estimator.__class__.__name__ == 'Perceptron'\n",
    "                 or model.estimator.__class__.__name__ == 'LinearDiscriminantAnalysis'):\n",
    "                \n",
    "                   # Traditional RFE\n",
    "                    rfe = RFE(model.estimator, n_features_to_select = feature_count)\n",
    "                    rfe = rfe.fit(X,Y)\n",
    "                    best_feature_list = np.array(list(X))[np.array(rfe.support_)]\n",
    "                    X_selected_features = X[best_feature_list]\n",
    "\n",
    "                    model.fit(X_selected_features,Y)  \n",
    "                    model_name = model.best_estimator_.__class__.__name__\n",
    "                    score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "                    score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "\n",
    "                    result_table = result_table.append({\n",
    "                     \"Model\": model_name,\n",
    "                     \"Oversampling Strategy\": oversampling,   \n",
    "                     \"Data Preparation\": data_preparation,\n",
    "                     \"Feature Count\": feature_count,\n",
    "                     \"Feature Selection Technique\": \"RFE\",\n",
    "                     \"Features\": best_feature_list,\n",
    "                     \"Optimal Parameters\": model.best_params_,\n",
    "                     \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "                     \"Monetary Value Per Instance - Standard Deviation\": score_std,  \n",
    "                     \"Raw Model\": model.best_estimator_\n",
    "                      }, ignore_index=True)\n",
    "                    \n",
    "                end_time = time.time()\n",
    "\n",
    "                print(\"Finished \" + model.best_estimator_.__class__.__name__ + \" with \" + oversampling + \" and \" + data_preparation + \" and \" + str(feature_count) + \" features after \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "\n",
    "                 \n",
    "                \n",
    "            if (model.estimator.__class__.__name__ == 'LogisticRegression'\n",
    "             or model.estimator.__class__.__name__ == 'DecisionTreeClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'ExtraTreeClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'ExtraTreesClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'RandomForestClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'BernoulliNB'\n",
    "             or model.estimator.__class__.__name__ == 'AdaBoostClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'GradientBoostingClassifier'\n",
    "             or model.estimator.__class__.__name__ == 'Perceptron'\n",
    "             or model.estimator.__class__.__name__ == 'LinearDiscriminantAnalysis'):\n",
    "\n",
    "                # RFE with Cross Validation -> determines the optimum feature count automatically\n",
    "                rfecv = RFECV(model.estimator, cv = skf, scoring = my_custom_score)\n",
    "                rfecv = rfe.fit(X,Y)\n",
    "                best_feature_list = np.array(list(X))[np.array(rfecv.support_)]\n",
    "                X_selected_features = X[best_feature_list]\n",
    "\n",
    "                model.fit(X_selected_features,Y)  \n",
    "                model_name = model.best_estimator_.__class__.__name__\n",
    "                score_mean = model.cv_results_['mean_test_score'][model.best_index_]\n",
    "                score_std = model.cv_results_['std_test_score'][model.best_index_]\n",
    "\n",
    "\n",
    "                result_table = result_table.append({\n",
    "                 \"Model\": model_name,\n",
    "                 \"Oversampling Strategy\": oversampling,   \n",
    "                 \"Data Preparation\": data_preparation,\n",
    "                 \"Feature Count\": len(best_feature_list),\n",
    "                 \"Feature Selection Technique\": \"RFECV\",\n",
    "                 \"Features\": best_feature_list,\n",
    "                 \"Optimal Parameters\": model.best_params_,\n",
    "                 \"Monetary Value Per Instance - Mean\":  score_mean,\n",
    "                 \"Monetary Value Per Instance - Standard Deviation\": score_std,    \n",
    "                 \"Raw Model\": model.best_estimator_\n",
    "                  }, ignore_index=True)\n",
    "                    \n",
    "result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the saved result table to avoid recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_table.to_pickle(\"result_table_training_set.pkl\")\n",
    "result_table = pd.read_pickle(\"result_table_training_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling Strategy</th>\n",
       "      <th>Data Preparation</th>\n",
       "      <th>Feature Count</th>\n",
       "      <th>Feature Selection Technique</th>\n",
       "      <th>Features</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Monetary Value Per Instance - Mean</th>\n",
       "      <th>Monetary Value Per Instance - Standard Deviation</th>\n",
       "      <th>Raw Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120368</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120368</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120368</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.121215</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.138371</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.138371</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.138371</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>0.084027</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.117084</td>\n",
       "      <td>0.121028</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.117084</td>\n",
       "      <td>0.121028</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.111762</td>\n",
       "      <td>0.137173</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.125820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.131302</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.100420</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.108791</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.180599</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.180599</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.093135</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.162452</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.092775</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.105831</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.106390</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.082368</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.120123</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.106390</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.098423</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.154678</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.157366</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.073999</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.082491</td>\n",
       "      <td>0.116777</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.160232</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.160232</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.119992</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.163647</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.110248</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.160232</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.153785</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.177545</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.079830</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.148369</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.093820</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.077169</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153697</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153697</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153253</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.153697</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.118830</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.124820</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.147274</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.147274</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.147274</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.089208</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.133034</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.116007</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.128960</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.149659</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.158264</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.088130</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.121912</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.123550</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.135525</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.126292</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.979244</td>\n",
       "      <td>1.219465</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.984566</td>\n",
       "      <td>1.234920</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.987227</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.987227</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.987227</td>\n",
       "      <td>0.319313</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.016498</td>\n",
       "      <td>1.759214</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.021820</td>\n",
       "      <td>1.758131</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.027142</td>\n",
       "      <td>0.374191</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.029803</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItemsPerSecond]</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>-1.043108</td>\n",
       "      <td>0.334697</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.056413</td>\n",
       "      <td>0.306418</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.106972</td>\n",
       "      <td>0.427994</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItemsPerSecond]</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>-1.189462</td>\n",
       "      <td>0.304893</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.287919</td>\n",
       "      <td>0.398643</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.303885</td>\n",
       "      <td>0.361401</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.303885</td>\n",
       "      <td>0.361401</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.303885</td>\n",
       "      <td>0.361401</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.327834</td>\n",
       "      <td>0.385513</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.327834</td>\n",
       "      <td>0.351853</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>-1.330495</td>\n",
       "      <td>0.382551</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.333156</td>\n",
       "      <td>0.359628</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[totalScanTimeInSeconds, scannedLineItems]</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-1.386376</td>\n",
       "      <td>0.335402</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.466205</td>\n",
       "      <td>2.617490</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.466205</td>\n",
       "      <td>2.617490</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.466205</td>\n",
       "      <td>2.617490</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.490154</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.490154</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.490154</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[grandTotal, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.543374</td>\n",
       "      <td>1.212528</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.548696</td>\n",
       "      <td>0.534504</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.564662</td>\n",
       "      <td>0.496072</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.591272</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.599255</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.628526</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.628526</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.628526</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, grandTotal, scannedLineItems, pri...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.692390</td>\n",
       "      <td>1.538135</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.817456</td>\n",
       "      <td>0.475335</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.822778</td>\n",
       "      <td>0.398985</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.868015</td>\n",
       "      <td>0.432081</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.868015</td>\n",
       "      <td>0.435536</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.875998</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.875998</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.875998</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.969133</td>\n",
       "      <td>0.441033</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.998403</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.998403</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1.998403</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.009047</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.009047</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.009047</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.048962</td>\n",
       "      <td>0.480463</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.086216</td>\n",
       "      <td>0.503074</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, pricePerScannedLineItem, se...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.152741</td>\n",
       "      <td>1.970403</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.195317</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.195317</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.195317</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.421205</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.251197</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.277807</td>\n",
       "      <td>0.480363</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.280468</td>\n",
       "      <td>0.383766</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.280468</td>\n",
       "      <td>0.383766</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.280468</td>\n",
       "      <td>0.383766</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.291112</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.339010</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.339010</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.339010</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.344332</td>\n",
       "      <td>0.574415</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.344332</td>\n",
       "      <td>0.574415</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.344332</td>\n",
       "      <td>0.574415</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.357637</td>\n",
       "      <td>0.452316</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.386908</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.424162</td>\n",
       "      <td>0.366827</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.450772</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.450772</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.450772</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.496009</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.496009</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.496009</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.509313</td>\n",
       "      <td>0.370092</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[scannedLineItems, secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.653007</td>\n",
       "      <td>2.938061</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.676956</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.676956</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.676956</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-2.788717</td>\n",
       "      <td>0.432177</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.249069</td>\n",
       "      <td>0.700153</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.249069</td>\n",
       "      <td>0.700153</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.249069</td>\n",
       "      <td>0.700153</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.400745</td>\n",
       "      <td>0.469608</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.400745</td>\n",
       "      <td>0.462822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.467270</td>\n",
       "      <td>0.531802</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.706759</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.706759</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-3.706759</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.111229</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.111229</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.111229</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.132517</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.132517</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.132517</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.177754</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.177754</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.177754</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.204364</td>\n",
       "      <td>0.487839</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.683342</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.683342</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.683342</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.709952</td>\n",
       "      <td>0.394694</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.749867</td>\n",
       "      <td>0.412888</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.843002</td>\n",
       "      <td>0.431181</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-4.962746</td>\n",
       "      <td>0.415310</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.109101</td>\n",
       "      <td>0.429031</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-5.162320</td>\n",
       "      <td>0.471822</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.373603</td>\n",
       "      <td>1.024395</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.394891</td>\n",
       "      <td>0.676389</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems, pricePerScanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.394891</td>\n",
       "      <td>0.676389</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.421501</td>\n",
       "      <td>0.681185</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-7.421501</td>\n",
       "      <td>0.681185</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.077169</td>\n",
       "      <td>0.671206</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.082491</td>\n",
       "      <td>0.675176</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>17</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>16</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>14</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>12</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scansWith...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>9</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>20</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>19</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, grandTota...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>18</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-10.353912</td>\n",
       "      <td>0.612998</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model Oversampling Strategy Data Preparation Feature Count Feature Selection Technique                                           Features                              Optimal Parameters  Monetary Value Per Instance - Mean  Monetary Value Per Instance - Standard Deviation                                          Raw Model\n",
       "1909             AdaBoostClassifier       No Oversampling        LogScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "319              AdaBoostClassifier       No Oversampling       No Scaling             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "849              AdaBoostClassifier       No Oversampling     MinMaxScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1379             AdaBoostClassifier       No Oversampling   StandardScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "317              AdaBoostClassifier       No Oversampling       No Scaling             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "847              AdaBoostClassifier       No Oversampling     MinMaxScaler             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1907             AdaBoostClassifier       No Oversampling        LogScaler             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1377             AdaBoostClassifier       No Oversampling   StandardScaler             6                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.167642                                          0.066132  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "24               LogisticRegression       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "28               LogisticRegression       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "554              LogisticRegression       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1088             LogisticRegression       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "558              LogisticRegression       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1084             LogisticRegression       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1612             LogisticRegression       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.162320                                          0.119850  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1090             LogisticRegression       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.156998                                          0.120305  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "548              LogisticRegression       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "550              LogisticRegression       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1078             LogisticRegression       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "552              LogisticRegression       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1080             LogisticRegression       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1082             LogisticRegression       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1086             LogisticRegression       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.120368  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "30               LogisticRegression       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.156998                                          0.120305  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1076             LogisticRegression       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "546              LogisticRegression       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "556              LogisticRegression       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.120368  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "26               LogisticRegression       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.120368  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "20               LogisticRegression       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "16               LogisticRegression       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "560              LogisticRegression       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.156998                                          0.120305  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "18               LogisticRegression       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "22               LogisticRegression       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.156998                                          0.126081  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "32               LogisticRegression       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.134489  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1092             LogisticRegression       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.134489  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "562              LogisticRegression       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.134489  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1610             LogisticRegression       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.151676                                          0.121215  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "570              LogisticRegression       No Oversampling     MinMaxScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1630             LogisticRegression       No Oversampling        LogScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1629             LogisticRegression       No Oversampling        LogScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1628             LogisticRegression       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1614             LogisticRegression       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "569              LogisticRegression       No Oversampling     MinMaxScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "568              LogisticRegression       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1098             LogisticRegression       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1099             LogisticRegression       No Oversampling   StandardScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "39               LogisticRegression       No Oversampling       No Scaling            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "38               LogisticRegression       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "40               LogisticRegression       No Oversampling       No Scaling            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1100             LogisticRegression       No Oversampling   StandardScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.149015                                          0.114885  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1094             LogisticRegression       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "566              LogisticRegression       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1096             LogisticRegression       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1622             LogisticRegression       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1624             LogisticRegression       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1626             LogisticRegression       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "564              LogisticRegression       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "36               LogisticRegression       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...      {'fit_intercept': True, 'solver': 'lbfgs'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "34               LogisticRegression       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.143693                                          0.115470  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1616             LogisticRegression       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.138371                                          0.118278  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1618             LogisticRegression       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.138371                                          0.118278  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1620             LogisticRegression       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.138371                                          0.118278  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1773           ExtraTreesClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.119745                                          0.084027  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1951     GradientBoostingClassifier       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.117084                                          0.121028  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1953     GradientBoostingClassifier       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                            0.117084                                          0.121028  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1961     GradientBoostingClassifier       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.111762                                          0.137173  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "365      GradientBoostingClassifier       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1425     GradientBoostingClassifier       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "863              AdaBoostClassifier       No Oversampling     MinMaxScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1920             AdaBoostClassifier       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.125820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1393             AdaBoostClassifier       No Oversampling   StandardScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1923             AdaBoostClassifier       No Oversampling        LogScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "333              AdaBoostClassifier       No Oversampling       No Scaling            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.106440                                          0.131302  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1957     GradientBoostingClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "895      GradientBoostingClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.106440                                          0.134110  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1962     GradientBoostingClassifier       No Oversampling        LogScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.103779                                          0.147455  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "713            ExtraTreesClassifier       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.103779                                          0.100420  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1432     GradientBoostingClassifier       No Oversampling   StandardScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.103779                                          0.147455  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1921             AdaBoostClassifier       No Oversampling        LogScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1391             AdaBoostClassifier       No Oversampling   StandardScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1385             AdaBoostClassifier       No Oversampling   StandardScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1915             AdaBoostClassifier       No Oversampling        LogScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "855              AdaBoostClassifier       No Oversampling     MinMaxScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "331              AdaBoostClassifier       No Oversampling       No Scaling            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "861              AdaBoostClassifier       No Oversampling     MinMaxScaler            13                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.133283  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "325              AdaBoostClassifier       No Oversampling       No Scaling            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.101118                                          0.102889  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1966     GradientBoostingClassifier       No Oversampling        LogScaler            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1240           ExtraTreesClassifier       No Oversampling   StandardScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.098457                                          0.108791  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "376      GradientBoostingClassifier       No Oversampling       No Scaling            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "906      GradientBoostingClassifier       No Oversampling     MinMaxScaler            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1436     GradientBoostingClassifier       No Oversampling   StandardScaler            15                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.098457                                          0.148207  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "912      GradientBoostingClassifier       No Oversampling     MinMaxScaler            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1426     GradientBoostingClassifier       No Oversampling   StandardScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.093135                                          0.180599  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "910      GradientBoostingClassifier       No Oversampling     MinMaxScaler            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1440     GradientBoostingClassifier       No Oversampling   StandardScaler            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1442     GradientBoostingClassifier       No Oversampling   StandardScaler            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1972     GradientBoostingClassifier       No Oversampling        LogScaler            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1970     GradientBoostingClassifier       No Oversampling        LogScaler            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1956     GradientBoostingClassifier       No Oversampling        LogScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.093135                                          0.180599  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "380      GradientBoostingClassifier       No Oversampling       No Scaling            17                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1959     GradientBoostingClassifier       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.093135                                          0.144889  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "857              AdaBoostClassifier       No Oversampling     MinMaxScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "372      GradientBoostingClassifier       No Oversampling       No Scaling            13                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.162452  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1963     GradientBoostingClassifier       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1608             LogisticRegression       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.090474                                          0.162155  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1964     GradientBoostingClassifier       No Oversampling        LogScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "320              AdaBoostClassifier       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.127099  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1387             AdaBoostClassifier       No Oversampling   StandardScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "904      GradientBoostingClassifier       No Oversampling     MinMaxScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1766           ExtraTreesClassifier       No Oversampling        LogScaler             7                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                           {'criterion': 'gini'}                            0.090474                                          0.092775  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1389             AdaBoostClassifier       No Oversampling   StandardScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "850              AdaBoostClassifier       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.127099  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1917             AdaBoostClassifier       No Oversampling        LogScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "374      GradientBoostingClassifier       No Oversampling       No Scaling            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1380             AdaBoostClassifier       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.127099  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1919             AdaBoostClassifier       No Oversampling        LogScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "327              AdaBoostClassifier       No Oversampling       No Scaling            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "329              AdaBoostClassifier       No Oversampling       No Scaling            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1914             AdaBoostClassifier       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.090474                                          0.105831  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1434     GradientBoostingClassifier       No Oversampling   StandardScaler            14                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.090474                                          0.152513  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "859              AdaBoostClassifier       No Oversampling     MinMaxScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.090474                                          0.136750  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "851              AdaBoostClassifier       No Oversampling     MinMaxScaler             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1912             AdaBoostClassifier       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                            0.087813                                          0.106390  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1911             AdaBoostClassifier       No Oversampling        LogScaler             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1381             AdaBoostClassifier       No Oversampling   StandardScaler             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "710            ExtraTreesClassifier       No Oversampling     MinMaxScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                           {'criterion': 'gini'}                            0.087813                                          0.082368  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "180            ExtraTreesClassifier       No Oversampling       No Scaling             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.087813                                          0.120123  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "321              AdaBoostClassifier       No Oversampling       No Scaling             8                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.138643  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1910             AdaBoostClassifier       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.087813                                          0.106390  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "711            ExtraTreesClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.085152                                          0.098423  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "379      GradientBoostingClassifier       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.152815  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "368      GradientBoostingClassifier       No Oversampling       No Scaling            11                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.154678  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1969     GradientBoostingClassifier       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.157366  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1439     GradientBoostingClassifier       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.152815  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1236           ExtraTreesClassifier       No Oversampling   StandardScaler             7                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                        {'criterion': 'entropy'}                            0.085152                                          0.073999  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "909      GradientBoostingClassifier       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.085152                                          0.152815  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1423     GradientBoostingClassifier       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.152141  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1913             AdaBoostClassifier       No Oversampling        LogScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1383             AdaBoostClassifier       No Oversampling   StandardScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "853              AdaBoostClassifier       No Oversampling     MinMaxScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "363      GradientBoostingClassifier       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.152141  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "323              AdaBoostClassifier       No Oversampling       No Scaling             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.153816  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "893      GradientBoostingClassifier       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.152141  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1918             AdaBoostClassifier       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.082491                                          0.116777  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "385      GradientBoostingClassifier       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "384      GradientBoostingClassifier       No Oversampling       No Scaling            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1433     GradientBoostingClassifier       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "383      GradientBoostingClassifier       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "386      GradientBoostingClassifier       No Oversampling       No Scaling            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "382      GradientBoostingClassifier       No Oversampling       No Scaling            18                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1435     GradientBoostingClassifier       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1428     GradientBoostingClassifier       No Oversampling   StandardScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.160232  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1977     GradientBoostingClassifier       No Oversampling        LogScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "387      GradientBoostingClassifier       No Oversampling       No Scaling            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "370      GradientBoostingClassifier       No Oversampling       No Scaling            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.163647  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "378      GradientBoostingClassifier       No Oversampling       No Scaling            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "377      GradientBoostingClassifier       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1958     GradientBoostingClassifier       No Oversampling        LogScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.160232  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "315              AdaBoostClassifier       No Oversampling       No Scaling             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1968     GradientBoostingClassifier       No Oversampling        LogScaler            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1973     GradientBoostingClassifier       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1974     GradientBoostingClassifier       No Oversampling        LogScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1975     GradientBoostingClassifier       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1976     GradientBoostingClassifier       No Oversampling        LogScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1443     GradientBoostingClassifier       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1444     GradientBoostingClassifier       No Oversampling   StandardScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1445     GradientBoostingClassifier       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1446     GradientBoostingClassifier       No Oversampling   StandardScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1447     GradientBoostingClassifier       No Oversampling   StandardScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "373      GradientBoostingClassifier       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1438     GradientBoostingClassifier       No Oversampling   StandardScaler            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1960     GradientBoostingClassifier       No Oversampling        LogScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.163647  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1905             AdaBoostClassifier       No Oversampling        LogScaler             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "375      GradientBoostingClassifier       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1437     GradientBoostingClassifier       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "845              AdaBoostClassifier       No Oversampling     MinMaxScaler             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "712            ExtraTreesClassifier       No Oversampling     MinMaxScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.079830                                          0.119992  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "900      GradientBoostingClassifier       No Oversampling     MinMaxScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.163647  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "915      GradientBoostingClassifier       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "914      GradientBoostingClassifier       No Oversampling     MinMaxScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "913      GradientBoostingClassifier       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1770           ExtraTreesClassifier       No Oversampling        LogScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.079830                                          0.110248  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "908      GradientBoostingClassifier       No Oversampling     MinMaxScaler            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "898      GradientBoostingClassifier       No Oversampling     MinMaxScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.160232  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "917      GradientBoostingClassifier       No Oversampling     MinMaxScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "916      GradientBoostingClassifier       No Oversampling     MinMaxScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.079830                                          0.153785  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "903      GradientBoostingClassifier       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "905      GradientBoostingClassifier       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1375             AdaBoostClassifier       No Oversampling   StandardScaler             5                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.079830                                          0.177545  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "907      GradientBoostingClassifier       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.079830                                          0.149137  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "324              AdaBoostClassifier       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1384             AdaBoostClassifier       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1916             AdaBoostClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1967     GradientBoostingClassifier       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.148369  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1771           ExtraTreesClassifier       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                        {'criterion': 'entropy'}                            0.077169                                          0.093820  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "179            ExtraTreesClassifier       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.077169                                          0.128288  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1764           ExtraTreesClassifier       No Oversampling        LogScaler             6                         RFE  [trustLevel, totalScanTimeInSeconds, scannedLi...                        {'criterion': 'entropy'}                            0.077169                                          0.123318  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "854              AdaBoostClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.077169                                          0.109265  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "901      GradientBoostingClassifier       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.153697  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "371      GradientBoostingClassifier       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.153697  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "897      GradientBoostingClassifier       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.171039  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "367      GradientBoostingClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.171039  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "366      GradientBoostingClassifier       No Oversampling       No Scaling            10                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.074508                                          0.153253  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1427     GradientBoostingClassifier       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.171039  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1431     GradientBoostingClassifier       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.074508                                          0.153697  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1242           ExtraTreesClassifier       No Oversampling   StandardScaler            10                         RFE  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.071847                                          0.105882  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1933             AdaBoostClassifier       No Oversampling        LogScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1386             AdaBoostClassifier       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.071847                                          0.124820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1403             AdaBoostClassifier       No Oversampling   StandardScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "326              AdaBoostClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.071847                                          0.124820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "183            ExtraTreesClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.071847                                          0.118830  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "856              AdaBoostClassifier       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.071847                                          0.124820  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "343              AdaBoostClassifier       No Oversampling       No Scaling            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "873              AdaBoostClassifier       No Oversampling     MinMaxScaler            19                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.071847                                          0.135590  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1424     GradientBoostingClassifier       No Oversampling   StandardScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.069186                                          0.147274  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1954     GradientBoostingClassifier       No Oversampling        LogScaler             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.069186                                          0.147274  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "364      GradientBoostingClassifier       No Oversampling       No Scaling             9                         RFE  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                            0.069186                                          0.147274  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "224          RandomForestClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.069186                                          0.089208  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "872              AdaBoostClassifier       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "342              AdaBoostClassifier       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "346              AdaBoostClassifier       No Oversampling       No Scaling            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1971     GradientBoostingClassifier       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1935             AdaBoostClassifier       No Oversampling        LogScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1404             AdaBoostClassifier       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1406             AdaBoostClassifier       No Oversampling   StandardScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1405             AdaBoostClassifier       No Oversampling   StandardScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "874              AdaBoostClassifier       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "876              AdaBoostClassifier       No Oversampling     MinMaxScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "345              AdaBoostClassifier       No Oversampling       No Scaling            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "875              AdaBoostClassifier       No Oversampling     MinMaxScaler            20                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1932             AdaBoostClassifier       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1934             AdaBoostClassifier       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1441     GradientBoostingClassifier       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1936             AdaBoostClassifier       No Oversampling        LogScaler            20                       RFECV  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1402             AdaBoostClassifier       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "344              AdaBoostClassifier       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.066525                                          0.133034  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "911      GradientBoostingClassifier       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "381      GradientBoostingClassifier       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.066525                                          0.166348  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "1814         RandomForestClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.066525                                          0.116007  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "194            ExtraTreesClassifier       No Oversampling       No Scaling            16                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                           {'criterion': 'gini'}                            0.063864                                          0.128960  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1430     GradientBoostingClassifier       No Oversampling   StandardScaler            12                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                            0.063864                                          0.149659  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "14               LogisticRegression       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.063864                                          0.187959  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1074             LogisticRegression       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.063864                                          0.187959  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "1922             AdaBoostClassifier       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.063864                                          0.158264  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "544              LogisticRegression       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.063864                                          0.187959  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "755          RandomForestClassifier       No Oversampling     MinMaxScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                           {'criterion': 'gini'}                            0.061203                                          0.088130  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1774           ExtraTreesClassifier       No Oversampling        LogScaler            11                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                        {'criterion': 'entropy'}                            0.061203                                          0.121912  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "227          RandomForestClassifier       No Oversampling       No Scaling            12                         RFE  [trustLevel, totalScanTimeInSeconds, grandTota...                        {'criterion': 'entropy'}                            0.061203                                          0.123550  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "927               BaggingClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.061203                                          0.135525  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1280         RandomForestClassifier       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                           {'criterion': 'gini'}                            0.061203                                          0.126292  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "...                             ...                   ...              ...           ...                         ...                                                ...                                             ...                                 ...                                               ...                                                ...\n",
       "944                      Perceptron       No Oversampling     MinMaxScaler             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.979244                                          1.219465  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "950                      Perceptron       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1480                     Perceptron       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2010                     Perceptron       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "420                      Perceptron       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.984566                                          1.234920  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "495   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.987227                                          0.319313  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1025  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.987227                                          0.319313  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1555  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.987227                                          0.319313  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2028                     Perceptron       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2026                     Perceptron       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2024                     Perceptron       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2020                     Perceptron       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2022                     Perceptron       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.016498                                          1.759214  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2018                     Perceptron       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.021820                                          1.758131  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1185            ExtraTreeClassifier       No Oversampling   StandardScaler             2                         RFE               [trustLevel, totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.027142                                          0.374191  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "612          DecisionTreeClassifier       No Oversampling     MinMaxScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1672         DecisionTreeClassifier       No Oversampling        LogScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "82           DecisionTreeClassifier       No Oversampling       No Scaling             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1142         DecisionTreeClassifier       No Oversampling   StandardScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.029803                                          0.339035  DecisionTreeClassifier(class_weight=None, crit...\n",
       "735          RandomForestClassifier       No Oversampling     MinMaxScaler             1                         RFE                        [scannedLineItemsPerSecond]                           {'criterion': 'gini'}                           -1.043108                                          0.334697  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "1713            ExtraTreeClassifier       No Oversampling        LogScaler             1                         RFE                           [totalScanTimeInSeconds]                        {'criterion': 'entropy'}                           -1.056413                                          0.306418  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "1026  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "496   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1556  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2086  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.106972                                          0.427994  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "694            ExtraTreesClassifier       No Oversampling     MinMaxScaler             1                         RFE                        [scannedLineItemsPerSecond]                           {'criterion': 'gini'}                           -1.189462                                          0.304893  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "1027  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.232038                                          0.366117  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1557  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.232038                                          0.366117  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "497   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.232038                                          0.366117  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2083  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             4                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -1.287919                                          0.398643  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1028  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.303885                                          0.361401  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1558  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.303885                                          0.361401  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "498   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.303885                                          0.361401  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "84           DecisionTreeClassifier       No Oversampling       No Scaling             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.327834                                          0.385513  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1144         DecisionTreeClassifier       No Oversampling   StandardScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.327834                                          0.351853  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1715            ExtraTreeClassifier       No Oversampling        LogScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                           {'criterion': 'gini'}                           -1.330495                                          0.382551  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "1674         DecisionTreeClassifier       No Oversampling        LogScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.333156                                          0.359628  DecisionTreeClassifier(class_weight=None, crit...\n",
       "614          DecisionTreeClassifier       No Oversampling     MinMaxScaler             2                         RFE         [totalScanTimeInSeconds, scannedLineItems]                        {'criterion': 'entropy'}                           -1.386376                                          0.335402  DecisionTreeClassifier(class_weight=None, crit...\n",
       "1482                     Perceptron       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.466205                                          2.617490  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "952                      Perceptron       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.466205                                          2.617490  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "422                      Perceptron       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.466205                                          2.617490  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1559  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.490154                                          0.406493  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1029  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.490154                                          0.406493  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "499   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.490154                                          0.406493  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "415                      Perceptron       No Oversampling       No Scaling             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "945                      Perceptron       No Oversampling     MinMaxScaler             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2005                     Perceptron       No Oversampling        LogScaler             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1475                     Perceptron       No Oversampling   StandardScaler             4                         RFE  [grandTotal, scannedLineItems, pricePerScanned...                                              {}                           -1.543374                                          1.212528  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1879                     GaussianNB       No Oversampling        LogScaler             4                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -1.548696                                          0.534504       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "2087  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.564662                                          0.496072  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2084  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             5                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -1.591272                                          0.383223  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2085  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -1.599255                                          0.338200  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "290                      GaussianNB       No Oversampling       No Scaling             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.628526                                          0.515212       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1350                     GaussianNB       No Oversampling   StandardScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.628526                                          0.515212       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "820                      GaussianNB       No Oversampling     MinMaxScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.628526                                          0.515212       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1477                     Perceptron       No Oversampling   StandardScaler             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "417                      Perceptron       No Oversampling       No Scaling             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "947                      Perceptron       No Oversampling     MinMaxScaler             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2007                     Perceptron       No Oversampling        LogScaler             5                         RFE  [trustLevel, grandTotal, scannedLineItems, pri...                                              {}                           -1.692390                                          1.538135  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2089  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -1.817456                                          0.475335  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2090  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.822778                                          0.398985  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2092  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.868015                                          0.432081  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2091  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.868015                                          0.435536  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1030  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.875998                                          0.558251  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "500   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.875998                                          0.558251  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1560  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -1.875998                                          0.558251  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2088  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                           -1.969133                                          0.441033  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "291                      GaussianNB       No Oversampling       No Scaling             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.998403                                          0.470626       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "821                      GaussianNB       No Oversampling     MinMaxScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.998403                                          0.470626       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1351                     GaussianNB       No Oversampling   StandardScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -1.998403                                          0.470626       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "501   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.009047                                          0.518266  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1561  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.009047                                          0.518266  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1031  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.009047                                          0.518266  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1880                     GaussianNB       No Oversampling        LogScaler             5                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -2.048962                                          0.480463       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "2093  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.086216                                          0.503074  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1473                     Perceptron       No Oversampling   StandardScaler             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "413                      Perceptron       No Oversampling       No Scaling             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2003                     Perceptron       No Oversampling        LogScaler             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "943                      Perceptron       No Oversampling     MinMaxScaler             3                         RFE  [scannedLineItems, pricePerScannedLineItem, se...                                              {}                           -2.152741                                          1.970403  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "502   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.195317                                          0.546154  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1562  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.195317                                          0.546154  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1032  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.195317                                          0.546154  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2094  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.421205  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "824                      GaussianNB       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1353                     GaussianNB       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1354                     GaussianNB       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "294                      GaussianNB       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "293                      GaussianNB       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "823                      GaussianNB       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -2.251197                                          0.499499       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1881                     GaussianNB       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -2.277807                                          0.480363       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "503   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.280468                                          0.383766  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1033  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.280468                                          0.383766  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1563  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.280468                                          0.383766  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1352                     GaussianNB       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "822                      GaussianNB       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1882                     GaussianNB       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "292                      GaussianNB       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.291112                                          0.481289       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1564  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.339010                                          0.429265  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1034  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.339010                                          0.429265  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "504   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.339010                                          0.429265  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1355                     GaussianNB       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.344332                                          0.574415       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "295                      GaussianNB       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.344332                                          0.574415       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "825                      GaussianNB       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.344332                                          0.574415       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "2095  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.357637                                          0.452316  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "509   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1039  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1038  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1569  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2099  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.392267  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2098  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1568  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "508   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -2.386908                                          0.335630  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2096  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.424162                                          0.366827  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1565  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.450772                                          0.453778  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "505   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.450772                                          0.453778  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1035  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.450772                                          0.453778  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1036  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.496009                                          0.395064  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1566  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.496009                                          0.395064  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "506   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.496009                                          0.395064  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1037  QuadraticDiscriminantAnalysis       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "1567  QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "2097  QuadraticDiscriminantAnalysis       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "507   QuadraticDiscriminantAnalysis       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.509313                                          0.370092  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "941                      Perceptron       No Oversampling     MinMaxScaler             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "411                      Perceptron       No Oversampling       No Scaling             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "1471                     Perceptron       No Oversampling   StandardScaler             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "2001                     Perceptron       No Oversampling        LogScaler             2                         RFE                 [scannedLineItems, secondsPerEuro]                                              {}                           -2.653007                                          2.938061  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "826                      GaussianNB       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.676956                                          0.667603       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "296                      GaussianNB       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.676956                                          0.667603       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1356                     GaussianNB       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.676956                                          0.667603       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1883                     GaussianNB       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -2.788717                                          0.432177       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1357                     GaussianNB       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.249069                                          0.700153       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "297                      GaussianNB       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.249069                                          0.700153       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "827                      GaussianNB       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.249069                                          0.700153       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1885                     GaussianNB       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                           -3.400745                                          0.469608       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1886                     GaussianNB       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.400745                                          0.462822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1884                     GaussianNB       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                           -3.467270                                          0.531802       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1358                     GaussianNB       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.706759                                          0.728619       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "298                      GaussianNB       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.706759                                          0.728619       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "828                      GaussianNB       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -3.706759                                          0.728619       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "829                      GaussianNB       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.111229                                          0.765794       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1359                     GaussianNB       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.111229                                          0.765794       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "299                      GaussianNB       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.111229                                          0.765794       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "830                      GaussianNB       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.132517                                          0.752621       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1360                     GaussianNB       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.132517                                          0.752621       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "300                      GaussianNB       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.132517                                          0.752621       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "831                      GaussianNB       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.177754                                          0.637230       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1361                     GaussianNB       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.177754                                          0.637230       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "301                      GaussianNB       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.177754                                          0.637230       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1887                     GaussianNB       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.204364                                          0.487839       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "832                      GaussianNB       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.683342                                          0.517235       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1362                     GaussianNB       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.683342                                          0.517235       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "302                      GaussianNB       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.683342                                          0.517235       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1888                     GaussianNB       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.709952                                          0.394694       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1889                     GaussianNB       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.749867                                          0.412888       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1890                     GaussianNB       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.843002                                          0.431181       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1891                     GaussianNB       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -4.962746                                          0.415310       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1892                     GaussianNB       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.109101                                          0.429031       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1895                     GaussianNB       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "834                      GaussianNB       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1365                     GaussianNB       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1893                     GaussianNB       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "305                      GaussianNB       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1894                     GaussianNB       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "304                      GaussianNB       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "835                      GaussianNB       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "303                      GaussianNB       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1364                     GaussianNB       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1363                     GaussianNB       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "833                      GaussianNB       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -5.162320                                          0.471822       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "592                 NearestCentroid       No Oversampling     MinMaxScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1122                NearestCentroid       No Oversampling   StandardScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1652                NearestCentroid       No Oversampling        LogScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "62                  NearestCentroid       No Oversampling       No Scaling             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "591                 NearestCentroid       No Oversampling     MinMaxScaler             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "61                  NearestCentroid       No Oversampling       No Scaling             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1121                NearestCentroid       No Oversampling   StandardScaler             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1651                NearestCentroid       No Oversampling        LogScaler             1                 SelectKBest                                       [trustLevel]                                              {}                           -7.373603                                          1.024395  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1653                NearestCentroid       No Oversampling        LogScaler             3                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -7.394891                                          0.676389  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1654                NearestCentroid       No Oversampling        LogScaler             4                 SelectKBest  [trustLevel, scannedLineItems, pricePerScanned...                                              {}                           -7.394891                                          0.676389  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1656                NearestCentroid       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -7.421501                                          0.681185  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1655                NearestCentroid       No Oversampling        LogScaler             5                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...                                              {}                           -7.421501                                          0.681185  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "70                  NearestCentroid       No Oversampling       No Scaling            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "67                  NearestCentroid       No Oversampling       No Scaling             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "66                  NearestCentroid       No Oversampling       No Scaling             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "65                  NearestCentroid       No Oversampling       No Scaling             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "64                  NearestCentroid       No Oversampling       No Scaling             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "605                 NearestCentroid       No Oversampling     MinMaxScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "602                 NearestCentroid       No Oversampling     MinMaxScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1130                NearestCentroid       No Oversampling   StandardScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "603                 NearestCentroid       No Oversampling     MinMaxScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "604                 NearestCentroid       No Oversampling     MinMaxScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1126                NearestCentroid       No Oversampling   StandardScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1127                NearestCentroid       No Oversampling   StandardScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1129                NearestCentroid       No Oversampling   StandardScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "69                  NearestCentroid       No Oversampling       No Scaling             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "599                 NearestCentroid       No Oversampling     MinMaxScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "71                  NearestCentroid       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1133                NearestCentroid       No Oversampling   StandardScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1131                NearestCentroid       No Oversampling   StandardScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1135                NearestCentroid       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1132                NearestCentroid       No Oversampling   StandardScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "72                  NearestCentroid       No Oversampling       No Scaling            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1657                NearestCentroid       No Oversampling        LogScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "594                 NearestCentroid       No Oversampling     MinMaxScaler             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1124                NearestCentroid       No Oversampling   StandardScaler             4                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1125                NearestCentroid       No Oversampling   StandardScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "595                 NearestCentroid       No Oversampling     MinMaxScaler             5                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "601                 NearestCentroid       No Oversampling     MinMaxScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "596                 NearestCentroid       No Oversampling     MinMaxScaler             6                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "597                 NearestCentroid       No Oversampling     MinMaxScaler             7                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "75                  NearestCentroid       No Oversampling       No Scaling            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "74                  NearestCentroid       No Oversampling       No Scaling            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "73                  NearestCentroid       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "600                 NearestCentroid       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1134                NearestCentroid       No Oversampling   StandardScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.077169                                          0.671206  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "598                 NearestCentroid       No Oversampling     MinMaxScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1128                NearestCentroid       No Oversampling   StandardScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1123                NearestCentroid       No Oversampling   StandardScaler             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "63                  NearestCentroid       No Oversampling       No Scaling             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "68                  NearestCentroid       No Oversampling       No Scaling             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "593                 NearestCentroid       No Oversampling     MinMaxScaler             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                          -10.082491                                          0.675176  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1136                NearestCentroid       No Oversampling   StandardScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1137                NearestCentroid       No Oversampling   StandardScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1138                NearestCentroid       No Oversampling   StandardScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1139                NearestCentroid       No Oversampling   StandardScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1140                NearestCentroid       No Oversampling   StandardScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "610                 NearestCentroid       No Oversampling     MinMaxScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "76                  NearestCentroid       No Oversampling       No Scaling            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "77                  NearestCentroid       No Oversampling       No Scaling            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "608                 NearestCentroid       No Oversampling     MinMaxScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "607                 NearestCentroid       No Oversampling     MinMaxScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "606                 NearestCentroid       No Oversampling     MinMaxScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1670                NearestCentroid       No Oversampling        LogScaler            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1669                NearestCentroid       No Oversampling        LogScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1668                NearestCentroid       No Oversampling        LogScaler            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1667                NearestCentroid       No Oversampling        LogScaler            17                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1666                NearestCentroid       No Oversampling        LogScaler            16                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1664                NearestCentroid       No Oversampling        LogScaler            14                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1663                NearestCentroid       No Oversampling        LogScaler            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1662                NearestCentroid       No Oversampling        LogScaler            12                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1661                NearestCentroid       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1660                NearestCentroid       No Oversampling        LogScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scansWith...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1659                NearestCentroid       No Oversampling        LogScaler             9                 SelectKBest  [trustLevel, totalScanTimeInSeconds, valuePerS...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1658                NearestCentroid       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "609                 NearestCentroid       No Oversampling     MinMaxScaler            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "80                  NearestCentroid       No Oversampling       No Scaling            20                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "79                  NearestCentroid       No Oversampling       No Scaling            19                 SelectKBest  [trustLevel, totalScanTimeInSeconds, grandTota...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "78                  NearestCentroid       No Oversampling       No Scaling            18                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "1665                NearestCentroid       No Oversampling        LogScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                          -10.353912                                          0.612998  NearestCentroid(metric='euclidean', shrink_thr...\n",
       "\n",
       "[2120 rows x 10 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table = result_table.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)\n",
    "result_table.to_excel(\"Result-Train Set.xlsx\")\n",
    "result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result tables for the various OverSampling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling Strategy</th>\n",
       "      <th>Data Preparation</th>\n",
       "      <th>Feature Count</th>\n",
       "      <th>Feature Selection Technique</th>\n",
       "      <th>Features</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Monetary Value Per Instance - Mean</th>\n",
       "      <th>Monetary Value Per Instance - Standard Deviation</th>\n",
       "      <th>Raw Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, lineItemVoids, scansWithoutRegist...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>13</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'fit_intercept': True, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>0.084027</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>8</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.117084</td>\n",
       "      <td>0.121028</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.089208</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>10</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>0.135525</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>7</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, valuePerS...</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.211173</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>5</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>-0.053220</td>\n",
       "      <td>0.125149</td>\n",
       "      <td>ExtraTreeClassifier(class_weight=None, criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>11</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>0.112533</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.082491</td>\n",
       "      <td>0.220512</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, scannedLi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.093135</td>\n",
       "      <td>0.184733</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.159659</td>\n",
       "      <td>0.208667</td>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>6</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, lineItemVoidsPerPosition, scanned...</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
       "      <td>-0.239489</td>\n",
       "      <td>0.248537</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>15</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, totalScanTimeInSeconds, lineItemV...</td>\n",
       "      <td>{'binarize': 1.9000000000000001}</td>\n",
       "      <td>-0.271421</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>BernoulliNB(alpha=1.0, binarize=1.900000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>LogScaler</td>\n",
       "      <td>1</td>\n",
       "      <td>RFE</td>\n",
       "      <td>[secondsPerEuro]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.316658</td>\n",
       "      <td>0.117495</td>\n",
       "      <td>Perceptron(alpha=0.0001, class_weight=None, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>No Oversampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>[trustLevel, scannedLineItems]</td>\n",
       "      <td>{}</td>\n",
       "      <td>-6.434274</td>\n",
       "      <td>0.541220</td>\n",
       "      <td>NearestCentroid(metric='euclidean', shrink_thr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model Oversampling Strategy Data Preparation Feature Count Feature Selection Technique                                           Features                              Optimal Parameters  Monetary Value Per Instance - Mean  Monetary Value Per Instance - Standard Deviation                                          Raw Model\n",
       "12             AdaBoostClassifier       No Oversampling        LogScaler             7                         RFE  [trustLevel, lineItemVoids, scansWithoutRegist...                                              {}                            0.170303                                          0.077832  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "0              LogisticRegression       No Oversampling       No Scaling            13                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...  {'fit_intercept': True, 'solver': 'newton-cg'}                            0.162320                                          0.113088  LogisticRegression(C=1.0, class_weight=None, d...\n",
       "10           ExtraTreesClassifier       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.119745                                          0.084027  (ExtraTreeClassifier(class_weight=None, criter...\n",
       "9      GradientBoostingClassifier       No Oversampling        LogScaler             8                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.117084                                          0.121028  ([DecisionTreeRegressor(criterion='friedman_ms...\n",
       "6          RandomForestClassifier       No Oversampling       No Scaling            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                        {'criterion': 'entropy'}                            0.069186                                          0.089208  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "15              BaggingClassifier       No Oversampling     MinMaxScaler            10                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                            0.061203                                          0.135525  (DecisionTreeClassifier(class_weight=None, cri...\n",
       "3          DecisionTreeClassifier       No Oversampling       No Scaling             7                         RFE  [trustLevel, totalScanTimeInSeconds, valuePerS...                           {'criterion': 'gini'}                            0.007983                                          0.211173  DecisionTreeClassifier(class_weight=None, crit...\n",
       "2             ExtraTreeClassifier       No Oversampling        LogScaler             5                         RFE  [trustLevel, totalScanTimeInSeconds, scannedLi...                        {'criterion': 'entropy'}                           -0.053220                                          0.125149  ExtraTreeClassifier(class_weight=None, criteri...\n",
       "13     LinearDiscriminantAnalysis       No Oversampling        LogScaler            11                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                                              {}                           -0.063864                                          0.112533  LinearDiscriminantAnalysis(n_components=None, ...\n",
       "7   QuadraticDiscriminantAnalysis       No Oversampling   StandardScaler             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.082491                                          0.220512  QuadraticDiscriminantAnalysis(priors=None, reg...\n",
       "11                     GaussianNB       No Oversampling   StandardScaler             3                 SelectKBest  [trustLevel, totalScanTimeInSeconds, scannedLi...                                              {}                           -0.093135                                          0.184733       GaussianNB(priors=None, var_smoothing=1e-09)\n",
       "1                             SVC       No Oversampling        LogScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -0.159659                                          0.208667  SVC(C=1.0, cache_size=200, class_weight=None, ...\n",
       "14           KNeighborsClassifier       No Oversampling        LogScaler             6                 SelectKBest  [trustLevel, lineItemVoidsPerPosition, scanned...        {'n_neighbors': 2, 'weights': 'uniform'}                           -0.239489                                          0.248537  KNeighborsClassifier(algorithm='auto', leaf_si...\n",
       "4                     BernoulliNB       No Oversampling   StandardScaler            15                 SelectKBest  [trustLevel, totalScanTimeInSeconds, lineItemV...                {'binarize': 1.9000000000000001}                           -0.271421                                          0.015445  BernoulliNB(alpha=1.0, binarize=1.900000000000...\n",
       "5                      Perceptron       No Oversampling        LogScaler             1                         RFE                                   [secondsPerEuro]                                              {}                           -0.316658                                          0.117495  Perceptron(alpha=0.0001, class_weight=None, ea...\n",
       "8                 NearestCentroid       No Oversampling     MinMaxScaler             2                 SelectKBest                     [trustLevel, scannedLineItems]                                              {}                           -6.434274                                          0.541220  NearestCentroid(metric='euclidean', shrink_thr..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table_aggregated = pd.DataFrame(columns=[\"Model\", \"Oversampling Strategy\", \"Data Preparation\", \"Feature Count\", \"Feature Selection Technique\", \"Features\", \"Optimal Parameters\", \"Monetary Value Per Instance - Mean\", \"Monetary Value Per Instance - Standard Deviation\", \"Raw Model\"])\n",
    "\n",
    "\n",
    "for model in list(set(result_table[\"Model\"].values)):\n",
    "    sub_table = result_table[result_table[\"Model\"] == model]\n",
    "    result_table_aggregated = result_table_aggregated.append({\n",
    "        \"Model\": model,\n",
    "        \"Oversampling Strategy\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Oversampling Strategy\"],\n",
    "        \"Data Preparation\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Data Preparation\"],\n",
    "        \"Feature Count\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Feature Count\"],\n",
    "        \"Features\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Features\"],\n",
    "        \"Feature Selection Technique\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Feature Selection Technique\"],\n",
    "        \"Optimal Parameters\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Optimal Parameters\"],\n",
    "        \"Monetary Value Per Instance - Mean\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Monetary Value Per Instance - Mean\"],\n",
    "        \"Monetary Value Per Instance - Standard Deviation\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Monetary Value Per Instance - Standard Deviation\"],\n",
    "        \"Raw Model\": sub_table.loc[sub_table[\"Monetary Value Per Instance - Mean\"].argmax()][\"Raw Model\"]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "result_table_aggregated.to_excel(\"Result-Train Set-Aggregated.xlsx\")\n",
    "\n",
    "result_table_aggregated.sort_values(by = \"Monetary Value Per Instance - Mean\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Monetary Value Per Instance - Mean')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "plt.scatter(result_table[result_table[\"Model\"] == \"LogisticRegression\"][\"Feature Count\"],\n",
    "         result_table[result_table[\"Model\"] == \"LogisticRegression\"][\"Monetary Value Per Instance - Mean\"])\n",
    "plt.xlabel('Number of features', fontsize=16)\n",
    "plt.ylabel('Monetary Value Per Instance - Mean', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "['trustLevel' 'lineItemVoids' 'scansWithoutRegistration'\n",
      " 'scannedLineItemsPerSecond' 'valuePerSecond' 'scannedLineItems'\n",
      " 'scansWithoutRegistrationPerScannedLineItem']\n"
     ]
    }
   ],
   "source": [
    "best_model = result_table_aggregated.loc[result_table_aggregated[\"Monetary Value Per Instance - Mean\"].argmax()][\"Raw Model\"]\n",
    "best_model_features = result_table_aggregated.loc[result_table_aggregated[\"Monetary Value Per Instance - Mean\"].argmax()][\"Features\"]\n",
    "\n",
    "print(best_model)\n",
    "print(best_model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative:  1775\n",
      "False positive:  0\n",
      "False negative:  0\n",
      "True positive:  104\n",
      "520 for 1879 instances in the test set\n",
      "0.2767429483767962 per instance in the test set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_monetary_value(cm):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(\"True negative: \", tn)\n",
    "        print(\"False positive: \", fp)\n",
    "        print(\"False negative: \", fn)\n",
    "        print(\"True positive: \", tp)\n",
    "        score = (-25)*fp + (-5)*fn + 5*tp\n",
    "        print(str(score) + \" for \" + str(sum(sum(cm))) + \" instances in the test set\")\n",
    "        print(str(score/sum(sum(cm))) + \" per instance in the test set\")\n",
    "        return score\n",
    "    \n",
    "cm = confusion_matrix(Y , best_model.predict(X[best_model_features]))\n",
    "\n",
    "monetary_value = get_monetary_value(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
