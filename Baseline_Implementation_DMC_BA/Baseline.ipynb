{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(ne, ua, cutoff_date = '2017-08-01'):\n",
    "   \n",
    "    ua['start_date']= pd.to_datetime(ua['start_date'])\n",
    "    ua['end_date']= pd.to_datetime(ua['end_date'])\n",
    "    cutoff_date= pd.to_datetime(cutoff_date)\n",
    "    \n",
    "    # Step A\n",
    "    ua=ua.loc[ua['start_date'] <cutoff_date,:]\n",
    "    ua['end_date']= ua['end_date'].apply(lambda x: cutoff_date - pd.Timedelta(seconds=1) if x > cutoff_date  else x)\n",
    "    ua['duration_days']=(ua['end_date']-ua['start_date']).apply(lambda x: x.seconds)\n",
    "    \n",
    "    # Step B\n",
    "    mean_duration_days= ua.groupby('ne_id')['duration_days'].apply(lambda x: np.nanmean(x.values)).values  \n",
    "    mode_product_2 = ua.groupby('ne_id')['product_category_2'].apply(lambda x: stats.mode(x.values).mode[0]).values\n",
    "    mode_product_3 = ua.groupby('ne_id')['product_category_3'].apply(lambda x: stats.mode(x.values).mode[0]).values\n",
    "    ne_id= ua.groupby('ne_id')['ne_id'].unique().apply(lambda x: x[0]).values\n",
    "    d = {'ne_id':ne_id,'mean_duration_days':mean_duration_days, 'mode_product_2': mode_product_2, 'mode_product_3': mode_product_3}\n",
    "    ua_features = pd.DataFrame(data=d)\n",
    "    \n",
    "    ## Step C - add the features to the NE data frame ----\n",
    "    ne_with_features= pd.merge(ne, ua_features, how='left', on='ne_id')\n",
    "  \n",
    "    ## Step D - replace NAs with sensible values ----\n",
    "    ne_with_features['mean_duration_days']= ne_with_features['mean_duration_days'].fillna(0)\n",
    "    ne_with_features['mode_product_2']= ne_with_features['mode_product_2'].fillna('no outages found')\n",
    "    ne_with_features['mode_product_3']= ne_with_features['mode_product_3'].fillna('no outages found')\n",
    "\n",
    "    return ne_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(ne,ua,interval_start,interval_end):\n",
    "    \n",
    "    interval_start=pd.to_datetime(interval_start)\n",
    "    interval_end=pd.to_datetime(interval_end)\n",
    "    \n",
    "    # Hold only uas in the given interval\n",
    "    idx1 = (ua['start_date'] >= interval_start)  &  (ua['start_date'] <= interval_end )\n",
    "    idx2 = (ua['end_date'] >= interval_start)  &  (ua['end_date'] <= interval_end) \n",
    "    idx3 = (ua['start_date'] < interval_start)  &  (ua['end_date'] > interval_end ) \n",
    "    idx_overall = idx1 | idx2 | idx3 \n",
    "    unavailability_by_ne= ua[idx_overall]\n",
    "    \n",
    "    # Hold only one ua for singe ne \n",
    "    ua1=unavailability_by_ne.drop_duplicates( subset='ne_id' )\n",
    "    ua1['label']=1\n",
    "    \n",
    "    ua2= ua1.loc[:,['ne_id','label']]\n",
    "    ua2=ua1[['ne_id','label']]\n",
    "    # Create the label for each network id\n",
    "    ne_with_uas=pd.merge(ne, ua2, how='left', on='ne_id')\n",
    "    ne_with_uas['label']=ne_with_uas['label'].fillna(0)\n",
    "    \n",
    "    return ne_with_uas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_holdout_test(ua,ne,cutoff_train='2017-06-01',cutoff_holdout='2017-07-01',cutoff_test='2017-08-01'):\n",
    "    train=make_features(ne, ua, cutoff_date = cutoff_train)\n",
    "    holdout = make_features(ne, ua, cutoff_holdout)\n",
    "    test = make_features(ne, ua, cutoff_test)\n",
    "  \n",
    "    train = make_label(train, ua, interval_start = cutoff_train, interval_end = cutoff_holdout)\n",
    "    holdout = make_label(holdout, ua, interval_start = cutoff_holdout, interval_end = cutoff_test)\n",
    "  \n",
    "    return train, holdout ,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/stats.py:248: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ne_id', 'ne_name', 'site_id', 'controller_id', 'origin_net',\n",
       "       'technology', 'n_cells', 'city', 'zip_code', 'location_type',\n",
       "       'urbanity', 'latitude', 'longitude', 'MNC', 'LAC', 'TAC', 'frequency',\n",
       "       'antenna_type', 'mean_duration_days', 'mode_product_2',\n",
       "       'mode_product_3', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ua=pd.read_csv('unavailabilities copy.csv',sep=',')\n",
    "ne=pd.read_csv('network_elements copy.csv',sep=',')\n",
    "cutoff_train =   '2017-06-01'\n",
    "cutoff_holdout = '2017-07-01'\n",
    "cutoff_test =    '2017-08-01' # this is the end of your data. You should not change this date.\n",
    "\n",
    "\n",
    "\n",
    "# this can take a bit of time (~5-10 mins on i7, depending on number and types of features)\n",
    "train,holdout,test = create_train_holdout_test(ua, ne, cutoff_train, cutoff_holdout, cutoff_test)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv',index=False)\n",
    "holdout.to_csv('holdout.csv',index=False)\n",
    "test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ne_id', 'ne_name', 'site_id', 'controller_id', 'origin_net',\n",
       "       'technology', 'n_cells', 'city', 'zip_code', 'location_type',\n",
       "       'urbanity', 'latitude', 'longitude', 'MNC', 'LAC', 'TAC', 'frequency',\n",
       "       'antenna_type', 'mean_duration_days', 'mode_product_2',\n",
       "       'mode_product_3', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv',sep=',')\n",
    "holdout=pd.read_csv('holdout.csv',sep=',')\n",
    "test=pd.read_csv('test.csv',sep=',')\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop =['ne_id', 'ne_name', 'site_id', 'controller_id', 'city','zip_code','LAC',\n",
    "               'TAC','antenna_type','MNC','latitude','longitude']\n",
    "train = train.drop(columns_drop,axis=1)\n",
    "holdout = holdout.drop(columns_drop,axis=1)\n",
    "test = test.drop(columns_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_net            False\n",
       "technology            False\n",
       "n_cells                True\n",
       "location_type          True\n",
       "urbanity               True\n",
       "frequency              True\n",
       "mean_duration_days    False\n",
       "mode_product_2        False\n",
       "mode_product_3        False\n",
       "label                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_net             object\n",
       "technology             object\n",
       "n_cells               float64\n",
       "location_type          object\n",
       "urbanity               object\n",
       "frequency             float64\n",
       "mean_duration_days    float64\n",
       "mode_product_2         object\n",
       "mode_product_3         object\n",
       "label                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_n_cells= np.nanmean(train['n_cells'])\n",
    "\n",
    "mean_frequency= np.nanmean(train['frequency'])\n",
    "\n",
    "\n",
    "train['n_cells'] =train['n_cells'].fillna(mean_n_cells)\n",
    "train['location_type'] = train['location_type'].fillna('unknown')\n",
    "train['urbanity'] = train['location_type'].fillna('unknown')\n",
    "train['frequency'] = train['frequency'].fillna(mean_frequency)\n",
    "\n",
    "holdout['n_cells'] =train['n_cells'].fillna(mean_n_cells)\n",
    "holdout['location_type'] = train['location_type'].fillna('unknown')\n",
    "holdout['urbanity'] = train['location_type'].fillna('unknown')\n",
    "holdout['frequency'] = train['frequency'].fillna(mean_frequency)\n",
    "\n",
    "test['n_cells'] =train['n_cells'].fillna(mean_n_cells)\n",
    "test['location_type'] = train['location_type'].fillna('unknown')\n",
    "test['urbanity'] = train['location_type'].fillna('unknown')\n",
    "test['frequency'] = train['frequency'].fillna(mean_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T' 'E']\n",
      "['3g' '4g' '2g']\n",
      "[ 6.       4.77419  9.      12.       3.       8.       4.       2.\n",
      " 18.       1.      16.       5.      10.     ]\n",
      "['SITE' 'unknown' 'POLE' 'TOWER' 'BUILDING']\n",
      "['SITE' 'unknown' 'POLE' 'TOWER' 'BUILDING']\n",
      "[2100.         1449.17247387  800.         2600.         1800.\n",
      "  900.        ]\n",
      "[13321.5 18460.      0.  ... 21300.6 19582.  21072.5]\n",
      "['Network' 'Others' 'no outages found' 'Switch' 'Multiplex' 'Connectivity'\n",
      " 'Mobile' '0' 'Other' 'Facilities' 'Endpoint' 'Synchronization']\n",
      "['Ethernet Microwave' 'IP Support' 'no outages found' 'Node B' 'BS' 'DXX'\n",
      " 'SDH' 'LTE enode' 'BSC' 'RNC' 'ATM Switch' 'Special-Use-Device' 'RR'\n",
      " 'DCN-Equipment' 'Cross Connect' 'MUX' '0' 'Mobile' 'Microwave PDH'\n",
      " 'Mobilfunk Repeater' 'Other' 'PMP Central Station' 'Router' 'Location'\n",
      " 'Microwave SDH' 'WDM' 'Microwave Link' 'Leased Line' 'Interworking'\n",
      " 'GPS Clock' 'Master Unit for optical fibre repeaters GSM']\n",
      "[0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['origin_net', 'technology', 'n_cells', 'location_type', 'urbanity',\n",
       "       'frequency', 'mean_duration_days', 'mode_product_2', 'mode_product_3',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train:\n",
    "    print(train[col].unique())\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "encoder_One_Hot= LabelEncoder() #OneHotEncoder()\n",
    "\n",
    "#encoder_Ordinal_tech= OrdinalEncoder(categories=['2g', '3g', '4g'])\n",
    "\n",
    "train_origin_net=train['origin_net'].values.reshape(-1, 1)\n",
    "train_technology=train['technology'].values.reshape(-1, 1)\n",
    "train_location_type =train['location_type'].values.reshape(-1, 1)\n",
    "train_urbanity =train['urbanity'].values.reshape(-1, 1)\n",
    "train_mode_product_2=train['mode_product_2'].values.reshape(-1, 1)\n",
    "train_mode_product_3 =train['mode_product_3'].values.reshape(-1, 1)\n",
    "\n",
    "#train['technology']=encoder_Ordinal_tech.fit_transform(train_origin_net)\n",
    "\n",
    "train['origin_net']= encoder_One_Hot.fit_transform(train_origin_net)\n",
    "train['location_type'] = encoder_One_Hot.fit_transform(train_location_type)\n",
    "train['urbanity'] = encoder_One_Hot.fit_transform(train_urbanity)\n",
    "train['mode_product_2'] = encoder_One_Hot.fit_transform(train_mode_product_2)\n",
    "train['mode_product_3'] = encoder_One_Hot.fit_transform(train_mode_product_3)\n",
    "train['technology']= encoder_One_Hot.fit_transform(train_technology)\n",
    "\n",
    "\n",
    "holdout_origin_net=holdout['origin_net'].values.reshape(-1, 1)\n",
    "holdout_technology=holdout['technology'].values.reshape(-1, 1)\n",
    "holdout_location_type =holdout['location_type'].values.reshape(-1, 1)\n",
    "holdout_urbanity =holdout['urbanity'].values.reshape(-1, 1)\n",
    "holdout_mode_product_2=holdout['mode_product_2'].values.reshape(-1, 1)\n",
    "holdout_mode_product_3 =holdout['mode_product_3'].values.reshape(-1, 1)\n",
    "\n",
    "#train['technology']=encoder_Ordinal_tech.fit_transform(train_origin_net)\n",
    "\n",
    "holdout['origin_net']= encoder_One_Hot.fit_transform(holdout_origin_net)\n",
    "holdout['location_type'] = encoder_One_Hot.fit_transform(holdout_location_type)\n",
    "holdout['urbanity'] = encoder_One_Hot.fit_transform(holdout_urbanity)\n",
    "holdout['mode_product_2'] = encoder_One_Hot.fit_transform(holdout_mode_product_2)\n",
    "holdout['mode_product_3'] = encoder_One_Hot.fit_transform(holdout_mode_product_3)\n",
    "holdout['technology']= encoder_One_Hot.fit_transform(holdout_technology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train= train['label']\n",
    "x_train= train.drop('label',axis=1)\n",
    "\n",
    "y_holdout = train['label'] \n",
    "x_holdout = holdout.drop('label',axis=1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=324)\n",
    "\n",
    "x_holdout, x_test, y_holdout, y_test = train_test_split(x_holdout, y_holdout, test_size=0.0, random_state=324)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= DecisionTreeClassifier(max_leaf_nodes=10, random_state=0)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8837264190704183"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions=model.predict(x_holdout)\n",
    "accuracy_score(y_true = y_holdout, y_pred = predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
